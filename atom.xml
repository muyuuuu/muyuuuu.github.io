<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Just for Life.</title>
  
  <subtitle>明月更几时</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://muyuuuu.github.io/"/>
  <updated>2022-04-04T12:39:45.544Z</updated>
  <id>https://muyuuuu.github.io/</id>
  
  <author>
    <name>兰铃</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>遥感图像分割，类别不平衡损失为何失效了？</title>
    <link href="https://muyuuuu.github.io/2022/04/04/deal-unbalance-label/"/>
    <id>https://muyuuuu.github.io/2022/04/04/deal-unbalance-label/</id>
    <published>2022-04-04T11:54:49.000Z</published>
    <updated>2022-04-04T12:39:45.544Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>去年寒假接到了一个语义分割的任务，存在着严重的类别不平衡问题。当时想着使用经典的类别不平衡损失 focal loss 和 dice loss 解决一下，但是效果不升反降，甚至不如传统的交叉熵损失函数。而且我在 github 上搜类似的项目，也都不推荐使用这些 loss。但是在 mmseg 的文档中，我们又发现 dice loss 有明显的提升，来冷静分析一下这是为什么。本文默认读者了解 focal loss 和 dice loss，因此不会对损失函数进行讲解。</p><p>其实我也不是第一次遇到这种经典损失函数失效的现象，之前 triplet loss 也频频失效，一度上了我的黑名单。关于 trilet loss 何时失效以及为什么，可以参考之前的文章，<a href="https://muyuuuu.github.io/2022/03/24/E-commerce-Search-Recall/">如何更好的提取文本表示</a>。</p><a id="more"></a><h1 id="focal-loss"><a href="#focal-loss" class="headerlink" title="focal loss"></a>focal loss</h1><p>focal loss 是目标检测领域中很经典的存在，focal loss 和 retinanet 发在同一篇论文，但是我看源程序，发现在实现上有一些小细节。我们知道基于 anchor 生成检测框时，会有大量的无效检测框，这些框和真实目标毫不相交，这就导致了样本不平衡的问题。而 focal loss 的解决方案也是简单粗暴，使用 $\alpha$ 控制正负样本不平衡问题，使用 $\gamma$ 控制难易样本的区分。</p><p>在实现中，作者将与真实目标框 IoU 大于 0.5 的视为正样本，IoU 小于 0.4 的视为负样本，还有介于两者之间模棱两可的模糊样本。将所有的预测结果和真实标签计算损失，我们希望和真实结果 IoU 较大的区域分类结果接近 1，其余位置接近 0，此时有严重的类别不平衡问题，因此使用了 focal loss 进行缓解。但是在反向传播的时候，并不所有预测结果都要反向传播，而是对损失进行筛选，只回传正样本部分的损失，其余损失不考虑。</p><p>不然那么多负样本在那里，假设有 10000 个预测结果，只有 10 个真实目标，我就算输出 10000 个 0 损失也不会低，但是检测不到目标，俗称模型坍塌。因此源程序中做了这样的处理。</p><p>那么为什么语义分割的时候失效了呢？看完程序我大概给出我的猜测（目前实在没有精力做消融实验），我看了一些语义分割经典仓库中 focal loss 的实现，发现了一个问题。假设分割时的图像大小是 $512\times 512$，那么这就有将近 27 万个预测结果，遗憾的是，这些全部参与了反向传播。尤其是遥感领域的图像分割，背景占据大部分面积，前景目标的面积占比很小时，这就导致了模型坍塌的问题：模型把所有像素点预测为背景，损失不低，但结果无效。</p><p>因此，一个简单的解决方案就是：像 retinanet 一样，并不是所有的预测结果都参与反向传播。只需按照真实标签，只选择前景区域所在位置的损失，而忽略掉大部分背景区域的损失。</p><h2 id="focal-程序实现"><a href="#focal-程序实现" class="headerlink" title="focal 程序实现"></a>focal 程序实现</h2><ul><li><a href="https://github.com/yhenon/pytorch-retinanet/blob/master/retinanet/losses.py#L120-L123" target="_blank" rel="noopener">retinanet 实现</a></li><li><a href="https://github.com/qubvel/segmentation_models.pytorch/blob/master/segmentation_models_pytorch/losses/_functional.py#L70-L96" target="_blank" rel="noopener">smp 实现</a></li><li><a href="https://github.com/open-mmlab/mmsegmentation/blob/master/mmseg/models/losses/focal_loss.py#L47-L67" target="_blank" rel="noopener">mmseg 实现</a></li></ul><h1 id="dice-loss"><a href="#dice-loss" class="headerlink" title="dice loss"></a>dice loss</h1><p>dice loss 很神奇，可以说是为语义分割而诞生的。因为交叉熵定义的是分类损失，评估衡量结果时却用 mIoU，也就是优化目标和期望目标不一致，所以 dice loss 以类似 IoU 损失的想法优化目标。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;去年寒假接到了一个语义分割的任务，存在着严重的类别不平衡问题。当时想着使用经典的类别不平衡损失 focal loss 和 dice loss 解决一下，但是效果不升反降，甚至不如传统的交叉熵损失函数。而且我在 github 上搜类似的项目，也都不推荐使用这些 loss。但是在 mmseg 的文档中，我们又发现 dice loss 有明显的提升，来冷静分析一下这是为什么。本文默认读者了解 focal loss 和 dice loss，因此不会对损失函数进行讲解。&lt;/p&gt;
&lt;p&gt;其实我也不是第一次遇到这种经典损失函数失效的现象，之前 triplet loss 也频频失效，一度上了我的黑名单。关于 trilet loss 何时失效以及为什么，可以参考之前的文章，&lt;a href=&quot;https://muyuuuu.github.io/2022/03/24/E-commerce-Search-Recall/&quot;&gt;如何更好的提取文本表示&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DeepLearning" scheme="https://muyuuuu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>分治枚举</title>
    <link href="https://muyuuuu.github.io/2022/04/04/divide-conquer-enumerate/"/>
    <id>https://muyuuuu.github.io/2022/04/04/divide-conquer-enumerate/</id>
    <published>2022-04-04T08:36:29.000Z</published>
    <updated>2022-04-04T08:42:55.121Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>之后的日子，大概会放缓刷题的脚步进行简单的整理，因为有些题目是有规律的，需要做号总结和整理，不能刷一个忘一个。<strong>今日总结：题目要求返回所有结果，且能找到分界点分解为子问题的，都可以套用分治枚举算法。</strong></p><a id="more"></a><h1 id="分治算法枚举"><a href="#分治算法枚举" class="headerlink" title="分治算法枚举"></a>分治算法枚举</h1><p>众所周知，枚举是个技术活，如何合理的枚举所有结果、避免重复和剪枝，并没有想象的那么简单。而分治枚举就是，通过将原问题分割为多个子问题，多个子问题的解<strong>排列组合</strong>能产生多种答案，我们收集多种答案并返回。</p><p>对于此类问题，我们需要确定三个东西：分界点，递归函数，如何排列组合。这样，给定一个分界点，我们把问题分解为左侧问题和右侧问题，两者答案的组合就是当前分界点对应的所有结果。然后再移动分界点，得到其他所有结果即可。此外，再分割得到子问题并求解时，需要设置 base case 用于退出递归。</p><h2 id="96-不同的二叉搜索树"><a href="#96-不同的二叉搜索树" class="headerlink" title="96. 不同的二叉搜索树"></a>96. 不同的二叉搜索树</h2><p>给你一个整数 n ，求恰由 n 个节点组成且节点值从 1 到 n 互不相同的 二叉搜索树 有多少种？返回满足题意的二叉搜索树的种数。如下的示例，3 个节点能组成 5 种二叉树。</p><p><img data-src="/2022/04/04/divide-conquer-enumerate/1.jpg" alt></p><p>那我们考虑给出那三个东西：</p><ol><li>分界节点，以不同的值作为根节点，遍历所有的情况</li><li>既然有了根节点，就需要构建左子树。定义一个函数，返回某子树对应的情况，也就能得到分界点左子树有多少情况，同理得到右子树的排列组合</li><li>而左子树和右子树的乘积就是当前根节点对应的结果</li></ol><p>我们定义一个函数，函数有两个参数，这两个参数是子树的取值范围，因此，退出递归的 base case 就是子树的左侧值大于右侧值，此时返回 1，因为表示调用者的结果是 1，不能再划分为子问题了。函数的返回值是这种取值范围下，有多少结果。我们写出程序：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; memo;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">numTrees</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; <span class="title">tmp</span><span class="params">(n, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n, <span class="number">0</span>))</span></span>;</span><br><span class="line">        memo = tmp;</span><br><span class="line">        <span class="keyword">return</span> build(<span class="number">1</span>, n);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">build</span><span class="params">(<span class="keyword">int</span> l, <span class="keyword">int</span> r)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// base case</span></span><br><span class="line">        <span class="keyword">if</span> (l &gt; r)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (memo[l<span class="number">-1</span>][r<span class="number">-1</span>] != <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> memo[l<span class="number">-1</span>][r<span class="number">-1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = l; i &lt;= r; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> a = build(l, i - <span class="number">1</span>);</span><br><span class="line">            <span class="keyword">int</span> b = build(i + <span class="number">1</span>, r);</span><br><span class="line">            <span class="comment">// 累积所有的结果</span></span><br><span class="line">            memo[l<span class="number">-1</span>][r<span class="number">-1</span>] += a*b;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> memo[l<span class="number">-1</span>][r<span class="number">-1</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>其中，<code>memo</code> 起到剪枝的效果。</p><h2 id="95-不同的二叉搜索树-II"><a href="#95-不同的二叉搜索树-II" class="headerlink" title="95. 不同的二叉搜索树 II"></a>95. 不同的二叉搜索树 II</h2><p>给你一个整数 n ，求恰由 n 个节点组成且节点值从 1 到 n 互不相同的 二叉搜索树 有多少种？返回满足题意的二叉搜索树的种数。如下的示例，3 个节点能组成 5 种二叉树。</p><p><img data-src="/2022/04/04/divide-conquer-enumerate/1.jpg" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入：n = 3</span><br><span class="line">输出：[[1,null,2,null,3],[1,null,3,2],[2,1,3],[3,1,null,null,2],[3,2,null,1]]</span><br></pre></td></tr></table></figure><p>同上一题，既然要给出所有的子树结果，那么此时就不需要计数，而是需要创建子树。同样以根节点的取值为分界点，统计出所有可能的左子树，统计出所有可能的右子树，上一题为结果相加，那么这个题目需要对左右子树的结果进行排列组合。因为这题不会超时，因此没有设置剪枝。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">vector</span>&lt;TreeNode*&gt; <span class="title">build</span><span class="params">(<span class="keyword">int</span> l, <span class="keyword">int</span> r)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (l &gt; r) &#123;</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="literal">nullptr</span>&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">vector</span>&lt;TreeNode*&gt; res;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = l; i &lt;= r; i++) &#123;</span><br><span class="line">        <span class="keyword">auto</span> leftTree = build(l, i - <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">auto</span> rightTree = build(i + <span class="number">1</span>, r);</span><br><span class="line">        <span class="comment">// 创建子树，等价于上一题的相加</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> a : leftTree) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">auto</span> b : rightTree) &#123;</span><br><span class="line">                TreeNode* node = <span class="keyword">new</span> TreeNode(i);</span><br><span class="line">                node-&gt;left = a;</span><br><span class="line">                node-&gt;right = b;</span><br><span class="line">                res.emplace_back(node);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="241-为运算表达式设计优先级"><a href="#241-为运算表达式设计优先级" class="headerlink" title="241. 为运算表达式设计优先级"></a>241. 为运算表达式设计优先级</h2><p>给你一个由数字和运算符组成的字符串 expession ，按不同优先级组合数字和运算符，计算并返回所有可能组合的结果。你可以 按任意顺序 返回答案。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">输入：expression = &quot;2*3-4*5&quot;</span><br><span class="line">输出：[-34,-14,-10,-10,10]</span><br><span class="line">解释：</span><br><span class="line">(2*(3-(4*5))) = -34 </span><br><span class="line">((2*3)-(4*5)) = -14 </span><br><span class="line">((2*(3-4))*5) = -10 </span><br><span class="line">(2*((3-4)*5)) = -10 </span><br><span class="line">(((2*3)-4)*5) = 10</span><br></pre></td></tr></table></figure><p>最开始我以为这是回溯，后来发现不是，因此总结出一个规律：<strong>题目要求返回所有结果，且能找到分界点分解为子问题的，都可以套用分治枚举算法</strong>。对于这个题而言，运算符就是分界点，然后枚举左侧和右侧有几种结果即可。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; <span class="title">diffWaysToCompute</span><span class="params">(<span class="built_in">string</span> expression)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; expression.size(); i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (expression[i] == <span class="string">'-'</span> || expression[i] == <span class="string">'*'</span> || expression[i] == <span class="string">'+'</span>) &#123;</span><br><span class="line">            <span class="comment">// 分治，左侧有几种结果</span></span><br><span class="line">            <span class="keyword">auto</span> res1 = diffWaysToCompute(expression.substr(<span class="number">0</span>, i));</span><br><span class="line">            <span class="keyword">auto</span> res2 = diffWaysToCompute(expression.substr(i + <span class="number">1</span>));</span><br><span class="line">            <span class="comment">// 枚举所有结果，并追加，和第一题的 += 一样</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">auto</span> it1 : res1) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">auto</span> it2 : res2) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (expression[i] == <span class="string">'-'</span>)</span><br><span class="line">                        res.push_back(it1 - it2);</span><br><span class="line">                    <span class="keyword">if</span> (expression[i] == <span class="string">'+'</span>)</span><br><span class="line">                        res.push_back(it1 + it2);</span><br><span class="line">                    <span class="keyword">if</span> (expression[i] == <span class="string">'*'</span>)</span><br><span class="line">                        res.push_back(it1 * it2);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (res.size() == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> &#123;stoi(expression)&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之后的日子，大概会放缓刷题的脚步进行简单的整理，因为有些题目是有规律的，需要做号总结和整理，不能刷一个忘一个。&lt;strong&gt;今日总结：题目要求返回所有结果，且能找到分界点分解为子问题的，都可以套用分治枚举算法。&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DataStructure" scheme="https://muyuuuu.github.io/tags/DataStructure/"/>
    
  </entry>
  
  <entry>
    <title>什么是 bert</title>
    <link href="https://muyuuuu.github.io/2022/03/28/bert/"/>
    <id>https://muyuuuu.github.io/2022/03/28/bert/</id>
    <published>2022-03-28T14:16:12.000Z</published>
    <updated>2022-03-28T14:51:04.932Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>书接上文，因为参加 NLP 的比赛不知道什么是 bert 实在有点说不过去，于是花了三天时间看了下 bert 的基本概念和代码。不得不说，网上阳间的 bert 预训练代码太少了，大多是转载和 mark 之类没啥用的东西，属实是占据了搜索引擎的首页，占够了热度。</p><a id="more"></a><h1 id="transformer"><a href="#transformer" class="headerlink" title="transformer"></a>transformer</h1><p>这个就不得不提一下 Attention is all your need. 由于处理序列的时候 RNN 不容易并行计算，输出 $b_4$ 的时候需要输入 $a_1, a_2, a_3, a_4$。所以使用 CNN 来代替 RNN，一个 CNN 按顺序划过序列输入产生一个输出，就不用看完一个句子才会有输出，而多个 CNN 就可以产生多个输出，模型就可以可以并行化。如下图所示，不需要等待红色的输出算完，再算黄色的输出。</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs1mct.jpg" alt></p><p>如果考虑让一个 CNN 看到更多的输入，那么只需要在模型的隐层叠加另外的 CNN 即可，也就是上图的蓝色三角。基于这个概念，就有了后面的 self-attention。</p><h2 id="self-attention"><a href="#self-attention" class="headerlink" title="self-attention"></a>self-attention</h2><p>$A=Wx, Q=W_qA, K=W_kA, V=W_vA$，这里其实就是乘以一个大矩阵，只不过图里分开写清楚一些。</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs1Y3n.png" alt></p><p>之后每个 $q$ 和每个 $k$ 做 attention，也就是内积，得到如下的 $\alpha$ 输出，然后再除以维度数，防止维度过高导致的内积过大。</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs1auV.png" alt></p><p>然后将 $\alpha$ 经过 softmax 操作得到 $\hat{\alpha}$：</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs1wHU.png" alt></p><p>对于 $b_1$ 输出，只需要让 $\hat{\alpha_{1,i}}$ 和所有的 $v_i$ 做乘积并求和即可。同理，可以得到 $b_2,b_3,b_4$ 的输出。</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs1DN4.png" alt></p><p>对应的，下图左上角就是我们的 self-attention 层，期中的运算可以总结成矩阵乘法：</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs1r4J.png" alt></p><h3 id="multi-head-self-attention"><a href="#multi-head-self-attention" class="headerlink" title="multi-head-self-attention"></a>multi-head-self-attention</h3><p>可以再计算 $Q,K,V$ 的时候产生多个结果，然后在输出 $b$ 的时候再通过一个矩阵将多个结果融合成一个。而我看的程序，就分开注意力，最后 view 到一起。</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs1Ru6.png" alt></p><h3 id="Positional-Encoding"><a href="#Positional-Encoding" class="headerlink" title="Positional Encoding"></a>Positional Encoding</h3><p>现在的 self-attention 没有考虑到序列的位置信息，而是使用全局信息，不能利用单词的顺序信息，而这部分信息对于 NLP 来说非常重要，所以需要加入位置的 embedding。人工设定每一个位置的 embedding，和 $A$ 加在一起作为新的 $A$ 参与后面的运算，等价于在 $X$ 拼接一个 one-hot 向量后再做运算：</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs1fHO.png" alt></p><h1 id="程序"><a href="#程序" class="headerlink" title="程序"></a>程序</h1><p>网上最常见的图就是它了，在看完理论后还是由些许的疑惑之处，比如位置编码如何实现，比如注意力机制具体如何执行，只能看代码来解决。</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs178A.png" alt></p><h2 id="MultiHeadAttention"><a href="#MultiHeadAttention" class="headerlink" title="MultiHeadAttention"></a>MultiHeadAttention</h2><ol><li>在这个类的初始化阶段，首先初始化 $W_Q,W_K,W_V$ 三个全连接层，输入维度和输出维度保持一致。假设输入维度是 512，有 8 个头；</li><li>计算 $Q,K,V$，大小是 <code>B, L, 8, 64</code>，毕竟有 8 个头。在 softmax 之后经过 0.1 的 dropout，最后在把这 8 个头 view 到一起，加上最开始的 $Q$</li></ol><h2 id="FeedForwardNetwork"><a href="#FeedForwardNetwork" class="headerlink" title="FeedForwardNetwork"></a>FeedForwardNetwork</h2><ol><li>经过全连接降维，而后 relu 激活并 dropout</li><li>在经过一个全连接，升到之前的维度，加上最开始的输入做一个残差，layer norm 后输出</li></ol><h2 id="PositionalEncoding"><a href="#PositionalEncoding" class="headerlink" title="PositionalEncoding"></a>PositionalEncoding</h2><p>这个就是生成一个 $200\times dim$ 的表，每次输入一个 $x$，查看 $x$ 的维度，从表中取到对应维度的数值，和 $A$ 直接相加。这个表采用的是 sin-cos 规则，使用了 sin 和 cos 函数的线性变换来提供给模型位置信息。</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs1HgI.png" alt></p><p>如上图所示，随着维度越来越大，周期变化会越来越慢，而产生一种包含位置信息的纹理。</p><h2 id="Encoder-Layer"><a href="#Encoder-Layer" class="headerlink" title="Encoder Layer"></a>Encoder Layer</h2><ol><li>输入 $x$ 经过 layer norm，经过 MultiHeadAttention，经过 dropout 得到 $y$，进行 $x+y$</li><li>将 $x+y$ 经过 layer norm，经过 FeedForwardNetwork，经过 dropout 得到 $y’$，最终的输出为 $x+y+y’$</li></ol><p>通常，这个 Encoder Layer 堆叠 6 次 （因为维度没有发生变化）得到 Encoder。Encoder 的输入是输入序列的 embedding，如果是最开始的输入，需要叠加位置 embedding 后 dropout-&gt;layer norm，在经过堆叠的 Encoder Layer。</p><h2 id="Decoder-Layer"><a href="#Decoder-Layer" class="headerlink" title="Decoder Layer"></a>Decoder Layer</h2><p>大部分内容和 Encoder Layer 一样，先将 target 进行 embedding 并叠加位置 embedding，然后 dropout-&gt;layer norm，得到解码输出。拿到 encoder 的输出和解码输出送入 decoder，再依次经过堆叠的 6 个 decoder layer 时（解码输出注意力机制，结果在和encoder 输出进行注意力）得到新的解码输出，上一个解码状态输出下一个状态的解码输入。</p><p>在拿到 decoder 的输出后，经过一个全连接层，将 dim 映射到 n_vocab。而 bert 的结构就是 transformer 的多个 Encoder 双向堆叠到一起：</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs1HgI.png" alt></p><p>其输入的 embedding 为：</p><p><img data-src="https://s1.ax1x.com/2022/03/28/qs1Xb8.jpg" alt></p><ul><li>Token Embeddings 是词向量，第一个单词是CLS标志，可以用于之后的分类任务，通过 embedding 层实现。如果句子很短，pad 为 0。</li><li>Segment Embeddings 用来区别两种句子，因为预训练还要做 NSP 任务，同样是 embedding 层。</li><li>Position Embeddings 和之前的 Transformer 不一样，不是三角函数而是学习出来的，非人工设定，而是 embedding 层。</li></ul><p>将这三者的相加作为输入，经过 layernorm 和 dropout 后输出。大概理论就是这些，不过它的预训练是真的靠谱，或者说，应用到具体任务，可以针对具体任务设计与训练。借着预训练，解释一下上面的符号，也是困扰我很久的东西。</p><p>之前一直不知道 CLS 这种东西是干什么的，直到看了代码才清楚，这个符号输入网络，最后一层的输出经过全连接和激活，得到的输出，所以这个符号对应位置的输出能用于下游分类任务。</p><p>此外，常用 bert 训练时会传入三个参数，<code>input_ids</code> 表示输入序列的原始 <code>token id</code>，即根据词表映射后的索引，<code>token_type_ids</code> 用于不同序列之间的分割，例如 <code>[0,0,0,0,1,1,1,1]</code> 用于区分前后不同的两个句子，形状为 <code>[src_len,batch_size]</code>。而最重要的 mask 值得细说：</p><h1 id="MASK"><a href="#MASK" class="headerlink" title="MASK"></a>MASK</h1><p>bert 有效的原因取决于它的预训练，比如 MLM（Mask language model） 和 NSP （Next sentence prediction），而这其中依赖的主要是 mask。</p><h2 id="处理非定长序列"><a href="#处理非定长序列" class="headerlink" title="处理非定长序列"></a>处理非定长序列</h2><p>在NLP中，文本一般是不定长的，所以在进行 batch训练之前，要先进行长度的统一，过长的句子可以通过truncating 截断到固定的长度，过短的句子可以通过 padding 增加到固定的长度，但是 padding 对应的字符只是为了统一长度，并没有实际的价值，因此希望在之后的计算中屏蔽它们，这时候就需要 Mask。此外，self-attention中，$Q$ 和 $K$ 在点积之后，需要先经过 mask 再进行 softmax，因此，对于要屏蔽的部分，mask之后的输出需要为负无穷，这样softmax之后输出才为0。</p><h2 id="辅助预训练"><a href="#辅助预训练" class="headerlink" title="辅助预训练"></a>辅助预训练</h2><p>做 MLM 预训练时，需要对句子进行 mask，使得模型看不到输入句子的单词。而后，其 label 为被 mask 掉单词的 id。由于 bert 本身的结构，由于预训练的时候，需要做 NSP 和 MLM，而 NSP 是二分类任务，MLM 是多分类任务，因此需要在 bert 上插入两个头分别实现这两个功能，前者就是将缺失的词汇预测回去，后者加入一个全连接输入 pooler output，判断句子是否为上下文。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/Models.py" target="_blank" rel="noopener">https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/Models.py</a></li><li><a href="https://qixinbo.info/2021/11/09/transformer/" target="_blank" rel="noopener">https://qixinbo.info/2021/11/09/transformer/</a></li><li><a href="https://www.ylkz.life/deeplearning/p10602241/" target="_blank" rel="noopener">https://www.ylkz.life/deeplearning/p10602241/</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;书接上文，因为参加 NLP 的比赛不知道什么是 bert 实在有点说不过去，于是花了三天时间看了下 bert 的基本概念和代码。不得不说，网上阳间的 bert 预训练代码太少了，大多是转载和 mark 之类没啥用的东西，属实是占据了搜索引擎的首页，占够了热度。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="NLP" scheme="https://muyuuuu.github.io/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>电商搜索召回</title>
    <link href="https://muyuuuu.github.io/2022/03/24/E-commerce-Search-Recall/"/>
    <id>https://muyuuuu.github.io/2022/03/24/E-commerce-Search-Recall/</id>
    <published>2022-03-24T03:50:43.000Z</published>
    <updated>2022-03-24T04:02:39.070Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img data-src="https://s1.ax1x.com/2022/03/24/q806pT.png" alt></p><p>阿里灵杰问天引擎电商搜索算法赛，来详细的记录一下参加这个天池比赛的流程以及我眼中的检索。因为之前从未涉足 NLP 领域，对 NLP 的了解也仅限于大二的时候看完《数学之美》手写过 TF-IDF 算法，我甚至不知道什么是 bert。</p><p>为了防止更多的人踩坑，能愉快的参与进来，于是决定把我的做法和程序分享出来，供参赛选手参考。之前在交流群里大概说了我的做法，私聊我的人我也都告诉了他们大概怎么去做，在那几天看到好多人在排名突飞猛进保送到了 0.2 分左右，甚至超过了我，还是比较开心的。这次做一个系统的分享，我甚至会告诉你怎么做是不对的，也希望你能有更创新的想法。<strong>走过路过给我的 github 点个 star 就行了，孩子要秋招了，这对我比较重要</strong>。（2022年3月20日，0.22的得分排名 21，3月24日，这个得分只能90名，大家太卷了）。</p><a id="more"></a><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>每天坐在电脑面前查方案、读论文、写代码，每天都加班到凌晨，提交了近一周的 0.0X 的成绩，提交这么多成绩意味着我写了更多的代码。可还是排名倒数，提交成绩的时候一度不敢看排行榜。还有很多反向优化的操作，期间写错代码的次数更是数不胜数。单刷比赛确实感觉不容易，尤其是对我这种到处借显卡的人。除了思路出错和程序出错，读论文和尝试代码的速度也不如组队，写完程序满心欢喜，出来结果满眼失望，经历了一周这样的反反复复，还好稳住了心态，坚持了下来。<del>大型诉苦现场。</del></p><p>在 21 年 7 月的时候，接到了某互联网研究院的项目。我这里简化一下，给定一张图片，在数据库中快速的检索出相似的图片。因为对面采用的方法是使用欧式距离一张一张的比对，速度很慢，我表示对这种做法很震惊，从大学随便找个本科生至少也知道不应该这么做。而检索任务可以分为两阶段，第一阶段为特征提取，第二阶段为特征比对。因为当时对面提供了原始数据提取后的特征，于是当时只完成了特征比对任务。</p><p>时隔半年，我又遇到了相同场景的任务，不过此时要解决的是第一阶段，如何将原始数据提取为一个好的表示，也是这个比赛的关键内容。本文从数据、损失、模型等多个方面来阐述一下如何才能 work，以及为什么能 work。</p><h1 id="关于向量索引"><a href="#关于向量索引" class="headerlink" title="关于向量索引"></a>关于向量索引</h1><p>从计算机视觉、自然语言与语音处理，这三大类的搜索与推荐，只要物品能够被向量化表示，就可能会看到向量索引的身影。因为向量索引不是本文的重点，这里就简单略过。可以参考我之前的文章：<a href="https://muyuuuu.github.io/2021/08/04/LSH-consine/">局部敏感哈希算法的C++实现</a>。</p><p>特征检索也叫向量索引，学术上对应的专有名词叫 Approximate Nearest Neighbor Search (ANNS)，即近似最近邻搜索。为什么是近似，而不是我们想要的精确？这就是精度与时间、算力资源的折中，采用了牺牲精度换取时间和空间的方式，从海量的样本中实时获取跟查询最相似的样本。一种高效的向量索引算法，应该满足3个基本条件：</p><ol><li>实时查询，支持海量（百亿、千亿级别）规模库量级的实时查询；</li><li>存储高效，要求构建的向量索引模型数据压缩比高，达到大幅缩减内存使占用的目的；</li><li>召回精度好，top@K有比较好的召回率；</li></ol><p>目前主要的方法有：基于树的索引（KD 树）、基于哈希的索引（局部敏感哈希方法）、矢量量化方法（OPQ）和基于图的索引（HNSW ）等。更多内容可以参考这里：<a href="https://yongyuan.name/blog/vector-ann-search.html" target="_blank" rel="noopener">https://yongyuan.name/blog/vector-ann-search.html</a></p><p>当时通过编写线程池、空间换时间等操作优化了他人开源的局部敏感哈希算法，修复了他人开源线程池存在的 bug，达到了令人满意的速度和精度。</p><h1 id="关于特征提取"><a href="#关于特征提取" class="headerlink" title="关于特征提取"></a>关于特征提取</h1><p>这是一个很经典也很实用的问题，在 2022 年的今天，随着对比学习的发展，特征提取也迎来了新的热度。而 TF-IDF（文本），SIFT（图像）等非深度学习提取特征的方法本文就不谈了。</p><p>如果使用深度学习来提取特征，如果是图像，模型可以使用 resnet 或者 ViT 等成功的模型，如果是本文，那么可以使用他人预训练好的 bert，我比较推荐 hugging face 和 Nezha。因为前些日子看了 CV 领域的自监督论文，随着模型结构越来越简单，改进集中体现在损失函数上，常用的就是 SimCLR 论文中的对比损失，也叫 InfoNCE 损失函数，而好巧不巧，SimCSE 也用的是这个损失函数。因此，详细来讨论一下这些损失函数，<del>我也没有足够的算力去调网络结构</del>。</p><h2 id="简单的优化距离"><a href="#简单的优化距离" class="headerlink" title="简单的优化距离"></a>简单的优化距离</h2><p>一开始我的想法很简单，既然标注了样本对，那么一个样本视为 anchor，人工标注的答案视为 positive，在数据库中随机选取一个视为 negative，当然在这里也可以进行在线难例挖掘，不过这种改进还是要在实现 baseline 之后再进行。</p><p>选择样本后，将提取到的特征进行标准化，优化 anchor 和 positive 的距离，使他们更加接近，使 anchor 和 negative 的距离更远。为了达到这个目标，在叠加一个交叉熵损失。距离可以选择余弦距离或者欧氏距离，我看 github 的开源项目大部分是余弦距离。具体示意图如下所示：</p><p><img data-src="https://s1.ax1x.com/2022/03/24/q8D2w9.png" alt></p><p>我想大部分人最开始的想法都是这样，但是这么做合理嘛？显然不合理。</p><ol><li>因为即使使用随机数，两者的余弦距离也会很高：<br><img data-src="https://s1.ax1x.com/2022/03/24/q8sADe.png" alt></li><li><blockquote><p>负样本对的目标都“过低”了，因为对于“困难样本”来说，虽然语义不同，但依然是“相似”，相似度不至于0甚至-1那么低，如果强行让它们往0、-1学，那么通常的后果就是造成过度学习，从而失去了泛化能力，又或者是优化过于困难，导致根本学不动。这句话引自科学空间。</p></blockquote></li></ol><p>别看这种损失函数差劲，triplet loss 也一样，面临模型坍塌损失持续为零的现象。至少我两次在工程中使用 triplet loss 都出现了这种情况，而 triplet loss 模型坍塌在 ECCV 2020 的一篇论文【Semi-Siamese Training for Shallow Face Learning】中也解释过，出现坍塌的场景均为：样本种类多，但是每类的样本很少。而实际证明，这种方案做出来的特征向量，检索的 MRR@10 指标很低，大概在 0.05 就是极限了。心态爆炸的一周：</p><p><img data-src="https://s1.ax1x.com/2022/03/24/q8yfFs.png" alt></p><h2 id="CoSENT-使用"><a href="#CoSENT-使用" class="headerlink" title="CoSENT 使用"></a>CoSENT 使用</h2><p>顺着这个思路，查到了苏神的 CoSENT，不得不说从思路到代码都很新颖。如果让我总结一下，那么就是只需要让负样本之间的距离比正样本之间的距离更远就好了，远多少让模型去决定。遂有如下的损失函数（以我的使用经验，损失值会收敛到 0.0X 左右，而且很稳定），而且这个损失函数的代码写法也很棒，建议仔细阅读源码。</p><p>\begin{equation}<br>\log \Biggl(1 + \sum_{(i,j)\in \Omega_{pos}, (k,l)\in \Omega_{neg}} e^{\lambda (\cos(x_k, x_l)-\cos(x_i, x_j))}\Biggr)<br>\end{equation}</p><p>在最开始的时候，我设置正样本和负样本的比例为 1：1，效果不怎么好，可以说是负优化。我又读了一些论文，发现公司的模型都有两部分，其中离线的部分数据量大且训练慢，这么做的好处是训练到更多的数据。那么思路来了，我把正负样本调节到 1：10，负样本并不随机选取，而是顺序遍历全部语料库，因为 1:10 的比例可以囊括所有的样本，这种方法训练时常线性增加，毕竟数据量大了，但是效果好了很多。在 3080 卡，batch size = 2 的情况下，训练时间为 36 小时，得分在 0.15 左右。</p><p><img data-src="https://s1.ax1x.com/2022/03/24/q8ct5d.png" alt></p><h2 id="SimCSE"><a href="#SimCSE" class="headerlink" title="SimCSE"></a>SimCSE</h2><p>SimCSE 是做 NLP 的，但是仔细看了它的损失函数，会发现这种对比损失在 CV 领域也是存在的，比如 SimCLR 算法。这篇论文的想法简单却有效：</p><ul><li>如果是无监督，同一个 batch 中，同一个句子经过模型两次会得到不同的结果视为正样本，不同句子视为负样本。使得正样本之间距离近，负样本之间距离远。</li><li>如果是有监督，那么输入三个句子，一个为 anchor，一个为 positive，一个为 negative，使同一个 batch 中，正样本距离近，负样本距离远。正样本只有同一个句子的 anchor 和 positive，负样本包括两部分：anchor 和 negative，当前 anchor 和其他句子的 positive 与 negative。</li></ul><p>因为 SimCSE 支持无监督和有监督训练，那么想法自然也就来了：我看之前的比赛，RMB 玩家为了使得模型更加贴合当前任务的数据集，都要进行 MLM 预训练，但这种方法很耗时间，不适合我这种到处借显卡的人。所以，我用 SimCSE 的无监督方法训练语料库，使得模型贴合当前任务，在这之后，使用标注数据再训练模型来完成任务，岂不完美。个人的参数是，无监督训练 1 个 epoch，有监督训练 5 个 epoch（损失还很大，没有收敛），得分在 0.2 左右，而且 batch 越大，得分越好。</p><p><img data-src="https://s1.ax1x.com/2022/03/24/q82rNQ.png" alt></p><p>那么 SimCSE 和 CoSENT 如此相似，都是不优化距离，为什么 SimCSE 简单有效呢？这得从他们的损失函数说起：</p><ul><li>对于 CoSENT，只让负样本的距离大于正样本的距离，但是：负样本对之间的不同，正样本对之间的不同却没有考虑到，也就是利用的信息少。</li><li>而 SimCSE 却没有这个缺陷，一个 anchor 会计算 batch 中全部句子的距离并 softmax，并经过交叉熵损失，仅仅将与 positive 的距离视为标签 1，其他视为距离 0。也就是说，读取 batch 含有的全部的信息，并抑制除正样本对外其他表示的距离，利用的信息更多。这也就是前文说的，为什么 batch 越大效果越好。</li></ul><h1 id="其他-trick"><a href="#其他-trick" class="headerlink" title="其他 trick"></a>其他 trick</h1><p>数据不做任何形式的预处理，为什么呢？因为 query 来自用户的输入，这里面存在特殊字符、语序错误、错别字等现象很正常，处理掉反而不好。至于 item 则是商品信息，大家逛淘宝也会发现，商品信息的标注文字几乎没有标点符号，而是很多形容词的堆叠，处理掉也不好。比如：优质木制办公室家用卧室可调接高度带灯光插座多功能折叠桌，它是病句吗？是的，但是就是要查找这样的句子，没必要纠错和预处理。（我没有做消融实验，也没有做数据预处理的实验，这一点仅凭个人分析）。</p><p>使用 pool output 而不是 max pool 最后的隐层输出，也许你会问：使用 max pool 捕获最强的特征，也就是捕获句子中最关键的词，只要词匹配对就匹配完成了。但是想一个例子：优质木制办公室家用卧室可调接高度带灯光插座多功能<strong>折叠桌</strong> 和 优质木制办公室家用卧室可调接高度带灯光插座多功能<strong>支架</strong>，如果使用 max pool，模型初始阶段很容易捕捉错关键词，但是 pool output 就不一样了，我是全部的语义表示，哪怕只有一个词不一样，输出的表示也不一样。（这个我做了实验）。</p><p>模型输出的最后经过 normalization（p=2），为什么呢？我们来看个例子：假设 anchor 的表示是 <code>[0.5, 0.8]</code>，positive 的表示是 <code>[0.6, 0.7]</code>，如果计算欧式距离，此时是 0.14。如果我标准化之后，anchor 的表示是 <code>[0.53, 0.85]</code>，positive 的表示是 <code>[0.65, 0.76]</code>，此时的欧氏距离是 0.15。那么有什么用呢？<code>[0.6, 0.7]</code> 和 <code>[0.5, 0.8]</code> 虽然在每一维都很接近，但是维度间的差距却很大，因此 <code>[0.6, 0.7]</code> 并不是很好的表示，需要加大惩罚力度。而 <code>[0.4, 0.9]</code> 这样的 positive 的表示在标准化之后，和 anchor 的距离是 0.14。可见，如果不标准化，那么 <code>[0.4, 0.9]</code> 和 <code>[0.6, 0.7]</code> 等价；如果标准化，<code>[0.6, 0.7]</code> 就不是一个好表示。（这个也做了实验）。</p><p>交互式匹配（我没有尝试）。这个灵感来自于早年间看过的一个<a href="https://github.com/Lanping-Tech/Multi-modal-Valuation-Forecast-System" target="_blank" rel="noopener">多模态项目</a>，这个项目通过评论和股票的时序数据作为两个模态来预测股价，两个模态进行了四不像的 <a href="https://github.com/Lanping-Tech/Multi-modal-Valuation-Forecast-System/blob/main/models/fusion.py#L37-L45" target="_blank" rel="noopener">transformer</a> 操作，我没理解这是为什么，两者进行了注意力的融合，但是取得了不错的结果。我在想，这次任务没办法进行交互式匹配，但我可以在模型的隐层进行这样的注意力融合，并增加一个分类的分支给注意力提供标签。</p><ul><li>Dense Passage Retrieval for Open-Domain Question Answering 这个论文我看了，想法粗暴简洁，和 SimCSE 差不多，但我没算力去尝试。</li><li>SWA（stochastic weight averaging），我查别人的比赛代码看到了它，效果看着不错。而且早年间用 mmdetection 的时候，确实发现模型在最后几个 epoch 涨分很厉害，但是调参不够友好，在最后阶段我会尝试，现阶段不考虑。</li><li>难例挖掘，我觉得付出和收益不成正比，没有尝试。</li><li>以上 trick 可以拿到一个不错的分数，另外其他的 trick 我会在初赛结束后分享，真心太卷了。</li></ul><h1 id="排雷"><a href="#排雷" class="headerlink" title="排雷"></a>排雷</h1><ul><li>双塔结构不要尝试了，即 query 一个全连接，doc 一个全连接，两者共享一个 bert，企图让两者的表示分开不混杂在一起，但效果奇差无比。</li><li>SimCSE 的损失函数在 CV 的自监督领域也有应用，我尝试把 CV 自监督领域最新的损失套用到这里，但结果很难收敛。</li></ul><h1 id="程序"><a href="#程序" class="headerlink" title="程序"></a>程序</h1><p><a href="https://github.com/muyuuuu/E-commerce-Search-Recall" target="_blank" rel="noopener">https://github.com/muyuuuu/E-commerce-Search-Recall</a></p><p>为什么不用 tensorflow？我 17 年 10 月学 tf 的时候，它那个 with session 和 placeholder 我实在理解不了，那会儿才大二，编程功底很差。19 年 4 月再去看的时候，编程风格和语法大改，好像是什么磁带？梯度一会儿有一会儿没有，混乱的api设计导致代码写的晕晕的，而且和 keras 的关系我也没理解。20 年 7 月的时候我又去看，仿佛完全 keras 化，<code>tf.keras</code> 我实在是被震惊到了，编程风格和语法又又又有改动。我怕我学会了它又出现了 <code>tf.torch</code>，20 年 10 月左右入坑 pytorch，API 稳定，用着也很顺手，也就放弃了学 tf。</p><p>不过还是建议各位用 tf，毕竟这个项目最终要落地到工程，这就涉及到部署和性能优化，不是简简单单实现一个算法就可以完美解决所有问题。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li>CoSENT：<a href="https://kexue.fm/archives/8847/comment-page-1" target="_blank" rel="noopener">https://kexue.fm/archives/8847/comment-page-1</a></li><li>Pytorch CoSENT 损失函数：<a href="https://github.com/shawroad/CoSENT_Pytorch" target="_blank" rel="noopener">https://github.com/shawroad/CoSENT_Pytorch</a></li><li>simcse 的有监督和无监督训练：<a href="https://github.com/zhengyanzhao1997/NLP-model/tree/main/model/model/Torch_model/SimCSE-Chinese" target="_blank" rel="noopener">https://github.com/zhengyanzhao1997/NLP-model/tree/main/model/model/Torch_model/SimCSE-Chinese</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://s1.ax1x.com/2022/03/24/q806pT.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;阿里灵杰问天引擎电商搜索算法赛，来详细的记录一下参加这个天池比赛的流程以及我眼中的检索。因为之前从未涉足 NLP 领域，对 NLP 的了解也仅限于大二的时候看完《数学之美》手写过 TF-IDF 算法，我甚至不知道什么是 bert。&lt;/p&gt;
&lt;p&gt;为了防止更多的人踩坑，能愉快的参与进来，于是决定把我的做法和程序分享出来，供参赛选手参考。之前在交流群里大概说了我的做法，私聊我的人我也都告诉了他们大概怎么去做，在那几天看到好多人在排名突飞猛进保送到了 0.2 分左右，甚至超过了我，还是比较开心的。这次做一个系统的分享，我甚至会告诉你怎么做是不对的，也希望你能有更创新的想法。&lt;strong&gt;走过路过给我的 github 点个 star 就行了，孩子要秋招了，这对我比较重要&lt;/strong&gt;。（2022年3月20日，0.22的得分排名 21，3月24日，这个得分只能90名，大家太卷了）。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DeepLearning" scheme="https://muyuuuu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>YOLOX 源码解析与小目标检测调优</title>
    <link href="https://muyuuuu.github.io/2022/02/26/yolox/"/>
    <id>https://muyuuuu.github.io/2022/02/26/yolox/</id>
    <published>2022-02-26T08:31:59.000Z</published>
    <updated>2022-02-27T03:05:58.619Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近用 yolox 的发现了一个很神奇的现象，简而言之 <code>yolox-tiny</code> 在单目标检测的效果比 <code>yolox-small</code> 好上很多（3.2mAP%），且 <code>yolox-small</code> 能大幅提升检测精度的方法到了 <code>yolox-tiny</code> 也不起作用了。网上很多 yolox 的解读基本都是翻译论文，没啥价值，还是决定仔细读一下代码，这大概也是全网第一份从源代码的角度解析 yolox 的文章。</p><p>阅读源码后发现 yolox 的 SimOTA 机制存在一些漏洞，并使用对应的方法调优。调优过程明确不采用的方案：增大模型规模、模型融合和其他消耗算力的方法，专注算法本身。</p><a id="more"></a><h1 id="Model-部分"><a href="#Model-部分" class="headerlink" title="Model 部分"></a>Model 部分</h1><p>和其他检测模型一样，<code>model</code> 分为 <code>backbone</code>，<code>neck</code> 和 <code>head</code>。</p><h2 id="backbone"><a href="#backbone" class="headerlink" title="backbone"></a>backbone</h2><p><code>backbone</code> 采用 <code>CSPDarkNet</code>，包括 <code>stem</code>，<code>dark2</code>，<code>dark3</code>，<code>dark4</code> 和 <code>dark5</code>。</p><ul><li>数据经过增强处理并缩放到 <code>640X640</code> 大小后进入 <code>stem</code> 完成图像通道的升维，从 <code>3</code> 通道提升到 <code>X</code> 通道，<code>X</code> 取决于 <code>backbone</code> 规模的 <code>width_factor</code> 参数。图像经过这一层之前，会被均匀切分为左上、右上、左下和右下四个区域并按通道拼接得到 <code>160X160X12</code> 的数据，也就是 12 个通道，每个通道的图像大小占据原图像大小的 <code>1/4</code>，在经过卷积、<code>BN</code> 层和激活层，得到输出。</li><li><code>stem</code> 的输出进入 <code>dark2</code>，经过一个卷积模块，维度提升一倍后尺寸减半。而后经过 <code>CSPLayer</code>，<code>CSPLayer</code> 的结构和残差网络相似，一个分支只对输入卷积一次，另一个分支进行深度特征提取，深度的层数取决于 <code>backbone</code> 的 <code>depth_factor</code> 参数，而后两个分支的输出按照通道数拼接到一起，完成升维。</li><li><code>dark3, dark4, dark5</code> 的东西和 <code>dark2</code> 一致，无非是尺寸减半，通道数翻倍，同理得到 <code>dark3, dark4, dark5</code> 的输出。</li></ul><p><img data-src="https://s4.ax1x.com/2022/02/26/bZ86nH.png" alt></p><p>这里补充一下：</p><ul><li><code>dark3</code> 的输出维度：<code>256X80X80</code></li><li><code>dark4</code> 的输出维度：<code>512X40X30</code></li><li><code>dark5</code> 的输出维度：<code>1024X20X20</code></li></ul><h2 id="neck"><a href="#neck" class="headerlink" title="neck"></a>neck</h2><p>获取 <code>backbone</code> 的 <code>dark3, dark4, dark5</code> 的输出作为输入。这里用文字描述的话太复杂了，简单的画图展示一下大概结构，精细的结构还是要看源代码：</p><p><img data-src="https://s4.ax1x.com/2022/02/26/bZ8gHA.png" alt></p><p>也就是说，这三个输出都融合了模型深层的语义特征和模型浅层的细节特征。</p><h2 id="head"><a href="#head" class="headerlink" title="head"></a>head</h2><p>因为 <code>neck</code> 有三组输出，所以 <code>head</code> 对 <code>neck</code> 的每一组输出都要进行处理。对每一个输入经过不同的 <code>stem</code> 把通道数降维到 256，而后接入解耦的任务分支，包括分类（<code>cls</code>）、位置框（<code>reg</code>）和前背景（<code>obj</code>）三个网络。</p><p>分类网络的输出通道数是类别数，这里假设为 2，回归网络的输出通道数是 4，负责预测中心点坐标和高宽尺寸，前背景网络的输出通道数是 1，因此输出的通道数是 2+4+1=7。将这三个网络的输出然后拼接到一起，放到一个列表中。因此，<code>head</code> 部分得到的输出为三组数据：<code>7X80X80, 7X40X40, 7X20X20</code>。以 <code>7X80X80</code> 为例，表示预测了 <code>80X80</code> 个目标，每个目标包括位置、类别和前背景共 7 个参数。</p><p><img data-src="https://s4.ax1x.com/2022/02/26/bZ8cBd.png" alt></p><h1 id="训练部分"><a href="#训练部分" class="headerlink" title="训练部分"></a>训练部分</h1><p>这一部分是难点，或者说，是任何目标检测算法的实现难点，代码量也是最大。</p><h2 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h2><p>在这一部分，将对 <code>head</code> 的三个输出进行一些转换并生成对应的 <code>grid</code> 信息，将预测输出对应到图像中的实际位置。<code>grid</code> 可以理解为特征点的位置吧，是固定的，如下图所示黑色的那一个个格子（其他颜色不用看，我实在找不到类似的图了）：</p><p><img data-src="https://s4.ax1x.com/2022/02/27/beHtnP.png" alt></p><p>这一部分大概分以下步骤：</p><ol><li>获取输出特征的的宽度和高度，如 80 和 80，或者 40 和 40，那么就生成对应的 <code>grid</code>，如 [0, 1] [0, 2] … [80, 80] 共 6400 个，维度是 [1, 6400, 2]</li><li>将预测结果 <code>reshape</code> 成 <code>Batch, HxW, C</code> 大小，坐标的 <code>x</code> 和 <code>y</code> 加上 <code>grid</code> 会映射到每个预测特征点的中心位置，在乘以 8，也就是理想情况下位置信息的运算结果会在 640 X 640 之间，也就是图像上目标的中心点</li><li>计算 <code>w</code> 和 <code>h</code> 的 $e$ 次方，再乘以 8，得到目标框的高度和宽度。此时返回得到的 <code>grid</code> 和变换过后的 <code>output</code>。（80 对应的扩张步是 8，40 对应的扩张步是 16，20 对应的扩张步是 32）</li></ol><p>将每一个输出经过上面 3 个步骤的处理后，按照 <code>dim=1</code> 拼接到一起，也就是会得到 <code>Batch, 8400, 7</code> 的输出。（80X80 + 40X40 + 20X20 = 8400）。</p><h2 id="计算损失"><a href="#计算损失" class="headerlink" title="计算损失"></a>计算损失</h2><p>针对 <code>batch</code> 中的每一个图像开始处理：</p><ul><li>如果真实标签显示这个图像没有目标，全部真实标签就是清一色的 0，分类个数全部是 0，位置参数是 4 个 0，有无目标是 8400 个 0，<code>fg_mask</code> 全部是 <code>false</code>。（<code>fg_mask</code> 的用途后面会讲）</li><li>否则，取出这个图像包含的全部真实目标框，与预测结果进行 SimOTA 样本分配，为预测结果分配标签，或者说为标签分配预测结果，因为 8400 个预测结果不可能同时参与训练，只选择部分样本视为正样本进行训练。</li></ul><h3 id="SimOTA"><a href="#SimOTA" class="headerlink" title="SimOTA"></a>SimOTA</h3><p>首先计算真实框覆盖的 <code>grid</code> 中心点，将这些 <code>grid</code> 中心点称为 <code>fg_mask</code> 也就是正样本，从所有的预测结果中通过 <code>fg_mask</code> 把正样本取出来，包括位置，类别和前背景。此外，选择落入真实目标框的周围的预测结果并记录下来，周围的度量方式是：当前特征点乘以 2.5 倍的步长所覆盖的格子。</p><ul><li>之后计算选中的位置和真实位置的 <code>iou</code> 得分和损失；</li><li>将类别的输出激活后和 <code>obj</code> 的激活输出相乘得到类别得分，以此得到类别损失；</li><li>将没有被选中的预测结果视为负样本，也就是上面没有落入真实目标框及周围的预测结果视为预测失败，计算预测失败的损失，有一个预测结果不在，损失就是1，有 100 个不在，就是 100，然后计算这三个损失的和。</li></ul><p>之后进行动态 k 分配，这里的 k 计算比较简单，在 10 和上一步骤选中的 <code>fg_mask</code> 数量取最小值就是 <code>k</code>，给每个真实框选取损失最小的 <code>k</code> 个预测结果。如果当某一个特征点指向多个真实框的时候，选取 <code>cost</code> 最小的真实框，之后对 <code>fg_mask</code> 进行更新。</p><h3 id="计算损失-1"><a href="#计算损失-1" class="headerlink" title="计算损失"></a>计算损失</h3><ul><li><code>obj</code> 损失是全部的预测结果和动态 k 分配后得到的 <code>fg_mask</code> 做交叉熵，提升检测到目标的能力</li><li><code>cls</code> 损失基于 <code>fg_mask</code> 选中的预测结果，将类别的 <code>one-hot</code> 向量与正样本和真实框的 iou 做乘积视为目标。比如预测框和真实框的 iou 是 0.4，那么对应的类别得分就是 0.4，毕竟相交面积小。预测结果和目标做交叉熵损失</li><li><code>reg</code> 损失是就是预测盒子和真实盒子的 iou 损失</li></ul><h1 id="问题分析与调优"><a href="#问题分析与调优" class="headerlink" title="问题分析与调优"></a>问题分析与调优</h1><p>如何解释开头的问题以及如何调优呢？通过一路 <code>debug</code> 找到了一些问题，我目前只发现了一点点问题，<del>等我彻底解决完毕回来填坑（因为又又又摸不到显卡了）。</del></p><ul><li>第一点，由于是单目标检测任务，也就是说只有一个目标，那么小模型参数少，很容易聚焦和收敛；而大模型参数大，解空间也会更多，相对小模型难以探索到更好的解，因此一些常见的 <code>trick</code> （比如预训练 <code>backbone</code>）才会有效的提升大模型的检测效果，而对小模型而言，参数少，搜索空间小，很容易找到更优的解，因此一些 <code>trick</code> 并不会起到很大的作用。</li><li>第二点，由于检测任务绝大多数目标是小目标，而 yolox-tiny 模型尺寸小，输出的通道数也少，底层的特征信息的保留程度好于大模型，因为模型越深，对图像细节的保留程度就越低。</li><li>第三点，也是最重要的一点，由于 YOLOX 选取正样本的机制是：预测结果落入真实框，或者落入真实框的周围，这些落入真实框周围的正样本在模型初期会侥幸存活下来并通过 <code>SimOTA</code> ，但是，由于大部分都是小目标，会导致预测结果和真实目标毫不相交的场景，这就 <code>reg</code> 分支的 IoU Loss 不起作用，我们换成 CIoU Loss 就可以了。</li></ul><p><img data-src="https://s4.ax1x.com/2022/02/27/beHJXt.png" alt></p><p>如图所示，红色是真实框，绿色是落入真实框周围的预测结果（正样本），灰色表示不参与训练。可以看到，由于目标较小，预测结果和真实标签毫不相交，IoU Loss 的损失是 0，这显然是不合理的，应该是一个很大的数，而 CIoU Loss 能很好的解决这一点。</p><p>如果你要从发论文的角度调优 yolox，那么建议改动它的 SimOTA 机制，但是这也只能是为了毕业而发的一篇普通的论文，还远远达不到 yolov6 问世的高度。如果是工程的角度，那么 CIoU Loss 会很适合你。结果也显示，使用 CIoU Loss 的 mAP 要远远高于不使用和 yolox-tiny，提升 4.1 的 mAP。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近用 yolox 的发现了一个很神奇的现象，简而言之 &lt;code&gt;yolox-tiny&lt;/code&gt; 在单目标检测的效果比 &lt;code&gt;yolox-small&lt;/code&gt; 好上很多（3.2mAP%），且 &lt;code&gt;yolox-small&lt;/code&gt; 能大幅提升检测精度的方法到了 &lt;code&gt;yolox-tiny&lt;/code&gt; 也不起作用了。网上很多 yolox 的解读基本都是翻译论文，没啥价值，还是决定仔细读一下代码，这大概也是全网第一份从源代码的角度解析 yolox 的文章。&lt;/p&gt;
&lt;p&gt;阅读源码后发现 yolox 的 SimOTA 机制存在一些漏洞，并使用对应的方法调优。调优过程明确不采用的方案：增大模型规模、模型融合和其他消耗算力的方法，专注算法本身。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>PyQt 打造的图像预览软件</title>
    <link href="https://muyuuuu.github.io/2022/02/12/pyqt5-view-image/"/>
    <id>https://muyuuuu.github.io/2022/02/12/pyqt5-view-image/</id>
    <published>2022-02-12T10:08:59.000Z</published>
    <updated>2022-02-12T10:26:30.630Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>寒假某天下午的突发奇想，想实现一款图像预览软件。大概思路是：在软件的左侧点击图片，软件的右侧就能实时预览图片，因为感觉这个功能有一定的应用场景，所以实现了一下。</p><p><img data-src="https://s4.ax1x.com/2022/02/12/H0ywWQ.png" alt></p><a id="more"></a><p>简单说一下设计思路吧，代码没啥难度：</p><ol><li>使用 GridLayout 手动布局提升美感，左侧是文件列表，右侧是图片预览</li><li>当从左侧文件列表点击文件时，判断点击的文件是否为图像类型，如果是，右侧显示图像。关于如何显示高清图像，可以参考我之前的<a href="https://muyuuuu.github.io/2021/04/10/pyqt5-load-huge-image/">博客</a></li><li>文件列表使用 <code>QTreeView</code> 和 <code>QListView</code> 实现，<code>QTreeView</code> 负责显示文件夹层级关系，<code>QListView</code> 负责显示文件。两者都挂载文件模型。</li><li><del>Qt 的使用就是学会基础操作后大量翻阅官方库的过程。</del></li></ol><p><img data-src="https://s4.ax1x.com/2022/02/12/H0sJ5F.gif" alt></p><p>可以看到里面还有加载模型、识别等按钮，也能猜出来这是深度学习应用的软件。</p><h1 id="程序"><a href="#程序" class="headerlink" title="程序"></a>程序</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys, time</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtWidgets <span class="keyword">import</span> (QMainWindow, QWidget, QGridLayout, QApplication,</span><br><span class="line">                             QPushButton, QStatusBar, QProgressBar, QLabel,</span><br><span class="line">                             QTreeView, QListView, QFileSystemModel, QLineEdit,</span><br><span class="line">                             QInputDialog, QFileDialog, QTextEdit, QMessageBox)</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtCore <span class="keyword">import</span> QDir</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PyQt5.QtGui <span class="keyword">import</span> QPixmap, QFont</span><br><span class="line"><span class="keyword">from</span> PyQt5.Qt <span class="keyword">import</span> QSize, QImageReader</span><br><span class="line"><span class="keyword">import</span> qdarkstyle</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SecondWindow</span><span class="params">(QWidget)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, msg)</span>:</span></span><br><span class="line">        super(SecondWindow, self).__init__()</span><br><span class="line">        self.resize(<span class="number">400</span>, <span class="number">400</span>)</span><br><span class="line">        self.move(<span class="number">200</span>, <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">        layout = QGridLayout()</span><br><span class="line">        self.info = QTextEdit()</span><br><span class="line">        layout.addWidget(self.info)</span><br><span class="line">        self.info.setText(msg)</span><br><span class="line">        self.setLayout(layout)</span><br><span class="line">        self.setWindowTitle(<span class="string">'详细信息'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mainwindow</span><span class="params">(QMainWindow)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(mainwindow, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.setWindowTitle(<span class="string">"天然草地类型识别系统"</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 显示正在加载</span></span><br><span class="line">        self.status = QStatusBar()</span><br><span class="line">        self.status.setStyleSheet(<span class="string">'QStatusBar::item &#123;border: none;&#125;'</span>)</span><br><span class="line">        self.setStatusBar(self.status)</span><br><span class="line"></span><br><span class="line">        self.progressBar = QProgressBar()</span><br><span class="line">        self.label = QLabel()</span><br><span class="line">        self.label.setText(<span class="string">"加载中，请稍后... "</span>)</span><br><span class="line">        self.status.addPermanentWidget(self.label, stretch=<span class="number">2</span>)</span><br><span class="line">        self.status.addPermanentWidget(self.progressBar, stretch=<span class="number">4</span>)</span><br><span class="line">        self.progressBar.setRange(<span class="number">0</span>, <span class="number">100</span>)</span><br><span class="line">        self.progressBar.setMinimum(<span class="number">0</span>)</span><br><span class="line">        self.progressBar.setMaximum(<span class="number">0</span>)</span><br><span class="line">        self.statusBar().setVisible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        self.setMinimumSize(<span class="number">1500</span>, <span class="number">720</span>)</span><br><span class="line"></span><br><span class="line">        layout = QGridLayout()</span><br><span class="line">        w = QWidget()</span><br><span class="line">        w.setLayout(layout)</span><br><span class="line">        self.setCentralWidget(w)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 文件树</span></span><br><span class="line">        self.treeview = QTreeView()</span><br><span class="line">        self.listview = QListView()</span><br><span class="line">        layout.addWidget(self.treeview, <span class="number">0</span>, <span class="number">0</span>, <span class="number">7</span>, <span class="number">2</span>)</span><br><span class="line">        layout.addWidget(self.listview, <span class="number">0</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        path = QDir.rootPath()</span><br><span class="line"></span><br><span class="line">        self.dirModel = QFileSystemModel()</span><br><span class="line">        self.dirModel.setRootPath(QDir.rootPath())</span><br><span class="line">        self.dirModel.setFilter(QDir.NoDotAndDotDot | QDir.AllDirs)</span><br><span class="line"></span><br><span class="line">        self.fileModel = QFileSystemModel()</span><br><span class="line">        self.fileModel.setFilter(QDir.NoDotAndDotDot | QDir.Files)</span><br><span class="line"></span><br><span class="line">        self.treeview.setModel(self.dirModel)</span><br><span class="line">        self.listview.setModel(self.fileModel)</span><br><span class="line"></span><br><span class="line">        self.treeview.setRootIndex(self.dirModel.index(path))</span><br><span class="line">        self.listview.setRootIndex(self.fileModel.index(path))</span><br><span class="line"></span><br><span class="line">        self.treeview.clicked.connect(self.on_clicked)</span><br><span class="line">        self.listview.clicked.connect(self.run_model)</span><br><span class="line"></span><br><span class="line">        self.treeview.hideColumn(<span class="number">1</span>)</span><br><span class="line">        self.treeview.hideColumn(<span class="number">2</span>)</span><br><span class="line">        self.treeview.hideColumn(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 显示图片</span></span><br><span class="line">        self.image_label = QLabel()</span><br><span class="line">        self.image_label.setMinimumSize(<span class="number">800</span>, <span class="number">700</span>)</span><br><span class="line">        layout.addWidget(self.image_label, <span class="number">0</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 加载模型</span></span><br><span class="line">        btn = QPushButton(<span class="string">"加载模型"</span>)</span><br><span class="line">        layout.addWidget(btn, <span class="number">7</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        btn.clicked.connect(self.load_model)</span><br><span class="line"></span><br><span class="line">        more_btn = QPushButton(<span class="string">"详细信息"</span>)</span><br><span class="line">        layout.addWidget(more_btn, <span class="number">7</span>, <span class="number">14</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        more_btn.clicked.connect(self.show_info)</span><br><span class="line"></span><br><span class="line">        reco_btn = QPushButton(<span class="string">"识别"</span>)</span><br><span class="line">        layout.addWidget(reco_btn, <span class="number">7</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        reco_btn.clicked.connect(self.predict)</span><br><span class="line"></span><br><span class="line">        clear_btn = QPushButton(<span class="string">"清空"</span>)</span><br><span class="line">        layout.addWidget(clear_btn, <span class="number">7</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        clear_btn.clicked.connect(self.clear)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 预测结果</span></span><br><span class="line">        self.res = QLineEdit()</span><br><span class="line">        self.res.setReadOnly(<span class="literal">True</span>)</span><br><span class="line">        layout.addWidget(self.res, <span class="number">7</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        self.model = <span class="literal">None</span></span><br><span class="line">        self.fname = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clear</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.res.clear()</span><br><span class="line">        self.image_label.setVisible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">show_info</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.fname <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 调用你的图片信息代码，我这里没对应的 excel</span></span><br><span class="line">            <span class="comment"># 详细信息赋值给 msg 即可</span></span><br><span class="line">            msg = <span class="string">"详细信息"</span></span><br><span class="line">            self.child = SecondWindow(msg)</span><br><span class="line">            self.child.show()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 当选中图片的时候，直接进行预测</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run_model</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.image_label.setVisible(<span class="literal">True</span>)</span><br><span class="line">        idx = self.listview.currentIndex()</span><br><span class="line">        fname = self.fileModel.filePath(idx)</span><br><span class="line">        img_type = fname.split(<span class="string">'.'</span>)[<span class="number">-1</span>]</span><br><span class="line">        <span class="comment"># 判断下是不是图片</span></span><br><span class="line">        <span class="keyword">if</span> img_type <span class="keyword">in</span> [<span class="string">"png"</span>, <span class="string">"jpg"</span>]:</span><br><span class="line">            img = QImageReader(fname)</span><br><span class="line">            scale = self.image_label.width() / img.size().width()</span><br><span class="line">            height = int(img.size().height() * scale)</span><br><span class="line">            img.setScaledSize(QSize(self.image_label.width(), height))</span><br><span class="line">            img = img.read()</span><br><span class="line">            pixmap = QPixmap(img)</span><br><span class="line">            self.image_label.setPixmap(pixmap)</span><br><span class="line">            self.fname = fname</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 测试代码放在这里</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.fname <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># y = self.model(x)</span></span><br><span class="line">            <span class="comment"># y = str(y)</span></span><br><span class="line">            self.res.setText(<span class="string">"cls 1: 0.9, cls 2: 0.8, cls 3: 0.9"</span>)</span><br><span class="line">        <span class="comment"># res = self.model(img)</span></span><br><span class="line">        <span class="comment"># self.res.setText(res)</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            msgBox = QMessageBox()</span><br><span class="line">            msgBox.setIcon(QMessageBox.Warning)</span><br><span class="line">            msgBox.warning(self, <span class="string">"警告"</span>, <span class="string">"请选择图片后再预测"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_clicked</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        path = self.dirModel.fileInfo(index).absoluteFilePath()</span><br><span class="line">        self.listview.setRootIndex(self.fileModel.setRootPath(path))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载模型的代码</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_model</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.status.setVisible(<span class="literal">True</span>)</span><br><span class="line">        file_filter = <span class="string">'PKL File (*.pt *.pth *.pkl)'</span></span><br><span class="line">        response = QFileDialog.getOpenFileName(</span><br><span class="line">            parent=self,</span><br><span class="line">            caption=<span class="string">'Select a data file'</span>,</span><br><span class="line">            directory=os.getcwd(),</span><br><span class="line">            filter=file_filter,</span><br><span class="line">        )</span><br><span class="line">        pth_file, _ = response</span><br><span class="line">        <span class="comment"># torch load model</span></span><br><span class="line">        <span class="comment"># self.model.load_state_dict(torch.load(pth_file))</span></span><br><span class="line">        self.status.setVisible(<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    app = QApplication([])</span><br><span class="line">    dark_stylesheet = qdarkstyle.load_stylesheet_pyqt5()</span><br><span class="line">    <span class="comment"># 如果想美化就取消注释</span></span><br><span class="line">    <span class="comment"># app.setStyleSheet(dark_stylesheet)</span></span><br><span class="line">    m = mainwindow()</span><br><span class="line">    m.show()</span><br><span class="line">    sys.exit(app.exec())</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;寒假某天下午的突发奇想，想实现一款图像预览软件。大概思路是：在软件的左侧点击图片，软件的右侧就能实时预览图片，因为感觉这个功能有一定的应用场景，所以实现了一下。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s4.ax1x.com/2022/02/12/H0ywWQ.png&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="GUI" scheme="https://muyuuuu.github.io/tags/GUI/"/>
    
  </entry>
  
  <entry>
    <title>算是一个陈述句流水帐的年终总结吧</title>
    <link href="https://muyuuuu.github.io/2022/02/04/2021/"/>
    <id>https://muyuuuu.github.io/2022/02/04/2021/</id>
    <published>2022-02-04T09:44:53.000Z</published>
    <updated>2022-02-05T11:32:15.201Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>时间有些晚了，选一个词来描述今年的话，现实魔幻主义，孤魂野鬼又一年。现实比魔幻还要魔幻，魔幻比现实还要现实。</p><a id="more"></a><p>还是那句话，悲观是我的状态，努力是我的态度，不冲突。</p><ul><li><p>1 月，那会儿在期末考试吧，并趁考试的时候忙里偷闲学完了操作系统和 C++。至于为什么研究生在考试的时候才是一年中最清闲的时光，懂得都懂。大概又说错了一些话，又错过了，以后只在适当的时候和懂得人去说。也是在这时候完成的心态的转变，放弃科研。这个月看完了火影，仿佛自己是宇智波，被生活的重压的反噬了。</p></li><li><p>2 月，忘记了，大概是返校，选课。有一门老师的课极度恶心，又是说论文多么多么重要，不注重实践的东西反手退课，我至今羡慕学完计算机原理能写 RISC 五级流水的人。这个月印象最深的是初次尝试去淘宝开代码店了，这也是今年值得记录的大事之一。实在穷的揭不开锅，接近没钱吃饭的程度，实在没办法。接的前两个业务是 LaTeX 排版的，第一笔业务挣了 20 块钱，我当时在想我能免费用 5 次学校的洗衣机。我成为了我曾经讨厌的人，也许并不是。</p></li><li><p>3 月，连夜参加了同学的婚礼。同学在大学所在地结婚，正好我大学毕业很匆忙，没和同学告别，趁此机会好多同学都回来了，大家一起吃个饭，一起聊聊天，弥补当面没有告别的遗憾。不像上次，这次分别没有哭的稀里哗啦。</p></li><li><p>4 月，同学来了西安，和他一起在西安、咸阳转了转，是我第一次正经在西安旅游吧。之后爬了华山，和她矛盾愈演愈烈，不喜欢阴阳的聊天，索性不聊了。这个月应该是接业务的顶峰，啥都接，凌晨一点写代码头很晕的那种，不上课不科研一直在陪客户，很累，像个孤魂野鬼。在某一天，听了很久的音乐，推了所有的业务，退款道歉，准备收手。</p></li><li><p>5 月，学了下 mmdetection，shell 和设计模式，之后就是研三毕业的节奏占据实验室的主流，真好，解脱了。业务并没有彻底放弃，一个月一两笔，多了就不接了，第一点没啥营养，第二点我没钱吃饭。</p></li><li><p>6 月，准备期末？和几个客户确定了长期关系。</p></li><li><p>7 月，暑假放 10 天，但接了个华为的项目，旅行计划泡汤。想临时冲一下项目，加上暑假回去也没想见的人，索性留校了。后续又自己学了一些无监督、高维索引和线程池的东西，自己把项目解决了。</p></li><li><p>8 月，被折腾去投论文，很累，累的原因倒不是多难，而是这个字体加粗，这里行间距，这里符号替换，和换成及，去掉空格，加粗，换成楷体，真的很没意思。开始打游戏缓解压力，一天一天又一天。</p></li><li><p>9 月，在华为项目基础上又做了上游的开发，算是体验了一下一整套系统吧，然后打游戏，打游戏，打游戏…… 置身现实魔幻主义，被折腾的很累。</p></li><li><p>10 月，又被抓去投论文，真的很没意思。不是落地的项目，只在玩具数据集上追求比 A 高 2 个点，比 B 高 3 个点，比 C 高 10 个点，仿佛前人的工作都是垃圾，自己论文无与伦比的新颖，晚诞生一年就是这个世界的损失，用各种词汇体现论文的创新，但本来就是很简单的东西。因此对这种东西深恶痛绝。一个同学考上了清华，给我介绍了一笔大业务，会持续到明年 4 月吧，能写到简历里。所以除了老客户的业务，新业务都不接了。</p></li><li><p>11 月，接到了第二个华为的项目，补了一下 C++ 的高级特性，然后就去开发了。体验了面向生产环境该如何编程，如何设计数据结构，代码如何检验，开发之余还是打游戏，接业务。仿佛脱离了现实进入了魔幻。</p></li><li><p>12 月，大四的师弟来了，帮着我搞项目，也请了几顿饭，我又又又被抓去投论文了，真的恶心，持续性头晕。其中一点是，做深度学习但没有显卡，实验得不到保障。时隔 8 个月，和他关系有所缓和，他也理解了我所处环境的苦衷，终于能好好说话了，不容易。我也尝试不再去抱怨，可总是没话题去说，也许随缘吧。开始不带手机回宿舍，好好睡一觉。买了把静电容键盘。</p></li></ul><p>生活总是这样，不给半点希望的星光，把人压的苟延残喘却无可奈何，难过的时候都要去 b 站算卦占卜来看一下接下来的日子走势，企图获得一星半点的慰籍。可能是自己想太多，进入了精神内耗，经历过很多难熬的日子，似乎也不差这几百天。可能有什么办法呢？今年就要秋招了，努力一下，等找完工作稳定下来，好好休息吧，不再去想乱七八糟的东西。</p><p>我觉得师兄有句话很好，毕业了绝对不能立刻买房，先玩几年。学校里跟个孙子似的，没必要一毕业立刻成为孙子，每天一挣钱欠银行几百块钱的日子也不好受。虽然早晚是孙子，但先玩几年，快乐几年再说。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;时间有些晚了，选一个词来描述今年的话，现实魔幻主义，孤魂野鬼又一年。现实比魔幻还要魔幻，魔幻比现实还要现实。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Life" scheme="https://muyuuuu.github.io/tags/Life/"/>
    
  </entry>
  
  <entry>
    <title>半监督浅显入门</title>
    <link href="https://muyuuuu.github.io/2022/01/30/semi-intro/"/>
    <id>https://muyuuuu.github.io/2022/01/30/semi-intro/</id>
    <published>2022-01-30T12:15:16.000Z</published>
    <updated>2022-01-30T12:21:34.647Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>寒假开始前还是把在学校里遗留的工作先搞完，所接项目的目标是实现半监督语义分割。既然是半监督，就先来看一下半监督的经典论文，我选了经典的、结构相似的三篇论文。</p><p>第一篇是：NIPS 2017 的 Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results，因为我发现伪标签相关的论文或多或少有它的影子。</p><p>第二篇是：ICCV 2021 的 End-to-End Semi-Supervised Object Detection with Soft Teacher，微软出品的半监督目标检测，质量上还是比较让人相信的，且语义分割也可以借鉴目标检测的东西。</p><p>第三篇是：ECCV 2021 的 Semi-supervised Semantic Segmentation via Strong-weak Dual-branch Network，因为搜半监督语义分割，最新的进展论文就是它了。</p><p>文章最后有代码实现。<del>才发现好久没更新博客了。</del></p><a id="more"></a><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>因为现实世界标注数据比较昂贵，但无标注的数据很容易获得，那么基于少量标注数据和大量无标注数据的训练，也就是半监督训练也成为了研究的热门。简单来说，半监督分为两类：</p><ul><li>伪标签，用有标签数据训练一个分类器，然后用这个分类器对无标签数据进行分类，这样就会产生伪标签(<code>pseudo label</code>)，挑选其中认为分类正确的无标签样本，把选出来的无标签样本用来训练分类器，这样就使用了无标签数据。</li><li>协同训练，假设每个数据可以从不同的视角（对应到 <code>torch</code> 的话，就是不同的 <code>torchvision.transform</code>）进行分类。不同视角可以训练出不同的分类器，分类器对不同视角的图片分类结果应该相同。然后用这些从不同视角训练出来的分类器对无标签样本进行分类，再选出认为可信的无标签样本加入训练集中。由于这些分类器从不同视角训练出来的，可以形成一种互补，而提高分类精度，就如同从不同视角可以更好地理解事物一样。</li></ul><h1 id="半监督图像分类"><a href="#半监督图像分类" class="headerlink" title="半监督图像分类"></a>半监督图像分类</h1><p>这篇论文还是很简单的：</p><p><img data-src="https://s4.ax1x.com/2022/01/30/HC2TpQ.png" alt></p><p>但论文中的训练过程写的不是很清楚，看了<a href="https://github.com/CuriousAI/mean-teacher/tree/546348ff863c998c26be4339021425df973b4a36/pytorch" target="_blank" rel="noopener">代码</a>了解了完整的训练流程：</p><ul><li>有标签输入学生的预测输出和 <code>one-hot label</code> 进行对比，这个是分类损失；和教师的输出使用 <code>consistency cost</code> 进行对比，论文中用的是两个模型输出的二阶范数，代码提供了 <code>mse</code> 和 <code>kl</code> 散度两个损失。第二个 <code>loss</code> 根据 <code>epoch</code> 调整权重，<code>epoch</code> 越大，权重越大。</li><li>两个权重相加，反向传播更新学生的模型，<code>exponential moving average (EMA)</code> 更新教师模型，能在每个 <code>batch</code> 后聚合信息而不是每个 <code>epoch</code> 后才聚合信息，这样能获取更好的表示。</li><li>最后使用教师模型进行预测。</li></ul><p>至于<a href="https://github.com/CuriousAI/mean-teacher/blob/546348ff863c998c26be4339021425df973b4a36/pytorch/mean_teacher/data.py#L72-L79" target="_blank" rel="noopener">无标签数据部分</a>，就是一批数据作两次变换，第一组视为有标签，第二组数视为无标签。</p><p>这篇论文的思想可以总结为：作为教师，用来产生学生学习时的目标；作为学生，则利用教师模型产生的目标来进行学习。</p><h1 id="半监督目标检测"><a href="#半监督目标检测" class="headerlink" title="半监督目标检测"></a>半监督目标检测</h1><p>如果说分类图像的数据难以标注，那么目标检测的数据更加难以标注。</p><p>半监督目标检测的重点是：提升伪标签质量，伪标签质量好了也利于后续的训练。传统的半监督目标检测是多阶段方法：使用标签数据训练一个检测器，之后对无标签数据生成伪标签，再次训练检测器。但是也很容易受到限制：如何保证伪标签的质量？标签数据和无标签数据分布不一致怎么办？且不是端到端的，多年前写 <code>MTCNN</code> 的时候就感觉不是端到端就很不方便。</p><p>同样类似 <code>mean teacher</code> 的结构，创建两个模型，并使用 <code>EMA</code> 更新教师模型。教师模型指导学生模型的训练，而不是简单的提供伪标签就结束了。在获取学生模型生成的预测后，得分大于某个阈值的视为前景，以此保证伪标签的质量，但即使这样仍然有很多预测结果是背景，后文会给出解决方案。</p><p>对于无标签数据，控制标签数据和无标签数据在一个 <code>batch</code> 中的比率，从 <code>0.5</code> 开始，衰减到最后的 <code>epoch</code> 为 0。</p><p><img data-src="https://s4.ax1x.com/2022/01/30/HC2bXn.png" alt></p><p>在图里可以看到：教师模型对无标签数据进行弱数据增强，并生成盒子的伪标签和类别的伪标签。学生模型读入有标签数据，得到一个损失 $L_u$ ，对无标签数据使用强数据增强，预测结果和教师模型生成的伪标签对比，又得到一个损失 $L_s$ 。最后的损失为 $L_s + \alpha L_u$。</p><p>对于 $L_u$ 的分类部分，与半监督分类的一致性分布损失相反，目标检测的伪标签相对复杂，无标签数据上能检测出上千个盒子，即使 <code>NMS</code> 之后也会留下很多盒子，所以选择前景分数大于某个阈值的作为盒子，但是阈值高导致召回率低，也就是说，学习模型的前景被匹配为背景。为了避免这个问题，在得到学生模型计算出的前景和背景后，前景直接和伪标签进行对比，背景使用可靠性分数进行加权。</p><p>对于 $L_u$ 的盒子部分，前景得分并没有提供很好的定位信息，也就是说使用得分作为阈值筛选教师提供的盒子伪标签没啥用，那么如何使盒子的定位信息更加可靠呢？论文是这么做的，在教师生成的标签盒子周围附近进行随机采样，再次得到预测的盒子，重复这个过程$N$（实验部分取 10）次得到多个盒子，计算这些盒子的标准差，标准茶大于 0.5 的才视为前景的盒子。</p><p>代码是用 mmdetection 写的，几年前我用过这个东西，暂时不考虑精读代码，这个并不是大众用户的东西，暂时不考虑精读代码。</p><h1 id="半监督语义分割"><a href="#半监督语义分割" class="headerlink" title="半监督语义分割"></a>半监督语义分割</h1><p><img data-src="https://s4.ax1x.com/2022/01/30/HC2xtU.png" alt></p><p>这篇论文的结构和上面两篇论文的结构很像，在这一瞬间仿佛世界线收束了，虽然这个论文没提供代码，但个人感觉这个方法是靠谱的。</p><p>它在语义分割的时候分为有标签样本和弱标签样本，弱标签样本是用别的方法生成的，我没有细看生成的方法。因为我准备在这篇论文的结构上在加一个教师网络，用教师网络生成伪标签，剩下的东西和半监督图像分类差不多了。</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p>代码用的 <code>segmentation model pytorch</code>，我看了下代码，魔改成半监督的话还是比较简单的，思路有了，代码都好说。会在不久的将来开源程序和结果，预计三月初。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://zhuanlan.zhihu.com/p/437754834" target="_blank" rel="noopener">半监督目标检测 MMdetection 实现</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;寒假开始前还是把在学校里遗留的工作先搞完，所接项目的目标是实现半监督语义分割。既然是半监督，就先来看一下半监督的经典论文，我选了经典的、结构相似的三篇论文。&lt;/p&gt;
&lt;p&gt;第一篇是：NIPS 2017 的 Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results，因为我发现伪标签相关的论文或多或少有它的影子。&lt;/p&gt;
&lt;p&gt;第二篇是：ICCV 2021 的 End-to-End Semi-Supervised Object Detection with Soft Teacher，微软出品的半监督目标检测，质量上还是比较让人相信的，且语义分割也可以借鉴目标检测的东西。&lt;/p&gt;
&lt;p&gt;第三篇是：ECCV 2021 的 Semi-supervised Semantic Segmentation via Strong-weak Dual-branch Network，因为搜半监督语义分割，最新的进展论文就是它了。&lt;/p&gt;
&lt;p&gt;文章最后有代码实现。&lt;del&gt;才发现好久没更新博客了。&lt;/del&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>CV 领域的自监督</title>
    <link href="https://muyuuuu.github.io/2021/12/28/SSL-intro/"/>
    <id>https://muyuuuu.github.io/2021/12/28/SSL-intro/</id>
    <published>2021-12-28T07:09:23.000Z</published>
    <updated>2022-01-03T08:45:41.381Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>还是要认真的学习一会儿，降低多巴胺的分泌。在使用 triplet loss 学表示的时候，出现了模型坍塌的情况，也就是说，模型对任何输入的输出都是一样的，损失恒定的现象。在网上搜了一些解决方案后，需要用户去花精力构造正负样本，我不喜欢这样的东西，所以开始看了自监督的论文，毕竟都是学表示。也发现自监督会在一段时间内成为未来的视觉领域的主流，正好我做的东西和自监督也算相关，做一个论文整理。包括了 MoCo，SimCLR，SimSiam 和 Barlow Twins。</p><blockquote><p>模型崩塌，也就是模型为了偷懒，无论什么图片都会输出同样表示，这样结果 loss 很小，然后却没学到任何东西。</p></blockquote><a id="more"></a><p>图像领域的自监督主要由两部分组成，对比损失和数据增强，而那四篇论文也是基于这两个东西去做的，无非是如何对比。</p><h1 id="MoCo"><a href="#MoCo" class="headerlink" title="MoCo"></a>MoCo</h1><p>首先是 <code>MoCo</code>，简单的看一下模型的结构</p><p><img data-src="https://s4.ax1x.com/2021/12/28/TsYsxS.png" alt="TsYsxS.png"></p><p>对同一个样本做两次数据增强，会得到两个样本 $x_q$ 和 $x_k$，创建两个 <code>encoder</code>，左边那个 <code>encoder</code> 接入 $x_q$，右边的 <code>encoder</code> 接入 $x_k$，使得这两个的相似性越高越好，与此同时，期望 $x_q$ 与负样本的相似性越低越好。那么如何衡量相似性呢？使用的是 <code>InfoNCE</code> 这个损失函数。</p><p>\begin{aligned}<br>{L}_{InfoNCE} =-{E}_X\left[\log \frac{f_{k}\left(x_{t+k}, c_{t}\right)}{\sum_{x_{j} \in X} f_{k}\left(x_{j}, c_{t}\right)}\right] \\<br>\end{aligned}</p><p>分子是正样本的相似度，分母是负样本的相似度，这个比值越大，log 就越大，对应的损失函数就越小。<code>MoCo</code> 的改动如下，用点积来衡量 $x_q$ 和正负样本的距离。也就是说，使用对比损失来区分图像的高维特征。</p><p>\begin{equation}<br>{L}_q = -\log \frac{ \exp(q\cdot k_{+}/\tau) }{\sum_{i=0}^K \exp(q\cdot k_{i}/\tau)}<br>\end{equation}</p><p>那么与众不同的地方呢？换句话说，负样本从哪里来呢？模型会设计一个队列，队列负责维护将刚进入的样本视为负样本放入队列（最开始没负样本的话，用的是随机数），并弹出之前的负样本，这就需要很大的显存以及代码编写的难度，我不是很喜欢这两点。不信你来看他们官方的<a href="https://github.com/facebookresearch/moco" target="_blank" rel="noopener">程序</a>。</p><p>此外需要注意的是，作者提出了动量的更新方式，来更新右侧的网络：</p><p>\begin{equation}<br>\theta_k \leftarrow m\theta_k + (1-m)\theta_q , m\in[0,1)<br>\end{equation}</p><p>也许你会有疑问，都计算好梯度了，更新左侧的网络就没事，更新右侧的网络就有事，莫非在耍流氓？这个梯度给谁不是给，为什么不用梯度更新两个网络？论文上写的是：由于样本很多，右侧网络不容易更新。很多网上的论文解析也是人云亦云，看了代码就知道存储负样本的队列和右侧的网络没半毛钱关系，队列在计算梯度的时候已经 <code>detach</code> 了。所以，论文写的更新困难并不是梯度回传困难，那么为什么不能用梯度更新右侧的网络呢？</p><p>先来解释为什么不把左侧网络的参数拷贝给右侧网络的参数。这么做的目的是因为不同 <code>epoch</code> 之间数据分布差异可能很大，<code>encoder</code> 的参数有可能会发生突变，不能将多个 <code>epoch</code> 的数据特征近似成一个静止的大 <code>batch</code> 数据特征，因此就使用了这么一个类似于滑动平均的方法来更新右侧网络。</p><p>再来回答为什么不用梯度更新右侧的网络。$x_k$ 经过右侧网络后，然后我们就得到了它们相对应的表示。而对于这个表示，它们不光包含了这个 <code>mini-batch</code> 的表示，也包含了一些之前处理过的 <code>mini-batch</code> 中的表示。换句极端的话说，右侧的网络掌握了全部数据的表示，来调控左侧网络该学到什么样的表示。这些表示通过右侧网络后放入队列中，相对于只在本 <code>mini-batch</code> 内做比较的方法而言，<code>moco</code> 能用较小的管理开销来获得更多的负样本。如果只用一个 <code>mini-batch</code> 的梯度更新右侧网络，或者说右侧网络只掌握一个 <code>mini-batch</code> 的表示，那右侧网络直接输出和左侧网络一样的东西不就行了，这样损失很小，但什么也没学到。因此，不能用一个 <code>mini-batch</code> 的梯度去更新右侧网络。</p><h2 id="损失函数解析"><a href="#损失函数解析" class="headerlink" title="损失函数解析"></a>损失函数解析</h2><p>此外是本文较为迷惑的损失函数，文章写的没啥迷惑，迷惑的是代码。我第一眼过去，直接理解为不管是正样本还是负样本，都和 0 去接近，正样本明明越大越好，应该和 1 去接近，这么写肯定不对呀。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">l_pos = torch.einsum(<span class="string">'nc,nc-&gt;n'</span>, [q, k]).unsqueeze(<span class="number">-1</span>)</span><br><span class="line">l_neg = torch.einsum(<span class="string">'nc,ck-&gt;nk'</span>, [q, self.queue.clone().detach()])</span><br><span class="line">logits = torch.cat([l_pos, l_neg], dim=<span class="number">1</span>)</span><br><span class="line">labels = torch.zeros(logits.shape[<span class="number">0</span>], dtype=torch.long)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">loss = criterion(logits, target)</span><br></pre></td></tr></table></figure><p>后来仔细抠的代码才理解，<code>torch</code> 的交叉熵损失函数由 <code>logsoftmax</code> 和 <code>nllloss</code> 组成，前者完成 <code>logsoftmax</code> 的计算，后者 <code>nllloss</code> 取出对应的标签，在 <code>nllloss</code> 的时候，标签为 0 的意思是取出 <code>batch</code> 中的第一列，而这一列正好是正样本，<code>nlloss</code> 期望这列的值越小越好，那么回退到 <code>logsoftmax</code>，就是期望这列的值越大越好，也就是，正样本的相似度很高。<strong>并不是像网上那种垃圾博客说的，无监督任务都分成 0 类即可。</strong> 这里还是建议理解一下，因为自监督的损失大多是这么设计的。</p><h1 id="SimCLR"><a href="#SimCLR" class="headerlink" title="SimCLR"></a>SimCLR</h1><p>推荐一个比较好的<a href="https://github.com/Spijkervet/SimCLR" target="_blank" rel="noopener">实现</a>。因为反感 <code>MoCo</code> 那种开显存的操作，毕竟不是所有人都有  <code>facebook</code> 的财力，所以继续去读了其他自监督的论文，较为相似的一篇论文是 <code>SimCLR</code>。还是先来看模型结构图：</p><p><img data-src="https://s4.ax1x.com/2021/12/28/TsYr28.png" alt="TsYr28.png"></p><p>注意，左右两边的网络都是相同的，也就不存在梯度该传给谁的问题。一个 <code>batch</code> 的样本，经过数据增强得到两个 <code>batch</code> 的样本，这两个 <code>batch</code> 的样本进入网络会得到两个 <code>batch</code> 的表示，期待这两组表示中，同一数据的表示很接近，放大不同数据的差异。损失同样是用的类似 <code>InfoNCE</code> 的损失函数。不过论文中有比较奇怪的点，放一段原文：</p><blockquote><p>We randomly sample a minibatch of N examples, augmented examples derived from the minibatch, resulting in 2N data points. We treat the other 2(N-1) augmented examples within a minibatch as negative examples.The final loss is computed across all positive pairs.</p></blockquote><p>问题来了，一共 $2N$ 个样本，$2(N-1)$ 都视为负样本，哪来的 positive pairs？还是直接看代码吧，其实 <code>MoCo</code> 的论文写的也够晕的。看了代码损失函数的设计后发现，就是自己和自己是正样本，自己和其他的样本的关系是负样本。严格来说，对于一个样本而言，有 <code>2(N-2)</code> 个负样本。损失函数和 <code>MoCo</code> 的保持一致，都是用交叉熵损失函数实现的。推荐去看这个损失函数的实现，代码写的还是比较有意思的。但是计算量会大一些。</p><h1 id="SimSiam"><a href="#SimSiam" class="headerlink" title="SimSiam"></a>SimSiam</h1><p>在 <code>MoCo</code> 之后，提出了更简单的网络结构：</p><p><img data-src="https://s4.ax1x.com/2021/12/28/TsYD8f.png" alt="TsYD8f.png"></p><p>提前声明，相似度用的是余弦函数，因为余弦函数相似性越高数值越大，因此损失函数取了负数，最后的损失值也是负的。思路很简单，对同一个图像做两次增强得到俩个正样本，$x_1$ 和 $x_2$，$x_1$ 经过 <code>encoder</code> 得到表示 $z1$，$z1$ 经过 <code>predictor</code> 得到 $p_1$，同理得到 $p_2$ 和 $z_2$，计算 $p_1$ 和 $z_2$ 以及 $p_2$ 和 $z_1$ 的相似度，然后就没了。</p><p>简单吗？简单。有坑吗？有。我当时在想，如果 <code>predictor</code> 的权重全部是 1，那么相似度不就会很小了，但仍然是模型坍塌的情况。然后带着疑问去看代码，结果人家直接冻结了 <code>predictor</code> 某一层的权重，是我大意了。后来我以抄袭的形式复现的时候，没有冻结权重，效果比 SimCLR 要好一些。</p><h1 id="Barlow-Twins"><a href="#Barlow-Twins" class="headerlink" title="Barlow Twins"></a>Barlow Twins</h1><p>到这篇论文，思路更加简单，东西和 SimCLR 比较类似，损失函数用的是大二学过的协方差矩阵，对角线越大越好，其余位置越小越好。它虽然很简洁，但我感觉他比 SimSiam 更令人喜欢。</p><p>\begin{equation}<br>L=\sum_{i}(1-C_{ii})^2 + \lambda \sum_i \sum_{j\neq i} C_{ij}^2<br>\end{equation}</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://kakack.github.io/2021/05/Moco-%E5%9F%BA%E4%BA%8E%E5%8A%BF%E8%83%BD%E6%9B%B4%E6%96%B0%E7%9A%84%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" target="_blank" rel="noopener">MoCo 参考</a></li><li><a href="https://blog.csdn.net/qq_22210253/article/details/85229988" target="_blank" rel="noopener">NLLLoss 解析</a></li><li><a href="https://zhuanlan.zhihu.com/p/357088620" target="_blank" rel="noopener">SimSiam 为什么 stop grad</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;还是要认真的学习一会儿，降低多巴胺的分泌。在使用 triplet loss 学表示的时候，出现了模型坍塌的情况，也就是说，模型对任何输入的输出都是一样的，损失恒定的现象。在网上搜了一些解决方案后，需要用户去花精力构造正负样本，我不喜欢这样的东西，所以开始看了自监督的论文，毕竟都是学表示。也发现自监督会在一段时间内成为未来的视觉领域的主流，正好我做的东西和自监督也算相关，做一个论文整理。包括了 MoCo，SimCLR，SimSiam 和 Barlow Twins。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;模型崩塌，也就是模型为了偷懒，无论什么图片都会输出同样表示，这样结果 loss 很小，然后却没学到任何东西。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>工程开发经验总结三，以 sspaddmm 为例，再来谈一谈并行加速</title>
    <link href="https://muyuuuu.github.io/2021/12/27/project-experience-3/"/>
    <id>https://muyuuuu.github.io/2021/12/27/project-experience-3/</id>
    <published>2021-12-27T15:07:29.000Z</published>
    <updated>2022-01-07T08:31:56.416Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>今天来写什么呢？准备整理一些多线程的东西，虽然多线程相对很熟悉了，可每次工程中都会有新的收获。这次不谈多线程的理论问题，毕竟计算机专业都懂多线程的理论并写过相关程序，也了解其使用的背景。之前使用多线程的时候，总是看一看加速比和结果是否准确就完了，那么这次以多线程使用者和多线程设计者的角度出发，来谈一谈如何更好的使用和设计多线程。</p><a id="more"></a><h1 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h1><p>给定一个 2D 的稀疏矩阵，稀疏矩阵的采用 COO 格式的表示，如下图所示：</p><p><img data-src="https://s4.ax1x.com/2021/12/27/Treg5d.png" alt></p><p>稀疏矩阵由三部分组成，包括 <code>Indices, Values, Shapes</code>。具体而言，这是一个 100 X 100 的二维稀疏矩阵，索引的第一行表示行，第二行表示列，行列对应的索引处为具体的数值，初次之前全部是 0。比如，<code>sparse[1][0]=0.6</code>，注意：其中的索引是可以重复的，比如有两个 <code>[2,1]</code>。</p><p>现在的问题是，稀疏矩阵乘以稠密矩阵，既然是矩阵乘法，很容易想到并行。不过在此之前，还是简单说一下矩阵乘法的流程：</p><p>假设稀疏矩阵第 $r_1$ 行和第 $c_1$ 列的值为 $v_1$，假设稠密矩阵由 $C$ 列，那么乘法就是：将 $v_1$ 与稠密矩阵中第 $c_1$ 行对应的所有的列的值相乘，结果的索引是 $(r_1, 1), (r_1, 2), \cdots, (r_1, C)$。举个例子：</p><p><img data-src="https://s4.ax1x.com/2021/12/27/TreoqS.png" alt></p><p>如上的例子中，稀疏矩阵乘以稠密矩阵，将单个系数矩阵元素相乘的结果，直接以 <code>+=</code> 的形式放到对应的位置中，既然画图了，那么也就能看出来并行的点：</p><ol><li>方案 1：乘以稠密矩阵要遍历其所有的列，所以在取列的时候并行，这样不会有冲突</li><li>方案 2：稀疏矩阵并行，以上图为例，直接拿那两个的稀疏矩阵的元素去乘以稠密矩阵的列。不过这里会有冲突，比如稀疏矩阵中有多个行相同的索引，比如上图的稀疏矩阵 <code>[1,0], [1, 2]</code> 这样的，在 <code>+=</code> 的时候不加锁，多线程会出问题。</li></ol><p>以下，<code>mat1</code> 表示稀疏矩阵，<code>mat2</code> 表示稠密矩阵，且 <code>sspaddmm</code> 函数<strong>要求返回稀疏矩阵</strong>而不是稠密矩阵，上面的图只是为了便于理解。此外，能使用的并行工具有限，这取决于所在的工程，这个没办法，有点戴着镣铐跳舞的意思，高中老师经常用戴着镣铐跳舞来 PUA 我们，即：你必须听话，在听话的范围内做到很好，不能越界。</p><h2 id="并行-API"><a href="#并行-API" class="headerlink" title="并行 API"></a>并行 API</h2><p>API 是这样的：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 对矩阵中每个元素自增 10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 串行</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">  arr[i] += <span class="number">10</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> shared = [&amp;](uint start, uint end) &#123;</span><br><span class="line">  <span class="keyword">for</span> (uint i = start; i &lt; end; i++) &#123;</span><br><span class="line">    arr[i] += <span class="number">10</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line">parallelfor(<span class="number">10000</span>, <span class="number">10000</span> / n_threads, shared);</span><br></pre></td></tr></table></figure><p>其中 <code>parallelfor</code> 的第一个元素是任务总数，<code>n_threads</code> 是线程的数量，最后传入定义的匿名函数，在匿名函数中，默认从 0 开始，到任务总数结束，并划分对应的 <code>start</code> 和 <code>end</code> 区间，比如 1 到 5000 为一组，5000 到 10000 为另一组。</p><h1 id="串行版本"><a href="#串行版本" class="headerlink" title="串行版本"></a>串行版本</h1><p>矩阵的串行乘法比较容易理解，写出串行程序来，也就知道了如何写并行程序。先遍历第一个矩阵，在遍历第二个矩阵，相乘即可：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> cnt&#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; mat1_nums; i++) &#123;</span><br><span class="line">  <span class="keyword">int</span> row1 = mat1_indices[i][<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">int</span> col1 = mat1_indices[i][<span class="number">1</span>];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; mat2_col; j++) &#123;</span><br><span class="line">    output_val[cnt] += mat1_val[i] * mat2_val[col1][j];</span><br><span class="line">    output_idx[cnt][<span class="number">0</span>] = row1;</span><br><span class="line">    output_idx[cnt][<span class="number">1</span>] = j;</span><br><span class="line">    cnt++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="使用方案-1"><a href="#使用方案-1" class="headerlink" title="使用方案 1"></a>使用方案 1</h1><p>方案 1 的并行似乎很简单，可真的是这样吗？看上文的串行程序，我们发现做完一次乘法，就将结果直接写到 <code>output</code> 对应的地址中，写完一次，<code>cnt++</code>，为下一次写出数据做准备。那么问题来了，<code>parallelfor</code> 不提供锁，那么变量在没被保护的情况下的自增就会错误，如何解决呢？</p><p>既然读写会出现错误，而多线程的读是没有问题的，那么就想办法去掉写：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> cnt&#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="built_in">unordered_map</span>&lt;<span class="keyword">int</span>, <span class="built_in">unordered_map</span>&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&gt; idx_map_cnt;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; mat1_nums; i++) &#123;</span><br><span class="line">  <span class="keyword">int</span> row1 = mat1_indices[i][<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; mat2_col; j++) &#123;</span><br><span class="line">    idx_map_cnt[row1][j] = cnt++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; mat1_nums; i++) &#123;</span><br><span class="line">  <span class="keyword">int</span> row1 = mat1_indices[i][<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">int</span> col1 = mat1_indices[i][<span class="number">1</span>];</span><br><span class="line">  <span class="keyword">auto</span> shared = [&amp;](uint start, uint end) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = start; j &lt; end; j++) &#123;</span><br><span class="line">      <span class="keyword">int</span> idx = idx_map_cnt[row1][j];</span><br><span class="line">      output_val[idx] += mat1_val[i] * mat2_val[col1][j];</span><br><span class="line">      output_idx[idx][<span class="number">0</span>] = row1;</span><br><span class="line">      output_idx[idx][<span class="number">1</span>] = j;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">  parallelfor(<span class="number">10000</span>, <span class="number">10000</span>/n_threads, shared);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你看，在时间复杂度不变的情况下，借助一个额外的映射表就实现了并行，因为是针对 mat2 进行了并行，mat1 部分仍然是串行，也就是说，不会同时出现两个 <code>row1</code> 相等的情况，因此多线程中的 <code>+=</code> 是安全的。</p><h1 id="使用方案-2"><a href="#使用方案-2" class="headerlink" title="使用方案 2"></a>使用方案 2</h1><p>如果明白了方案 1 的并行思路，那么问题又来了，假设 mat1 有 2000 个元素，mat2 的列也是 20，那么此时我们应该针对 mat1 进行并行，而不是 mat2。但是 mat1 并行会出乱子，因为使用多线程访问上述程序中的 <code>row1</code>，可能会用重复的结果，那么多线程中的 <code>+=</code> 就是不安全的。如何解决呢？反而言之，多线程访问 mat1，如何保证每个线程拿到的 <code>row1</code> 是不一样的。我和师弟提出了两种思路：</p><ol><li>先来看思路 1。设计一个数据结构，这个数据结构每次从 mat1_indices 中抽取出不重复的行，因为行是不同的，那么这样就可以并行了。举个例子，mat1 中的行是 <code>[1, 2, 1, 2, 3, 4, 5, 5, 6, 7]</code>，那么我第一次选择 <code>[1, 2, 3, 4, 5, 6, 7]</code> 去并行，第二次选择 <code>[1, 2, 5]</code> 去运算，每次选择的元素不会有重复，这样多线程的 <code>+=</code> 就安全了。可视化一下这样的结构：</li></ol><p><img data-src="https://s4.ax1x.com/2021/12/27/Trm9ZF.png" alt></p><p>来看如何实现这样的数据结构，也就是下文中的 <code>unrepeated</code>，因为映射的 <code>key</code> 是唯一的，所以使用 <code>key</code> 来记录不同的索引，选择的时候，也是选择其中的 <code>key</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="keyword">int</span>, <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; unrepeated;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int64_t</span> i = <span class="number">0</span>; i &lt; mat1_num; i++) &#123;</span><br><span class="line">  <span class="keyword">int</span> _row = mat1_indices[i][<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">int</span> _col = mat1_indices[i][<span class="number">1</span>];</span><br><span class="line">  unrepeated[_row].push_back(_col);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt; res;</span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; tmp</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (unrepeated.size()) &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> it = unrepeated.begin(); it != unrepeated.end(); it++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (unrepeated[it-&gt;first].size() == <span class="number">1</span>) &#123;</span><br><span class="line">      res.push_back(&#123;it-&gt;first, it-&gt;second.back()&#125;);</span><br><span class="line">      tmp.push_back(it-&gt;first);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      res.push_back(&#123;it-&gt;first, it-&gt;second.back()&#125;);</span><br><span class="line">      it-&gt;second.pop_back();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> i : tmp) &#123;</span><br><span class="line">    unrepeated.erase(i);</span><br><span class="line">  &#125;</span><br><span class="line">  tmp.clear();</span><br><span class="line">  <span class="keyword">int</span> n = res.size();</span><br><span class="line">  <span class="keyword">auto</span> shared = [&amp;](uint start, uint end) &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; end; i++) &#123;</span><br><span class="line">    <span class="keyword">int</span> row1 = res[i][<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">int</span> col1 = res[i][<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &gt; mat2_col; j++) &#123;</span><br><span class="line">      <span class="keyword">int</span> idx = idx_map_cnt[row1][j];</span><br><span class="line">      output_val[idx] += mat1_val[i] * mat2_val[col1][j];</span><br><span class="line">      output_idx[idx][<span class="number">0</span>] = row1;</span><br><span class="line">      output_idx[idx][<span class="number">1</span>] = j;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">  parallelfor(res.size(), res.size()/n_threads, shared);</span><br><span class="line">  res.clear();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有没有发现问题？我猜一定没有，因为不会有人盯着一段非必须的程序仔细的看。还是直接说把，上述程序中的 <code>mat1_val[i]</code> 不是合法的，因为并行化以后，i 对应的是 <code>res.size()</code> 的某个元素，而不是 <code>mat1_values</code> 的第 i 个数值。怎么办呢？再加一个映射 <code>co_map_idx</code> 呗，把索引映射为数值：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="keyword">int</span>, <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="keyword">int</span>, <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&gt;&gt; co_map_idx;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int64_t</span> i = <span class="number">0</span>; i &lt; mat1_vals_num; i++) &#123;</span><br><span class="line">  <span class="keyword">int</span> _row = mat1_indices[i][<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">int</span> _col = mat1_indices[i][<span class="number">1</span>];</span><br><span class="line">  unrepeated[_row].push_back(_col);</span><br><span class="line">  co_map_idx[_row][_col].push_back(mat1_val_addr[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> shared = [&amp;](uint start, uint end) &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = start; i &lt; end; i++) &#123;</span><br><span class="line">  <span class="keyword">int</span> row1 = res[i][<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">int</span> col1 = res[i][<span class="number">1</span>];</span><br><span class="line">  <span class="keyword">double</span> val = co_map_idx[row_mat1][row_mat2].back();</span><br><span class="line">  co_map_idx[row_mat1][row_mat2].pop_back();</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &gt; mat2_col; j++) &#123;</span><br><span class="line">    <span class="keyword">int</span> idx = idx_map_cnt[row1][j];</span><br><span class="line">    output_val[idx] += val * mat2_val[col1][j];</span><br><span class="line">    output_idx[idx][<span class="number">0</span>] = row1;</span><br><span class="line">    output_idx[idx][<span class="number">1</span>] = j;</span><br><span class="line">  &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>但是根据实际运行的结果来看中，这是一种很烂的方案，每次都要选择不重复元素、清空和删除，这会带来不必要的开销，时间会很慢。那么再来看二种并行思路：我们已经有了 <code>unrepeated</code> 这样的数据结构，那么直接对 <code>unrepeated</code> 直接分组不是更好吗？</p><p><img data-src="https://s4.ax1x.com/2021/12/27/TrmesK.png" alt></p><p>直接对 <code>unrepeated</code> 的 <code>key</code> 进行分组计算，这样就不会出现重复的 <code>key</code>，不过为了拿到不同的 <code>key</code>，仍然需要一些预处理。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; res;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span> it = unrepeated.begin(); it != unrepeated.end(); it++)</span><br><span class="line">  res.push_back(it-&gt;first)</span><br><span class="line"><span class="keyword">auto</span> multi = [&amp;](<span class="keyword">uint32_t</span> start, <span class="keyword">uint32_t</span> end) &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">uint32_t</span> i = start; i &lt; end; i++) &#123;</span><br><span class="line">    <span class="comment">// get val</span></span><br><span class="line">    <span class="keyword">auto</span> row_mat1 = res[i];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> row_mat2 : unrepeated[row_mat1]) &#123;</span><br><span class="line">        <span class="keyword">double</span> val = co_map_idx[row_mat1][row_mat2].back();</span><br><span class="line">        co_map_idx[row_mat1][row_mat2].pop_back();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">uint32_t</span> j = <span class="number">0</span>; j &lt; mat2_col; j++) &#123;</span><br><span class="line">            <span class="comment">// get val</span></span><br><span class="line">          <span class="keyword">uint32_t</span> idx = idx_map_cnt[row_mat1][j];</span><br><span class="line">          *(out_val_addr + idx) +=</span><br><span class="line">              val * mat2_val_addr[row_mat2 * mat2_col + j];</span><br><span class="line">          out_idx_addr[idx] = row_mat1;</span><br><span class="line">          out_idx_addr[idx + out_num] = j;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>看，方法总比困难多，问题被完美解决。在这之后，我尝试了各种并行方案，以及双重并行，上述代码是性能最好的一个，但性能与其他库比仍然查了很多。为什么呢？来分析原因。当矩阵规模很小的时候会执行串行乘法，而串行乘法的效率会远远好于其他库，这就说明乘法的思路没问题，我觉得是并行 <code>API</code> 设计的不够好，它只支持一维的并行，且不支持额外的自定义，这就导致了这个接口的应用受限，甚至为了使用这个 API 还要执行很多其他的辅助。如果一定要在矩阵乘法中套两次并行，效率会极度低下。</p><h1 id="如何设计多线程-API？"><a href="#如何设计多线程-API？" class="headerlink" title="如何设计多线程 API？"></a>如何设计多线程 API？</h1><p>既然 <code>parallelfor</code> 这么难用，那如果我们是工程师，该如何设计这个接口呢？首先我们要知道，多线程的使用场景多种多样变化无穷，以计算为例，可以以行为单位进行并行，也可以以列为单位，甚至可以以数据块为单位。我想了很久，并没有想出一个很好的方案。也许，我要是能想出来，甲方也不至于提供 <code>parallelfor</code> 这样的 API 。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天来写什么呢？准备整理一些多线程的东西，虽然多线程相对很熟悉了，可每次工程中都会有新的收获。这次不谈多线程的理论问题，毕竟计算机专业都懂多线程的理论并写过相关程序，也了解其使用的背景。之前使用多线程的时候，总是看一看加速比和结果是否准确就完了，那么这次以多线程使用者和多线程设计者的角度出发，来谈一谈如何更好的使用和设计多线程。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Design" scheme="https://muyuuuu.github.io/tags/Design/"/>
    
  </entry>
  
  <entry>
    <title>工程开发经验总结二，如果我是甲方，该如何外包？</title>
    <link href="https://muyuuuu.github.io/2021/12/09/project-experience-2/"/>
    <id>https://muyuuuu.github.io/2021/12/09/project-experience-2/</id>
    <published>2021-12-09T11:49:01.000Z</published>
    <updated>2021-12-27T15:08:15.827Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>本来是想直接写下的，半路除了点问题，写一篇中吧。具体出了什么意外呢？当然是自己不太熟悉的 <code>git</code> 操作，实在是缺乏和别人一起开发项目的经验。后来又陆续有一些其他的收获，一并整理。</p><a id="more"></a><p>承接上文，在代码开发与测试完成后，其实工作量才完成了一半，对的，你没听错。</p><h2 id="关于代码提交"><a href="#关于代码提交" class="headerlink" title="关于代码提交"></a>关于代码提交</h2><p>提交代码自然而然用的是 <code>git</code>，但是甲方的代码开放程度是不同的，甲方的主代码我们称为 <code>master</code> 分支，每个组有一个 <code>owner</code>，<code>owner</code> 能直接获取 <code>master</code> 的仓库，而开发人员只能获取 <code>owner</code> 的仓库。</p><p>这种操作就导致了一个问题，<strong>代码更新不及时，开发者和甲方沟通低效</strong>。开发者想要更新仓库，就必须先让 <code>owner</code> 更新；甲方提出代码的问题，就必须由 <code>master</code> 转发。</p><p>暂且假设更新成功，本地提交时，创建分支，提交代码，由于没获取 <code>master</code> 仓库的权限，只能由 <code>owner</code> 发起 <code>pull request</code>。而众所周知：一件事情经过的转手次数越多，经过的人员越多，处理速度就越慢。脑补你办一件事情，一张纸要盖很多章，那些人踢皮球的水平超乎你的想象。</p><p>其实这也不能怪 <code>owner</code>，如果这是在公司，上班时间我们开发的会很快；但是这是在学校，且还是研究生，你永远不知道你的老师会在什么时间给你安排什么奇奇怪怪的任务，事情一多就容易耽误，且心累。</p><p>再次假设，<code>pull request</code> 成功了，由于 <code>master</code> 频繁收录提交的代码进行更新，刚刚提交的 <code>pull request</code> 很可能代码冲突，此时就需要手动处理。我尝试了用 <code>gitee</code> 的界面进行处理，结果，呵呵，我们组全部的 <code>pr</code> 被我弄没了，全部重新提交，大型操作失误现场。</p><p>之后尝试用命令行操作，手动处理冲突并提交，<code>pr</code> 处显示没冲突，但是代码审核就是有冲突，冲突的位置我看了一下，本地明明已经处理好了。也许是我 <code>git</code> 操作不熟练，也许是线上环境的问题，很奇怪，最后也没有修复，重新拉取最新，草草提交了。</p><p>这前前后后大概浪费了三天宝贵的时间，这也在提醒我，抽时间学 <code>git</code>。</p><h2 id="关于修改程序"><a href="#关于修改程序" class="headerlink" title="关于修改程序"></a>关于修改程序</h2><p>因为需求性分析搞错了方向，导致我在这上面吃了大亏。当时大概有两种可行路线，一种是 A 路线，一种是 B 路线，两者只是表现形式不一样，但最终结果是一样的。我当时盲目自信，以为都行，就选择了 A 路线。后来个甲方沟通才知道，要实现 B 路线。<strong>这就导致了代码大改，白白的浪费时间和精力。</strong> 以至于为了赶进度，我还叫别人帮我一起改，可真是愧疚。</p><p>实现代码的改动会带动原型定义代码、测试代码的一起变动，难确实不难，恶心是真的恶心。我也第一次体会到，实际开发中，测试代码会比实现代码多的多。而且改代码的时候需要注意，改一点编译一点，不要一次性改一堆然后一次性编译，出错了都不知道是哪错了。</p><p>用一句话总结吧，中国有个成语叫管中窥豹，但也有见微知著，有一叶知秋，也有一叶障目不见泰山，无论如何都有个成语，叫自以为是。</p><h2 id="从甲方的视角看代开发"><a href="#从甲方的视角看代开发" class="headerlink" title="从甲方的视角看代开发"></a>从甲方的视角看代开发</h2><p>因为在开发的过程中遇到了一些困难，不是实现代码的困难，而是理解逻辑的困难。所以引出了这个思考，如果我是甲方，我把项目外放给别人，<strong>我应该怎么描述问题，才能让对面完成的更好？</strong>毕竟花同样一份钱，我希望拿到更好的程序。</p><p>第一点是提前告知项目的所有内容。这次开发有两个任务，第一个任务是开发和测试，第二个任务是适配。当时大家都以为适配很简单，外什么呢？因为一开始根本看不到第二个任务的说明书和文档，只有做完第一个任务才能看到后续任务的文档。相比之下，我们都认为适配会比开发简单的多，所以时间花费不合理，导致在开发浪费的过多的精力。等看到第二个任务的文档时，才发现代码量不会比开发低，但此时已经没有时间了，只能延期。如果是我，我会提前告知，以及在开发期间进行适当的催促。</p><p>第二点是整理常用的编译命令。因为大型项目的编译不是点按钮就能实现了，需要在命令行执行很长的了命令。我会写单独的一个文档，把这些命令从文档的各个角落收集起来，方便开发人员的粘贴。不然翻来翻去太麻烦了，真的。</p><p>最后一点，也是我认为最重要的一点。<strong>在文档之中，而不是文档之前进行一个逻辑说明</strong>，而不是单纯的告诉用户哪个文件的程序该怎么写。为什么呢？配置环境，如何开发等基础文档在这里就先忽略了，不是重点。</p><p>如果把概念性的东西写在最前面，开发者读起来会晕，而且不知所云。放在文档中间，当用户写完程序后，相对有了一定了解，知道代码写的是什么，在看到概念性的东西会比较直观。这就像看当代论文一样，先看摘要和引言，丝毫不知道在说什么，往往看到最后才明白。这其实和中国人的思维不符。举个例子，中国人盖房先打地基，自底向上，外国人盖房先设计房顶，自顶向下。两者都没有错，可中国人习惯了自底向上，被迫看自顶向下的东西不舒服。再举个例子，学计算机网络，是从物理层学到网络层，还是从网络层学到物理层？</p><p>其次，我要告诉用户他写的那些文件之间是什么逻辑。假设有 A B C 三个代码，开发者可能以为 A 会调用 B，为保证运行正确，B 中需要进行初始化操作；但其实呢，A 不会调用 B，B 也不用初始化，因为初始化工作已经在 C 中完成了。相信我，当项目规模十分庞大的时候，复杂的文件以及这些调用关系不是人眼能看出来的。即使能看出来，你也不会相信这种调用关系，不信？我举个例子。A 是测试代码，里面含有正确结果，B 是实现代码，B 需要把返回结果写到数组中，但数组大小未知。</p><ul><li>第一种情况，B 不需要经过运算获得数组大小，直接把结果写到测试代码的结果里面就好。</li><li>第二种情况，B 需要运算并获取数组大小，开辟新的数组，将结果写到新的数组，并返回与测试结果对比。</li></ul><p>正确答案是第一种情况。为什么不用具体实现？实际调用代码的时候没人会给你测试代码提供结果啊？代码不实现功能怎么能行？刚开始我也这么想的，但后来发现在实际使用的时候，会在一个默默无闻的 C 文件的代码中对 B 文件中的代码进行初始化，这就是没有搞清楚逻辑的后果，再次导致了代码的改动，而这种改动是可以在一开始避免的。</p><p>那么对于乙方，如何避免这种情况呢？开发的时候多和身边的人聊一聊，要多问多交流，而不是闷头凭自己的感觉和想象写程序，独行快，众行远。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本来是想直接写下的，半路除了点问题，写一篇中吧。具体出了什么意外呢？当然是自己不太熟悉的 &lt;code&gt;git&lt;/code&gt; 操作，实在是缺乏和别人一起开发项目的经验。后来又陆续有一些其他的收获，一并整理。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Design" scheme="https://muyuuuu.github.io/tags/Design/"/>
    
  </entry>
  
  <entry>
    <title>工程开发经验总结一，如何参与开发？</title>
    <link href="https://muyuuuu.github.io/2021/12/03/project-experience-1/"/>
    <id>https://muyuuuu.github.io/2021/12/03/project-experience-1/</id>
    <published>2021-12-03T15:41:41.000Z</published>
    <updated>2021-12-27T15:08:31.863Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>拖更了两个月，不知道是最近无事发生还是之前太能写了，这期间发生了很多事，现实与虚幻并存，度过目前的难关以后再慢慢吐槽吧。决定更新一篇工程开发经验的文章，无技术细节。</p><p>亿点点项目总结。大概是第一次接这么正规的项目，从代码要求、提交规范、开发流程、开发需求、测试流程到文档撰写，虽然其中有不尽人意的地方，但也算正规。按时间流程说吧。</p><a id="more"></a><h1 id="明确需求"><a href="#明确需求" class="headerlink" title="明确需求"></a>明确需求</h1><p>首先是明确需求，也就是说知道自己从开始到结束要干什么。开始很简单，配置环境，登陆远程服务器，clone 源代码；中间的开发过程由甲方提供，对我而言就是实现 <code>sspaddmm</code> 算子，并且通过单元测试和性能测试；在开发完成后，需要提交程序、撰写文档和完成适配，这也就是知道自己要干什么。</p><p>不尽人意的地方是：甲方说哪里不明白直接去 github new issue，我也照做了，可惜直到半个月后才回复我。反而直接微信找他聊天反馈更快，这样问题、分析和解答都是私有的，得不到积累和分享，不利于后来者的查阅以及项目的进展。</p><h1 id="开发流程"><a href="#开发流程" class="headerlink" title="开发流程"></a>开发流程</h1><p>这个对于乙方是重点，那么重点来谈一下。</p><h2 id="关于读文档"><a href="#关于读文档" class="headerlink" title="关于读文档"></a>关于读文档</h2><p>配置环境、clone 源代码就不用说了，都是基础操作。重点是开发，按着文档一步一步来，先写哪个文件，在写哪个文件，不得不说，甲方文档写的好丑。</p><p>如果期间遇到不懂的疑问，可以翻阅文档，也可以查阅相关代码，但是建议查阅代码的 API，为什么呢？文档不是更好吗？我遇到的情况并不是的，众所周知，代码的更新速度是要比文档更新速度快的，代码写完就可以提交，文档要等代码写完后才能写，甚至懒得写，懒得写占大多数情况。程序员最讨厌的四件事：写文档、写注释、别人不写文档、别人不写注释。</p><p>这就导致了一个问题，文档滞后于程序，我甚至发现文档的描述和程序的功能不符，这会造成一定的时间浪费，具体表现在：用户按照文档写程序，结果写到一半发现错了，需要重写；用户不读文档，直接读代码 API 的难度系数又可想而知。</p><p>尽管难度系数大，但也要能读代码，为什么呢？还是回到懒这一话题，工程中很多 API 并没有记录在文档中，换句话说，文档中没有描述的操作，工程含有的 API 也许支持。因此遇到问题时，我们需要找到相关类的定义，可以粗糙的通过见名知意来了解函数的用途。</p><p>这一流程的确帮了我一个大忙。简而言之：我在程序实现的时候必须新开辟空间，修改传入的指针指向的地址，程序结束后，指针还在那里，但不能指向实现中开辟的空间，因为变量是被封装的，不是修改指针指向那么简单。困惑的时候，发现对应的累有 API 可以实现获取修改数据的地址，万事大吉。</p><h2 id="关于实现"><a href="#关于实现" class="headerlink" title="关于实现"></a>关于实现</h2><h3 id="关于参考"><a href="#关于参考" class="headerlink" title="关于参考"></a>关于参考</h3><p>而对于刚接手工程而言，以飞快的速度吃透原理、架构和各个类的各个功能是不现实的，毕竟代码过于庞大。那么这个时候就建议先看工程中有没有类似的实现，做一个参考。这会节省很多的时间，包括 API 阅读、实现逻辑和类设计这三个角度。</p><p>除此之外，还可以参考已有程序，避免造轮子。举个例子，<code>sspaddmm</code> 是要对标 <code>torch.sspaddmm</code> 的，那么就先可以参考 <code>torch.sspaddmm</code> 是如何实现的。借鉴前人千锤百炼的代码，我们能更好的出发。</p><h3 id="关于开发"><a href="#关于开发" class="headerlink" title="关于开发"></a>关于开发</h3><p>无论如何，都会回到具体的程序开发中。这个时候，我推荐的是<strong>迭代式开发</strong>，不要一次性做到尽善尽美，这样后面 debug 的压力会很大，没有任何一个程序员可以保证一次性写千行左右的程序而不报错，我自己说的。</p><p>这个时候写一个最小的程序版，感觉对即可。由于大型工程项目的编译和运行并不像平时点按钮就能运行那么简单。因此，在调试困难的情况下，写完最小程序版通过编译即可，不必关心程序运行结果的正确与否。与此同时，做好 <code>info</code> 的输出，也就是说，在执行各个子模块时，在前面加一句 <code>std::cout &lt;&lt; &quot;run module X&quot; &lt;&lt; std::endl</code>，这样更方便定位到程序哪里出了问题。</p><h2 id="关于测试"><a href="#关于测试" class="headerlink" title="关于测试"></a>关于测试</h2><h3 id="关于单元测试"><a href="#关于单元测试" class="headerlink" title="关于单元测试"></a>关于单元测试</h3><p>在开发中，由于我们没有保证程序的逻辑正确性，这一点可以在测试时完成。因为程序上线之前必须经过严格的测试，测试样例尽可能广泛、极端，保证程序的行覆盖率。生成测试样例和期望输出后，就可以对自己写的程序正确与否进行校对了。</p><p>如果不对，确切而言，99.99% 的情况都是不对的。我是通过缩小单元测试样例的数量和数据量，比如只有一个测试样例，这个测试样例的数据很小，毕竟应该通过常见用例后再去测其他广泛的用例。在凭借 <code>std::cout</code> 一步一步的 debug 后，程序基本没问题了，其中的技术细节不在这里详谈，技术内容会单独写到其他文章中。这里需要注意的是，每次编译运行都比较耗时间，因此多加几个 <code>std::cout</code>，之加一个每次 debug 一小段，太浪费时间。</p><p>单元测试通过后，就可以进行编译部署，将自己的程序部署到工程中。这个时候，我不建议提交代码，因为性能测试还会发现程序的问题，程序还会面临二次修改，这是其一；其二是：有些人自以为是贪功冒进，写一点代码就提交，也不管正确与否，这样别人在 pull 时会拉取到错误的代码，编译时不会通过，这种行为令人做呕。</p><h3 id="关于性能测试"><a href="#关于性能测试" class="headerlink" title="关于性能测试"></a>关于性能测试</h3><p>性能测试就不多说了，批量生成不同大小的数据，记录执行时间，与甲方要求的性能进行对比即可。我当时在这里遇到了很多问题，具体来说一下：</p><p>首先是甲方工程的报错信息不够人性化，说不支持 int 类型，不支持 int 类型你咋不上天呢？后来发现，是性能测试配置文件中有的内容由脚本生成、有的内容直接写到配置文件中导致的。由于数据量大，数据字段由脚本生成，类型字段我直接写到配置文件中了，也就是 int。所以报一个「不支持 int 类型的错误」，我不理解。别问我是怎么发现这个错误的，呵呵。</p><p>之后发现性能测试报错，其报错信息提示「不支持输入类型」，已经有了前车之鉴，我知道真正的错误不会是不支持数据类型，后来发现是：数据格式排列错误，比如 [2] 应该写成 [1, 2]，这些是小错误，可以通过阅读代码来解决。那么大错误呢？比如直接告诉我运行超时，但不可能是运行超时，如何解决？</p><p>一个万能的方案是，看日志。其实写到这里，虽然吐槽甲方程序的缺点，但是能把自定义类型、类的设计、架构设计、各种极端情况的应对 API、单元测试模块、性能测试模块、整合并调用第三方库、报错信息提示和日志收集做的如此系统，虽然有瑕疵，但也可圈可点，这其中使用了多少设计模式，细思极恐。也不知道什么时候我才能有这么强的工程能力，成为一个工程的总设计师得多厉害。</p><p>回到看日志这一话题，我发现导致超时的原因是：core dumped，一个喜闻乐见的错误。再次回到实现部分的代码加上 <code>std::cout</code> 进行 debug。结果发现是开辟内存空间出错了，怀疑单元测试和性能测试用的链接库不是同一个。换成更加安全的内存开辟方法，bug 解决了。</p><p>但是发现性能比 <code>pytorch</code> 弱了不少，这个时候继续迭代开发。给程序增加多线程功能，读到这里，也许你能更好的明白：「为什么不要急着提交程序」，你以为的程序正确，但也只是你以为的，后期还有很大概率要完善和修改。修改完毕后，记得回头去执行单元测试，因为修改代码后很可能导致单元测试无法通过。</p><p>增加多线程的时候，回顾操作系统，多线程访问变量的弊端，因此很轻松能确定什么时候加多线程，什么时候不加。因为只能使用被封装的多线程库，不能自己手写，所以有些地方不方便加锁。至此，程序开发的东西告以结束，性能比 <code>pytorch</code> 快了两倍。前前后后花费了大约 20 天的时间，也收获了不少东西，做此记录。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;拖更了两个月，不知道是最近无事发生还是之前太能写了，这期间发生了很多事，现实与虚幻并存，度过目前的难关以后再慢慢吐槽吧。决定更新一篇工程开发经验的文章，无技术细节。&lt;/p&gt;
&lt;p&gt;亿点点项目总结。大概是第一次接这么正规的项目，从代码要求、提交规范、开发流程、开发需求、测试流程到文档撰写，虽然其中有不尽人意的地方，但也算正规。按时间流程说吧。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Design" scheme="https://muyuuuu.github.io/tags/Design/"/>
    
  </entry>
  
  <entry>
    <title>一些攻击算法</title>
    <link href="https://muyuuuu.github.io/2021/09/22/some-attack-methods/"/>
    <id>https://muyuuuu.github.io/2021/09/22/some-attack-methods/</id>
    <published>2021-09-22T07:15:31.000Z</published>
    <updated>2021-11-09T12:00:18.710Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>又又又摸了几天，写了个爬虫，还是回来看论文了。整理一些常见的基于生成的攻击算法，之后再看一些较新的论文，就开始写自己的论文了，<del>早日毕业吧</del>。</p><a id="more"></a><h1 id="Natural-ADV"><a href="#Natural-ADV" class="headerlink" title="Natural ADV"></a>Natural ADV</h1><p>GENERATING NATURAL ADVERSARIAL EXAMPLES，发表在 ICLR 2018。众所周知，神经网络的输入层含有的信息和和隐层含有的信息是不同的，且常见攻击算法生成的对抗样本并不具有语义特征。所以这篇论文尝试生成 natural 的对抗样本。</p><p>与传统算法不同的是：传统算法在输入空间搜索对抗样本，而本文的算法尝试在隐空间进行搜索。即输入的为干净样本的分布 $P(x)$，搜索一个 $z^\star$，并通过生成器将其映射回 $x^\star$，并期望对抗样本是合法且和原始输入较为接近。</p><p>为了达到这个目标，作者选用 WGAN 作为生成器。首先训练一个 $G$，可以由 $z$ 生成 $x$；同时训练一个与 $G$ 相反的 $I$，由 $x$ 生成 $z$。通过最小化重构 $x$ 和 $z$ 与 $I(G(z))$ 的误差作为损失函数训练模型。</p><p><img data-src="https://z3.ax1x.com/2021/09/22/4US1kF.png" alt></p><p>之后便是对抗样本的生成方法，使用生成器来判断当前的噪音是否能欺骗分类器，即在 $f(G(z’)) \neq f(x)$ 的情况下，选择一个 $z’$，这个 $z’$ 和 $I(x)$ 最为接近，那么对抗样本就是 $x^\star=G(z’)$。那么问题来了，如何搜索 $z’$ 呢？论文提出了两种搜索算法，都是直接在干净样本对应的隐向量 $z$ 上增加扰动，如果扰动可以成功的攻击分类器，那么就认为搜索到了 $z’$。</p><p><img data-src="https://z3.ax1x.com/2021/09/22/4U9gdf.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;又又又摸了几天，写了个爬虫，还是回来看论文了。整理一些常见的基于生成的攻击算法，之后再看一些较新的论文，就开始写自己的论文了，&lt;del&gt;早日毕业吧&lt;/del&gt;。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DeepLearning" scheme="https://muyuuuu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>基于数据分布的对抗防御和攻击</title>
    <link href="https://muyuuuu.github.io/2021/09/07/data-dis-attack-defense/"/>
    <id>https://muyuuuu.github.io/2021/09/07/data-dis-attack-defense/</id>
    <published>2021-09-07T12:20:30.000Z</published>
    <updated>2021-09-18T10:58:30.515Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在做对抗训练的时候，我时常在想一个问题：PGD、CW 这些攻击算法都会设置迭代步长和阈值，如果模型固定、参数固定，那么每次生成的对抗样本也会是一样的。如果使用 min-max 的方式进行对抗训练，那么模型可能会只认识在某一设置下的数据，如果面对新的分布攻击样本，如 ZOO, UAP, Deepfool 等，岂不是不能很好的防御？</p><p>这就又会回到小样本问题，总不能对所有的攻击算法在不同阈值下都生成对抗样本，而应该生成分布尽可能广泛的对抗样。既然提到生成，就不得不考虑 GAN，所以搜了些相关论文，并作整理。注意，所有论文我没看代码，所以不评价好与坏，在不久的将来如果我要发论文，肯定还会做对比算法，到时候回来评价各个算法。未完待续。</p><a id="more"></a><h1 id="advFlow"><a href="#advFlow" class="headerlink" title="advFlow"></a>advFlow</h1><p>AdvFlow: Inconspicuous Black-box Adversarial Attacks using Normalizing Flows, NIPS 2020。</p><p>这篇论文提出使用 normal flow 模型来生成对抗样本实现内部的 max。使得生成的对抗样本能围绕在干净样本附近，生成的对抗扰动能捕获图片信息，换句话说，可以根据图片信息来生成对抗扰动。</p><p><img data-src="https://z3.ax1x.com/2021/09/07/hozhMq.png" alt></p><p>首先预训练一个神经网络 $f$，这个网络是可逆的：</p><ul><li>输入为一随机分布 $z$，而后产生 $x$;</li><li>输入为干净样本 $x$，输入是随机分布 $z$</li></ul><p>整个流程如下：（这篇论文的 github 提供了 gif 来描述这个流程）</p><p>输入干净样本，经过 $f^{-1}$ 得到均值和方差下的噪音，将噪音再次经过 $f$ 得到对抗样本，将对抗样本输入目标模型，使用损失来更新均值和方差。以此来实现对抗训练。其中的损失、网络细节我没有看。</p><h1 id="ADT"><a href="#ADT" class="headerlink" title="ADT"></a>ADT</h1><p>Adversarial Distributional Training for Robust Deep Learning, NIPS 2020。</p><p>这篇论文和我的关注点一样，果然发顶会手要快。作者认为：对抗训练可不可以理解为数据增强？单个攻击算法并不能代表全部的对抗样本，所以作者提出了 ADT，通过增加熵正则化项，来获取潜在的分布在干净样本周围的对抗样本。以此来作为内部最大化，好的攻击算法才能产生更好的鲁棒性。</p><p>由于单个攻击算法不能覆盖全部的扰动，为了避免这个问题，应该找到干净样本附近的对抗样本的分布，而不是单纯的找到一个对抗样本。</p><p><img data-src="https://z3.ax1x.com/2021/09/07/hTCI1J.png" alt></p><p>如上图所示，蓝色点是 PGD 产生的对抗样本，黄色点是 ADT 产生的对抗样本。为了使对抗样本的分布具有多样性，增加了熵作为模型损失的一部分，众所周知，熵能衡量系统的稳定性，熵越大越不稳定。也就是，对抗样本的产生方式为：</p><p>\begin{equation}<br>E[L(f(x+\delta), y)] + \lambda H(p(\delta))<br>\end{equation}</p><p>$\delta$ 是对抗扰动，由高斯噪音分布并经过 $\text{tanh}$ 函数映射而来。相对于单个攻击算法，上述公式能更好的探索对抗扰动的分布。</p><h1 id="AGAT"><a href="#AGAT" class="headerlink" title="AGAT"></a>AGAT</h1><p>Attribute-Guided Adversarial Training for Robustness to Natural Perturbations，发表在 AAAI 2021。</p><p>在许多情况下，并不能获得全部的对抗样本，如果预测的对抗样本和训练的对抗样本没有来自同一分布，就会导致鲁棒性的下降。所以本文提出的对抗训练算法中，在内部最大化时，操纵图像属性空间的变化，这样训练出来的模型更具鲁棒性。</p><p>这里的属性空间是：翻转算一个属性空间，缩放算一个属性空间，颜色变化又算另一个属性空间。</p><p>本文使用的扰动是自然扰动，如图片尺寸和颜色的改变；缩放、旋转、腐蚀等。传统攻击算法的扰动有时会不满足 $\Vert x-x’ \Vert \leq \epsilon$ 的限制，且 $\epsilon$ 太大太小都不好，太小了没扰动效果，太大了图像会失真。但是本文的算法能有效的处理自然的扰动，使用 DNN 来生成扰动（看后文的意思是，输入图像，输出对抗样本）。</p><p><strong>这篇论文好多话写的我也不明所以</strong>，只能说大概流程是：前 N 个 epoch 训练干净样本，后面几个 epoch 训练对数据以迭代的形式进行扰动增强，而扰动增强这里我感觉很玄学。损失为最小化图像的分类损失、以及最大化干净样本与对抗样本在隐层的差异，以及通过 $L_2$ 范数限制扰动 $\alpha$ 的范围。</p><h1 id="advGAN"><a href="#advGAN" class="headerlink" title="advGAN"></a>advGAN</h1><p>Generating Adversarial Examples with Adversarial Networks，发表在 IJCAI 2018，使用 GAN 来生成对抗样本。</p><p>通过 GAN 来生成围绕着原始实例的高质量扰动来产生对抗样本，判别器来把关生成图像的质量。</p><p><img data-src="https://z3.ax1x.com/2021/09/08/hbA4bQ.png" alt></p><p>这个图已经把论文的含义表达的差不多了，思路也是简洁明了。输入原始图像，生成扰动并叠加至干净样本。和我最开始的构思一样，可惜被别人发表了。损失函数由三部分组成，一部分是对抗样本的分类损失，一部分是 GAN 的生成和判别损失，一部分是对抗扰动的范围损失，希望扰动范围越大越好。</p><h1 id="advGAN-1"><a href="#advGAN-1" class="headerlink" title="advGAN++"></a>advGAN++</h1><p>AdvGAN++ : Harnessing latent layers for adversary generation 发表在 ICCV 2019，是基于 advGAN 的改进，之前的 advGAN 是读取全部图像生成对抗扰动，这篇论文发现读取图像的隐层表示生成的对抗扰动会更好，就这样改进了一下。</p><p><img data-src="https://z3.ax1x.com/2021/09/08/hbEcdJ.png" alt></p><h1 id="RobGAN"><a href="#RobGAN" class="headerlink" title="RobGAN"></a>RobGAN</h1><p>Rob-GAN: Generator, Discriminator, and Adversarial Attacker，发表在 CVPR 2018。</p><p>这篇论文从另一个角度结合了 GAN 和对抗训练，将生成器融入对抗训练，提升判别器的鲁棒性；对抗训练使得 GAN 更快的收敛，并得到更好的生成器，两者互益。这篇论文的出发点同上：生成器生成分布更广阔的数据，使分类器在不可见数据集上获取更好的鲁棒性。</p><p><img data-src="https://z3.ax1x.com/2021/09/18/41SOfK.png" alt></p><p>对于 WGAN 的判别器而言，需要判别对抗样本和生成器的虚假样本，所以损失就是使这两者的分类误差达到最小，这里需要注意的是，虚假样本也要加上对抗扰动。</p><p>对于鲁棒性差的 GAN 而言，它虽然 smarter 但是 weaker，如下图所示：</p><p><img data-src="https://z3.ax1x.com/2021/09/18/41phNt.png" alt></p><p>在鲁棒的区域，能有效的抵御攻击而不会错分类。论文给出了一些证明，由于生成网络的任务是欺骗判别器，如果判别器不够鲁棒，那么只需要一点点的更新就可以欺骗判别器。如果判别器鲁棒，那么得到的生成器也会更好。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在做对抗训练的时候，我时常在想一个问题：PGD、CW 这些攻击算法都会设置迭代步长和阈值，如果模型固定、参数固定，那么每次生成的对抗样本也会是一样的。如果使用 min-max 的方式进行对抗训练，那么模型可能会只认识在某一设置下的数据，如果面对新的分布攻击样本，如 ZOO, UAP, Deepfool 等，岂不是不能很好的防御？&lt;/p&gt;
&lt;p&gt;这就又会回到小样本问题，总不能对所有的攻击算法在不同阈值下都生成对抗样本，而应该生成分布尽可能广泛的对抗样。既然提到生成，就不得不考虑 GAN，所以搜了些相关论文，并作整理。注意，所有论文我没看代码，所以不评价好与坏，在不久的将来如果我要发论文，肯定还会做对比算法，到时候回来评价各个算法。未完待续。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DeepLearning" scheme="https://muyuuuu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>神经网络常见问题</title>
    <link href="https://muyuuuu.github.io/2021/09/04/DNN-issue/"/>
    <id>https://muyuuuu.github.io/2021/09/04/DNN-issue/</id>
    <published>2021-09-04T12:36:07.000Z</published>
    <updated>2021-09-05T13:02:20.894Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>写深度学习的代码多了，经常会发现网络准确率低、难以收敛等错误，大多时候不是算法问题，而是人为的 bug，特此记录。</p><p>比如：为何网络的误差一直是一个定值？为何同样的网络、同样的优化器和学习率，训练得到的准确率比别人低 20% ？</p><a id="more"></a><ol><li>神经网络处理数据时不进行<a href="https://muyuuuu.github.io/2021/05/07/DNN-data-normal/">标准化</a>，准确率会下降很多；</li><li>神经网络的学习率至关重要，batch 大而学习率小，batch 小而学习率大，都会导致不收敛问题。此外，学习率衰减很重要，能有效提升<a href="https://github.com/bearpaw/pytorch-classification" target="_blank" rel="noopener">卡在瓶颈</a>中的神经网络的准确率。</li><li>复现去噪器时，噪音数据在损失函数<a href="https://github.com/muyuuuu/Paper-ReImplement/tree/main/ADP-ICML-2021" target="_blank" rel="noopener">内部生成</a>。如果在损失外部生成噪音并输入网络，会导致网络的误差恒定为噪音的方差。</li></ol><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>本文持续整理中。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;写深度学习的代码多了，经常会发现网络准确率低、难以收敛等错误，大多时候不是算法问题，而是人为的 bug，特此记录。&lt;/p&gt;
&lt;p&gt;比如：为何网络的误差一直是一个定值？为何同样的网络、同样的优化器和学习率，训练得到的准确率比别人低 20% ？&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DeepLearning" scheme="https://muyuuuu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>YOLO V2，细读代码</title>
    <link href="https://muyuuuu.github.io/2021/08/28/yolo-v2/"/>
    <id>https://muyuuuu.github.io/2021/08/28/yolo-v2/</id>
    <published>2021-08-28T14:16:45.000Z</published>
    <updated>2022-01-03T08:45:57.091Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>还是老样子，不看代码永远不能称为学会了。况且 YOLO V2 有一些优化还是很常见的，如 Anchor Box 和多尺度训练。我之前也只是听说过这些名词，并不知道如何在程序中使用，索性直接读了程序了解一下，程序写的还是比较精彩的。另外：这是第一篇用 vim 写的博客。</p><a id="more"></a><h1 id="YOLO-v2"><a href="#YOLO-v2" class="headerlink" title="YOLO v2"></a>YOLO v2</h1><p>论文地址：<a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="noopener">https://arxiv.org/abs/1612.08242</a><br>提供两个代码地址：第一个适合看模型、损失和多尺度训练，第二个适合看 anchor box 如何用到模型中，但是需要注意的是有 bug，但写的比第一个容易理解。</p><ol><li><a href="https://github.com/longcw/yolo2-pytorch" target="_blank" rel="noopener">https://github.com/longcw/yolo2-pytorch</a></li><li><a href="https://github.com/uvipen/Yolo-v2-pytorch/tree/master" target="_blank" rel="noopener">https://github.com/uvipen/Yolo-v2-pytorch/tree/master</a></li></ol><p>作者基于之前的 YOLO v1，提出了一些改进的策略，快速的同时准确率也大幅度提升。训练检测网络的同时，在 ImageNet 数据集上进行训练，提升了网络的分类能力。文章的一开始，作者指出了检测存在的几个问题：</p><ol><li>小目标检测能力受限</li><li>目标检测数据集的类别远远小于分类数据集的类别，且，不可能对检测数据集进行标注。所以能不能使用多个分类的数据集提升网络能识别的类别数呢？</li></ol><h2 id="Better"><a href="#Better" class="headerlink" title="Better"></a>Better</h2><p>作者进行了一些尝试来提升网络的性能：</p><ul><li>Batch Normalization，在卷积层后、激活层前加入 BN 层，大约提升了 2%。BN 层帮助网络实现正则化，能移除之前的 droupout层。</li><li>提高分辨率，将 v1 的 224 尺寸变为 448 尺寸，并先在 ImageNet 上训练 10 次，使得网络适应高分辨率，而后在检测任务中进行微调。</li><li>使用 Anchor Box 提升定位精准度，预测相对 anchor box 的坐标偏移，预测偏移相对直接预测坐标会简单些。这样提升了网络的召回率。此外，图片的 Ground Truth 一般都是正方形，1:2 的长方形或者 2:1 的长方形，预先准备几个几率比较大的 bounding box，再以它们为基准进行预测。</li><li>为了设置合适的 Anchor Box 的大小，对数据集的盒子进行 K-means 聚类，筛选出合适的 bounding box 大小。K-means 没有使用 欧拉距离，而是 $1-\text{IOU(box, center)}$，即盒子的 IOU 越大，距离越小。</li></ul><p>以上都是微小的改进，下面的三点改进是比较大的。</p><h3 id="Direct-location-prediction"><a href="#Direct-location-prediction" class="headerlink" title="Direct location prediction"></a>Direct location prediction</h3><p>作者使用 Anchor Box 的时候发现早期的网络不稳定，原因来自 $(x,y)$ 的预测。在 RPN 网络中，预测出 $t_x$ 和 $t_y$，$(x,y)$ 的计算为：</p><p>\begin{aligned}<br>x &amp;= (t_x * w_a) + x_a \\<br>y &amp;= (t_y * h_a) + y_a \\<br>\end{aligned}</p><p>由于 $t_x,t_y$ 的输出值不受限制，$(x,y)$ 能忽略 Anchor Box 的存在而而满天飞。所以网络增加了 sigmoid 函数限制 $t_x,t_y$ 的取值在 0 到 1 之间。具体一点，就是更改网络的输出为 $(t_x, t_y, t_w, t_h, t_o)$。由于 YOLO 的预测的尺寸、中心点的坐标都是相对图片的占比，比如一个目标位于图片的正中心，那么 $(x,y)=(0.5,0.5)$ 。如果当前格子相对图片的偏移是 $(c_x,c_y)$，Anchor Box 之前的宽和高是 $(p_w,p_h)$，那么预测的 bounding box 输出为：</p><p><img data-src="https://z3.ax1x.com/2021/08/26/hncDq1.png" alt></p><p>此外，置信度的输出替换为 $\sigma (t_o)$。</p><h3 id="Fine-Grained-Features"><a href="#Fine-Grained-Features" class="headerlink" title="Fine-Grained Features"></a>Fine-Grained Features</h3><p>为了提升小目标的检测精度，增加了 passthrough layer，用类似残差连接的方式传递前几层的特征到网络后面，堆叠高层特征和低层特征到不同通道上。</p><p><img data-src="https://z3.ax1x.com/2021/08/26/huFwqg.jpg" alt></p><h3 id="Multi-Scale-Training"><a href="#Multi-Scale-Training" class="headerlink" title="Multi-Scale Training"></a>Multi-Scale Training</h3><p>为了使模型适应不同的尺寸，不再单一的固定单张图片的大小。而是在网络迭代 10 个 batch 后，网络通过下采样来产生新的输入尺寸来读取图像。这样简单的操作，使得模型适应不同尺寸的图像。</p><h2 id="Faster"><a href="#Faster" class="headerlink" title="Faster"></a>Faster</h2><p>这里的快是为了保证准确率而尽可能快，所以未必会比 YOLO v1 快。作者提出了 DarkNet-19 （黑暗网络，好中二的名称）作为模型的 backbone，相比 VGG16 还是比较快的。之后：</p><ol><li>ImageNet 预训练 160 个 epoch，训练期间使用了随机裁剪、旋转、颜色变换等增强方式；</li><li>ImageNet 的尺寸是 224，为了适应高分辨率的图像，将输入层的尺寸调为 448，再次在 ImageNet 上训练 10 个 epoch；</li><li>更改网络结构，移除分类层添加检测头。对于 VOC 数据集而言，每个格子输出 5 组参数，也就是预先有 5 个 Anchor Box，每组参数是 20 个类别的得分 5 个盒子参数，所以每个盒子一共 125 个参数。而后 passthrough layer 预测小目标的输出。</li></ol><p>用检测数据进行训练时，训练了 160 个 epoch ，也使用了随机裁剪、旋转、颜色变换等增强方式。</p><h2 id="Stronger"><a href="#Stronger" class="headerlink" title="Stronger"></a>Stronger</h2><p>数据比模型更重要。那么有没有办法把 classification 数据集也利用起来？毕竟它们虽然没有提供坐标信息，但是也提供了类别信息，这部分类别信息能够显著拓展检测的类别数。当输入是 detection 数据时，按照正常的训练过程进行反向传播；当输入的是 classification 数据时，只计算和更新类别对应的 loss 和网络参数。</p><p>与 Faster 训练方式不同的是，将分类数据集和检测数据集进行联合训练。此时存在的问题是，分类数据集和检测数据集不是同一个数据集，如果检测数据集的标签是「狗」，那么分类数据集的标签很可能是「泰迪、田园犬」等，所以要合并这些标签。论文采用树的结构融合这些标签，得到具有 1396 个节点的树。针对每一个 anchor，预测出长度为 1396 的矢量，对该矢量按照层级关系进行同层级的 softmax 得到条件概率，根据全概率公式连乘即可得到所属类别的条件概率。</p><p><img data-src="https://z3.ax1x.com/2021/08/26/hnHwtJ.png" alt></p><p>经过这种弱监督式的融合数据集训练后，YOLO v2得以检测超过9000种类别，因此得名为YOLO 9000。</p><h1 id="code"><a href="#code" class="headerlink" title="code"></a>code</h1><h2 id="模型部分"><a href="#模型部分" class="headerlink" title="模型部分"></a>模型部分</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成 anchor 个 [类别，x, y, w, h] 这样的数据</span></span><br><span class="line">out_channels = cfg.num_anchors * (cfg.num_classes + <span class="number">5</span>)</span><br><span class="line">self.conv5 = net_utils.Conv2d(c4, out_channels, <span class="number">1</span>, <span class="number">1</span>, relu=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对 x 和 y 激活处理，学习偏移量</span></span><br><span class="line">xy_pred = F.sigmoid(global_average_pool_reshaped[:, :, :, <span class="number">0</span>:<span class="number">2</span>])</span><br><span class="line"><span class="comment"># 对 w 和 h 进行映射，用来乘以之前 anchor 的宽和高，得到预测的宽和高</span></span><br><span class="line">wh_pred = torch.exp(global_average_pool_reshaped[:, :, :, <span class="number">2</span>:<span class="number">4</span>])</span><br><span class="line">bbox_pred = torch.cat([xy_pred, wh_pred], <span class="number">3</span>)</span><br><span class="line"><span class="comment"># IOU 预测，YOLO V1 中是置信度</span></span><br><span class="line">iou_pred = F.sigmoid(global_average_pool_reshaped[:, :, :, <span class="number">4</span>:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类别预测，共 anchor 个类别</span></span><br><span class="line">score_pred = global_average_pool_reshaped[:, :, :, <span class="number">5</span>:].contiguous()</span><br><span class="line">prob_pred = F.softmax(score_pred.view(<span class="number">-1</span>, score_pred.size()[<span class="number">-1</span>])).view_as(score_pred)</span><br></pre></td></tr></table></figure><h2 id="数据与损失"><a href="#数据与损失" class="headerlink" title="数据与损失"></a>数据与损失</h2><p>对于加载数据部分，由于是多尺度训练，所以先要把图像 <code>resize</code> 到指定的输入尺寸，而后对标签中的宽度、中心点进行放缩，而后返回盒子、类别标签即可。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">batch[<span class="string">'images'</span>].append(images)</span><br><span class="line">batch[<span class="string">'gt_boxes'</span>].append(gt_boxes)</span><br><span class="line">batch[<span class="string">'gt_classes'</span>].append(classes)</span><br><span class="line">batch[<span class="string">'dontcare'</span>].append(dontcare)</span><br><span class="line">batch[<span class="string">'origin_im'</span>].append(origin_im)</span><br></pre></td></tr></table></figure><p>众所周知，对于卷积神经网络而言，输入图像的尺寸大小不同，输出的图像尺寸也不会一样。而网络超参数始终是固定的，适应多尺度训练是在损失函数中进行的，将标签数据的尺寸适配到网络输出的尺寸，这样就实现了多尺度训练。而后开始计算损失和反向传播，也就是<a href="https://github.com/longcw/yolo2-pytorch/blob/17056ca69f097a07884135d9031c53d4ef217a6a/darknet.py#L40" target="_blank" rel="noopener">这个函数</a>所做的。</p><p>之后就是损失函数部分了，重点是来看看是如何基于 <code>anchor box</code> 进行预测的，不过仍然可以确定的是，不管是分类损失，还是 IOU 损失或 bounding box 损失，使用的都是 MSE 损失函数。</p><p>对于标签数据而言，重要的是看懂<a href="https://github.com/uvipen/Yolo-v2-pytorch/blob/9589413b5dce0476eb9cccc41945cf30cf131b34/src/loss.py#L89-L145" target="_blank" rel="noopener">这里</a>的流程：</p><ol><li>遍历当前的 batch size，处理每一个 batch；</li><li>对预测输出和真实标签进行 IOU 计算，筛选出大于阈值的 bounding box 作为正样本，其余样本忽略；</li><li>筛选出与真实标签大小最为接近的 anchor box，基于 anchor box 计算和真实框的偏移量。anchor box 是预先设置的，anchor box 没有位置的概念，不是基于某个框生成的，anchor box 在整个训练期间是不变的。假设是第 2 个 anchor box 最接近。由于标签数据的维度和网络输出的维度相同，将标签数据的第 2 维填充为对应标签。这样，其余数据回被忽略。这一部分<a href="https://github.com/uvipen/Yolo-v2-pytorch/blob/9589413b5dce0476eb9cccc41945cf30cf131b34/src/loss.py#L89-L145" target="_blank" rel="noopener">代码</a>。</li></ol><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>这一部分代码还是耐心读吧……我也读了一晚上。也确实没发现网上有哪篇博客写的比代码还要详细清晰。读完了代码，我也知道了代码中如何实现多尺度训练和使用 anchor box。据说 YOLO v3/v4/v5 都是一些工程上的 trick 了。应该只会读那些具有创新点的代码，其他代码会选择性了略过了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;还是老样子，不看代码永远不能称为学会了。况且 YOLO V2 有一些优化还是很常见的，如 Anchor Box 和多尺度训练。我之前也只是听说过这些名词，并不知道如何在程序中使用，索性直接读了程序了解一下，程序写的还是比较精彩的。另外：这是第一篇用 vim 写的博客。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>关于六天掌握 Vim 这件事</title>
    <link href="https://muyuuuu.github.io/2021/08/28/vim-learn/"/>
    <id>https://muyuuuu.github.io/2021/08/28/vim-learn/</id>
    <published>2021-08-28T14:15:36.000Z</published>
    <updated>2021-09-01T13:46:39.520Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>学习 vim 的时候曾经4进4出一直没学会，这次下定决心要学一下了，也不求一口吃个胖子，每天学习一点点。首先从基础操作开始练习，先不要配置插件，也不管高亮和编程。<del>IDE是人类退步的阶梯</del>，沃茨基说的。</p><p>当然，这份文档不一定包含所有命令，只是教学的目的，遇到没有涵盖的命令自行查阅即可。有些命令是我自己的总结，不一定对。此外，本文涉及的命令之间可以任意组合实现各类高级功能，这个没办法统一列出。</p><p>此外，纸上得来终觉浅，学习 vim 一定多动手练习，在平时任务中多用 vim，自然而然就掌握了。我前后花了 6 天能使用 vim 应付日常开发工作，所以本文也叫六天掌握 vim。</p><a id="more"></a><p>这个是我参考的 vim 的学习笔记，感觉写的还是不错的：<a href="https://coolshell.cn/articles/5426.html" target="_blank" rel="noopener">https://coolshell.cn/articles/5426.html</a></p><h1 id="第一天"><a href="#第一天" class="headerlink" title="第一天"></a>第一天</h1><p>我一点点的写vim，尝试着写点。</p><p>换行了。</p><pre><code>也能缩进。</code></pre><p>第一步直接安装 vim，而后新建一个文件，就叫 <code>vim-prac.md</code>，每次练习都打开这个文件，直接写入。我直接新建了一个博客，每次的练习都写入到这个博客。</p><p>首先要知道的，在 <code>normal</code> 模式下，万物都是功能键，比如 <code>hjkl</code> 是方向键，<code>h</code> 表示左，<code>j</code> 表示下，<code>k</code> 表示上，<code>l</code> 表示右。其实也容易记忆，位于两侧的 <code>hl</code> 表示左右，而后左下、右上这样记忆，即和 <code>h</code> 紧挨着的是下，和 <code>l</code> 紧挨着的是上。</p><ul><li>如果想要打字，按一下键盘上的 <code>i</code> 进入 <code>insert</code> 模式，而后开始随心所欲的打字，和编辑 txt 文件一样没啥区别，上面那些文字都是我刚入门就打出来的。</li><li>在写完之后，按键盘左上角的 <code>esc</code> 退出插入模式，而后输入 <code>:wq</code> 表示写入并退出，这样写好的文件就被保存了。冒号的意思是进入命令模式，<code>w</code> 是写入单词的首字符，<code>q</code> 是退出单词的首字符。</li></ul><p>那么再来看一下其他操作：</p><ul><li><code>x</code>，<code>normal</code> 模式下，表示删除光标后面的字符。既然删除了，是不是要撤销？那么撤销操作是 <code>u</code>，如果回退到 3 次修改之前，可以输入 <code>3u</code>。这个可以直接在界面下操作，也可以<code>:u</code>。如果发现撤销过头了，就需要恢复，此时的快捷键是 <code>ctrl+R</code>，或者 <code>:red</code>。</li><li><code>dd</code>，同样是在 <code>normal</code> 模式下，表示删除当前行，并复制到剪切板中，<code>p</code>，粘贴剪切板中的内容。如果复制的是一行，<code>p</code> 会另起一行粘贴，如果复制的是个单词， <code>p</code> 会空格后粘贴，<code>P</code> 会避免这些。</li></ul><p>现在差不多可以编辑基本的文本了，今天的内容学习到此结束。如果今后在面对不忙的、简单的、凭借目前 vim 技术可以解决的工作，可以尝试开始用 vim。</p><h1 id="第二天"><a href="#第二天" class="headerlink" title="第二天"></a>第二天</h1><p>在编辑文本的时候发现，光标的移动不是很便捷，每次都要狂按方向键才能到想要的位置。那么今天就来学习下便捷的光标移动与插入。</p><h2 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h2><ul><li><code>a</code>，在光标后插入，假设一段序列是 <code>abcd</code>，光标位于 <code>a</code> 后面，在 <code>normal</code> 模式下，那么输入 <code>a</code> 后会移动到 <code>b</code> 的后面，而后开始插入；</li><li><code>o</code>，当前行后插入一个新行；</li><li><code>O</code>，当前行前插入一个新行；</li></ul><h2 id="光标移动"><a href="#光标移动" class="headerlink" title="光标移动"></a>光标移动</h2><ul><li><code>0</code>，移动到行头；</li><li><code>^</code>，当本行第一个不是空格、tab、回车、换行字符的位置，也就是一行开头的这些东西会被忽略；</li><li><code>$</code>，移动到本行的行尾；</li><li><code>g_</code>，到本行最后一个不是空格、tab、回车、换行字符的位置；</li><li><code>/pattern</code>，搜索 <code>pattern</code> 的字符串，如果有多个，按 <code>n</code> 到下一个。</li></ul><h2 id="拷贝"><a href="#拷贝" class="headerlink" title="拷贝"></a>拷贝</h2><p>之前已经知道了 <code>p</code> 是粘贴，<code>dd</code> 是剪切当前行。如果不删除当前行直接复制呢？用的是 <code>yy</code>。</p><p>此外，有的时候还想不复制整行，只想复制一行中的某些文字。此时的命令是在 <code>normal</code> 模式下按 <code>v</code> 进入 <code>visual</code> 模式，而后移动光标（可以借助 <code>$</code> 等功能键）选中文本，按下 <code>y</code> 表示复制选中的文本。而后 <code>p</code> 表示在当前位置之后粘贴，即如果将一些内容复制到 <code>ABCDE</code> 的 <code>B</code> 后面，需要将光标放到 <code>A</code> 后面然后粘贴。</p><p>还有这里看着突兀的原因是，之前终端用的光标是 <code>Beam</code> 这样的细线，如果换成 <code>Block</code> 这样的光标块，能从视觉角度更好的理解复制和粘贴的位置。</p><p>还有诸如 <code>yG</code> 复制到当前文件结束，<code>y20G</code> 复制到第 20 行等操作，用到的时候再来整理。</p><h2 id="文件读取"><a href="#文件读取" class="headerlink" title="文件读取"></a>文件读取</h2><ul><li><code>:e path</code>，表示打开指定 path 的文件</li><li><code>:wq, :x, XX</code>，保存并退出，<code>:x</code> 仅在有改动时保存</li><li><code>:q!</code>，强制退出不保存，<code>:qa!</code> 强制退出正在编辑的文件，即使有更改</li></ul><p>今天的练习结束，淘到了一个键盘，回宿舍洗一洗。</p><h1 id="第三天"><a href="#第三天" class="headerlink" title="第三天"></a>第三天</h1><p>一时技痒，偷着做了两件事情，一个是 <code>vim</code> 的配置文件，一个是 <code>vim</code> 的插件。</p><p>大概昨天尝试了一下使用 <code>vim</code> 安装插件，不得不说真香。我选择的插件管理器是 <code>vim-plug</code>，记得配置 <code>git</code> 的 <code>ssh</code> 和 <code>https</code> 代理，否则下载不下来。先装了一个 <a href="https://github.com/vim-airline/vim-airline" target="_blank" rel="noopener"><code>vim-airline</code></a> 还不错。之后等时间长了，配置一些编程用的插件。</p><p>而后是 <code>vim</code> 的配置文件，用户自己的配置文件位于 <code>~/.vimrc</code>，系统的配置文件位于 <code>/etc/.vimrc</code>。而后可以网上查一查如何配置，比如显示行号、设置缩进、显示文件名等。我的 <code>vim</code> 配置放到了我的 github 上：<a href="https://github.com/muyuuuu/my-vim-config" target="_blank" rel="noopener">https://github.com/muyuuuu/my-vim-config</a> 。</p><p>回到正题，今天额外学一些光标移动的操作，我也是使用了一段事件后才发现快速定位到某个位置真的是太有用了。</p><p>在配置文件中开启行号设置后，可以知道文件位于哪一行。在 <code>normal</code> 模式下，可以使用 <code>NG</code> 移动到第 <code>N</code> 行，<code>N</code> 是数字；<code>G</code> 是移动到最后一行。或者在 <code>command</code> 模式下，<code>:112</code> 会移动到 112 行。<code>ctrl+f</code> 向下翻页，<code>ctrl+b</code> 向上翻页；<code>ctrl+e</code> 逐行向下翻页；<code>ctrl+y</code> 逐行向上翻页。 </p><p>之后再来看一下行内的移动：</p><ul><li><code>w</code> 到下一个单词的开头，<code>b</code> 移动到上一个单词的开头，<code>e</code> 到当前单词的结尾。</li><li><code>%</code> 匹配括号移动，包括 <code>([{</code>，把光标移动到括号上面，按 <code>%</code> 就可以吧光标移动到匹配的位置。</li><li>单词移动，<code>*</code>（下一个） 和 <code>#</code>（上一个），匹配光标当前所在的单词，移动到上一个单词和下一个单词。</li><li><code>6l</code> 向右移动 6 个字符</li></ul><p>今天的学习到此结束。今天用 <code>vim</code> 写了一段代码，发现还是熟能生巧，得多用用。</p><h1 id="第四天"><a href="#第四天" class="headerlink" title="第四天"></a>第四天</h1><p>因为我的电脑屏幕比较大，所以启动终端只开一个 <code>vim</code> 窗口有些资源浪费，今天来学习一下如何分屏。</p><p>就像这张图一样，上面是文档，下面是代码。</p><p><img data-src="https://z3.ax1x.com/2021/08/30/hNeo7D.png" alt></p><ul><li><code>:split</code> 为垂直分屏，<code>:vsplit</code> 为水平分屏。</li><li><code>ctrl+w+hjkl</code> 用于切换分屏，还记得之前说过的方向键盘吗？</li><li><code>ctrl+w+</code> 增加尺寸，<code>ctrl+w-</code> 缩小尺寸。</li></ul><p>当然只是分屏还是不爽的，能不能直接在 <code>vim</code> 中编译或解释直接查看代码的执行结果而不是每次都要退出去？答案肯定还是有的，不过准备放到后面的打造 <code>vim</code> 了，这里还是以学习 <code>vim</code> 命令为主。</p><ul><li><code>.</code>，小数点是重复上次的命令</li><li><code>N&lt;cmd&gt;</code> 重复命令 N 次，这个命令不用进入 <code>normal</code> 模式</li><li>如写一百遍名字，命令就是 <code>100iname</code> </li></ul><p>此外，我发现复制粘贴用的还是比较多的，所以再来整理一些复制的命令。</p><ul><li><code>ye</code>，复制光标后面的单词，不含空格</li><li><code>yw</code>，复制光标后面的单词，含空格</li><li><code>yl</code>，复制光标后面的字符，<code>l</code> 是方向键的右</li><li><code>yh</code>，复制光标前面的字符，<code>h</code> 是方向键的左</li><li><code>4yy</code>，复制当前行及后面的3行共4行</li><li><code>4yl</code>，当前字符及后面的3个字符，共4个</li><li><code>4yh</code>，当前字符前面的4个字符，不包括当前字符</li></ul><p>同理，<code>d</code> 是剪切的命令，且大体和 <code>y</code> 相似：</p><ul><li><code>dd</code>，剪切当前行</li><li><code>4dd</code>，剪切当前行及后面的3行，共4行</li><li><code>dw</code>，剪切光标后面的单词，含空格</li></ul><p>今天学习内容结束，大概还差区域选择、块操作、宏录制和可视化选择；在之后就会尝试把 vim 打造成 IDE 了，一去不复返。</p><h1 id="第五天"><a href="#第五天" class="headerlink" title="第五天"></a>第五天</h1><p>我又额外补充了一些插件换了主题来提升效率。<code>wakatime</code> 记录编程时间，<code>nerdtree</code> 显示工作目录，<code>startify</code> 显示近期打开的文件，<code>onehalfdark</code> 作为主题。</p><p>在服务器上体验了一把裸敲 <code>vim</code> 的快感，首先补充一些光标移动的东西，快速定位到想要的位置，这玩意太重要了。</p><ul><li><code>fa</code> 移动到下一个为 <code>a</code> 的字符处；<code>3fa</code> 移动到第三个 <code>a</code> 的位置；<code>F</code> 与 <code>f</code> 的查找顺序刚好相反。</li><li><code>t,</code> 到逗号前的一个字符，这里暂不支持中文字符 <del>难道以后我写文档要用英文符号了？</del></li></ul><p>此外，在编程时候会常用块操作，比如注释某个函数，或者 <code>python</code> 中的某段内容全部缩进，就需要块操作来实现。</p><ul><li>光标定位到要操作的地方；</li><li><code>ctrl+v</code> 进入「块可视化」模式，选取要操作的行；</li><li><code>shift+i</code> 输入要插入的内容；</li><li><code>esc</code> 按两次，会在每行的选定的区域出现插入的内容。</li></ul><p>另外的内容是区域选择，命令为 <code>&lt;action&gt;a&lt;object&gt;</code> 或者 <code>&lt;action&gt;i&lt;object&gt;</code>，两者的区别是，前者会选中 <code>object</code>，后者则不会。给定字符串 <code>((a) + (&quot;b+c&quot;)</code>。</p><ul><li>光标位于 <code>b</code>，<code>vi&quot;</code> 会选中 <code>b+c</code>，<code>va&quot;</code> 会选中 <code>&quot;b+c&quot;</code>；</li><li>光标位于 <code>b</code>，<code>v2i)</code> 会选中 <code>(a) + (&quot;b+c&quot;)</code>，<code>v2a)</code> 会选中全部</li></ul><p>今天的学习内容到此结束，其实很多时候都在查漏不缺，每次都要花很多时间联系，所以虽然内容很少，但是内容很多（误。</p><h1 id="第六天"><a href="#第六天" class="headerlink" title="第六天"></a>第六天</h1><p>今天大概是最后一天了，是一些批处理的内容，宏录制和块选择。可惜最近学业繁忙，事情太多，不能学的尽兴。如果之后时间充裕或者不想学习，一定花时间继续打造我的 <code>vim</code>，主要包括：编程语言的支持、自动提示、以及如何不退出 <code>vim</code> 直接执行程序。</p><p>首先是宏录制，这个功能十分强大。这里只举一个例子，如何给文件每一行末尾添加逗号：<del>如果功能过于复杂，我第一反应肯定是写脚本处理。</del></p><ol><li>按 <code>q</code> 加 <code>a~z</code> 中的任意字符，如 <code>qc</code> 表示开始录制宏，这个宏的名字叫 <code>c</code>，而后可以使用 <code>c</code> 来调用宏；</li><li>比如对文件的每一行末尾条件逗号，那么就是如下操作 <code>$a,ESC,j</code>，注意结束时移动到下一行；</li><li>再次输入 <code>q</code>，表示退出宏录制；</li><li><code>n@c</code> 表示执行宏命令 <code>n</code> 次；</li></ol><p>注意，录制上面的宏时，会修改第一行的内容，不用担心。除了宏之外，可视化选择也提供了丰富的选择，例如第五天提到的批量注释。<del>其实录制宏也能实现。</del> 今天就来细看可视化模式。</p><p>首先，<code>v</code> 是进入字符可视化模式，<code>V</code> 进入行可视化模式，<code>ctrl+v</code> 进入块可视化模式。<code>gv</code> 可以选中上次可视化模式选中的文本；<code>o</code> 会移动到选中区域的另一侧。 </p><ul><li>对于 <code>v</code>，进入可视化模式后移动光标，使用 <code>4l</code> 选中右边的 4 个字符，按 <code>d</code> 删除</li><li>对于 <code>V</code>，进入行可视化模式，同样的是选中，而后操作</li><li>对于 <code>ctrl-v</code>，进入块可视化模式，可以使用 <code>2l</code> 和 <code>3j</code> 选择两行三列</li></ul><p>而按照上面三种方法选中文本后，都可以进行编辑，如 <code>C</code> 删除选中文本并插入新文本，<code>~</code> 进行大小写替换，<code>ctrl+v</code> 进入块可视化模式，选中行后<code>J</code> 将这些行连成一行，<code>&gt;</code> 向右缩进<code>&lt;</code> 向左缩进，<code>=</code> 自动缩进。</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p><code>vim</code> 学习的内容到此结束，我宣布第 5 次 <code>vim</code> 学习顺利结束，完结撒花。不保证本文覆盖全部内容，但至少能看懂常见的命令，以及遇到问题知道往哪个方向搜索。之后的插件配置会放到 <code>github</code> 仓库里面了，那些东西放到这里也没啥用。还是那句话，不会走就别着急学跑，<code>vim</code> 还没学会就打造 IDE 和装插件的意义也不大。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;学习 vim 的时候曾经4进4出一直没学会，这次下定决心要学一下了，也不求一口吃个胖子，每天学习一点点。首先从基础操作开始练习，先不要配置插件，也不管高亮和编程。&lt;del&gt;IDE是人类退步的阶梯&lt;/del&gt;，沃茨基说的。&lt;/p&gt;
&lt;p&gt;当然，这份文档不一定包含所有命令，只是教学的目的，遇到没有涵盖的命令自行查阅即可。有些命令是我自己的总结，不一定对。此外，本文涉及的命令之间可以任意组合实现各类高级功能，这个没办法统一列出。&lt;/p&gt;
&lt;p&gt;此外，纸上得来终觉浅，学习 vim 一定多动手练习，在平时任务中多用 vim，自然而然就掌握了。我前后花了 6 天能使用 vim 应付日常开发工作，所以本文也叫六天掌握 vim。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Vim" scheme="https://muyuuuu.github.io/tags/Vim/"/>
    
  </entry>
  
  <entry>
    <title>YOLO目标检测从 V1 开始，细读代码</title>
    <link href="https://muyuuuu.github.io/2021/08/26/yolo-v1/"/>
    <id>https://muyuuuu.github.io/2021/08/26/yolo-v1/</id>
    <published>2021-08-26T11:06:48.000Z</published>
    <updated>2022-01-03T08:46:01.738Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>忙里偷闲，写几篇长文，从 YOLO 的 v1 到 v5。没想到时隔多年会回来重新看 YOLO 系列的东西，相比两阶段检测，YOLO 真的太快了，加上一些训练的 trick，mAP 也不会很低。网上看了好多教程不明所以，索性还是直接去读原论文了，读了原论文有些东西还是不理解，索性又去读了源程序。不过为了便于理解，有的地方不会按照论文顺序进行整理。少问问题，读论文产生的疑问在代码里都有解答，不看代码永远不能被称为学会了。</p><a id="more"></a><p>如果对本文有疑问或者想找男朋友，可以联系我，<a href="https://muyuuuu.github.io/about/">点击此处有我联系方式</a>。</p><h1 id="YOLO-v1"><a href="#YOLO-v1" class="headerlink" title="YOLO v1"></a>YOLO v1</h1><ul><li>论文地址：<a href="https://arxiv.org/abs/1506.02640" target="_blank" rel="noopener">https://arxiv.org/abs/1506.02640</a></li><li>pytorch 程序地址：<a href="https://github.com/motokimura/yolo_v1_pytorch" target="_blank" rel="noopener">https://github.com/motokimura/yolo_v1_pytorch</a></li></ul><p>YOLO v1 将目标检测定义为回归问题，直接读入全部图像，回归出边界框和分类概率。与同时期的 Faster RCNN 对比，算法快了不少，也没有 RPN 以及后处理，也避免里滑动窗口这样的暴力检测。所以能用到一些实时系统中，也是我花精力看这一些列论文的原因。</p><p>但是对于 v1 的 YOLO 存在一些缺陷，作者在论文中也进行了阐述：准确率低、定位不准尤其是小目标的定位。</p><h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p>首先将图片分为 $S\times S$ 个网格，论文中 $S=7$，如果一个物体的中心落入这个格子中，那么这个格子负责预测这个目标。设每个格子负责预测 $B$ 个物体的盒子参数和置信度得分，盒子参数指明物体的位置，置信度表示盒子含有目标且预测准确的可信程度。即对于图片的每个格子，会输出 $B$ 个 $(x,y,w,h,c)$，论文中 $B=2$。</p><p>既然有了输出，那么就需要 label 进行损失计算。$(x,y,w,h,c)$ 是人工标注的数据，$c$ 初始化为 1。论文定义网络输出的置信度标签是一个分段函数，如果格子没有目标，置信度是 0；如果有目标，置信度是预测框和真实框的 IOU 值，公式描述为 $\text{Pr(Object)} * \text{IOU}_{\text{pred}}^\text{truth}$。</p><p>目标检测和分类是分不开的，为了达到分类的目的，每个格子也会输出 $C$ 个类别的概率，公式表述为 $\text{Pr(Class}_i|\text{Object})$，即格子里面得是个目标，才能计算分类的概率和损失。而每个格子输出一组<a href="https://github.com/motokimura/yolo_v1_pytorch/blob/master/detect.py#L203-L206" target="_blank" rel="noopener">预测</a>，即使输出了 $B$ 组数据，这就限制了网络的表达。</p><p>在测试阶段，类别置信度的分数就是分类概率和置信度相乘，即盒子中「有这个类别的概率」和「网络预测这个类别的概率」的乘积：</p><p>\begin{equation}<br>\text{Pr(Class}_i|\text{Object})*\text{Pr(Object)}*\text{IOU}_{\text{pred}}^\text{truth}=\text{Pr(Class}_i) * \text{IOU}_{\text{pred}}^\text{truth}<br>\end{equation}</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>这种东西还是代码清楚，只放了最关键的检测输出：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nn.Linear(<span class="number">4096</span>, S * S * (<span class="number">5</span> * B + C))</span><br><span class="line">nn.Sigmoid()</span><br><span class="line">x.view(<span class="number">-1</span>, S, S, <span class="number">5</span> * B + C)</span><br></pre></td></tr></table></figure><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>\begin{aligned}<br>{ } &amp; \lambda_{coord} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{I}_{ij}^{\text{obj}} [(x_i-\hat{x}_i)^2 + (y_i-\hat{y}_i)^2] \\<br>{ } &amp;+ \lambda_{coord} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{I}_{ij}^{\text{obj}} [(\sqrt{w_i}-\sqrt{\hat{w}_i})^2+(\sqrt{h_i}-\sqrt{\hat{h}_i})^2] \\<br>{ } &amp;+ \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{I}_{ij}^{\text{obj}} (C_i - \hat{C}_i)^2 \\<br>{ } &amp;+ \lambda_{noobj} \sum_{i=0}^{S^2} \sum_{j=0}^{B} \mathbb{I}_{ij}^{\text{noobj}} (C_i - \hat{C}_i)^2 \\<br>{ } &amp;+ \sum_{i=0}^{S^2} \mathbb{I}_{ij}^{\text{obj}} \sum_{c\in classes} (p_i(c)-\hat{p}_i(c))^2<br>\end{aligned}</p><ul><li>$\lambda_{coord}$ 是前景的权重，$\mathbb{I}_{ij}^{\text{obj}}$ 是指示函数，取值只有 0 和 1</li><li>前两行表示 bound box 的损失</li><li>第三行是前景置信度的损失</li><li>第四行是背景置信度的损失</li><li>第五行是分类的损失</li></ul><h2 id="缺陷"><a href="#缺陷" class="headerlink" title="缺陷"></a>缺陷</h2><ol><li>每个网格只能检测一个类别和两个目标，类间竞争严重，网络表达受限，对于密集群体的检测性能会下降；</li><li>定位不准确，因为网络直接预测 bounding box 的坐标，一开始的偏移可能会很大，导致定位不准确，读完代码能深刻理解这里的缺陷；</li><li>对于检测问题而言，大多情况背景居多，前景居少，也就是样本不均衡。YOLO v1 的损失中，并没有计算背景的 bound box 损失，只计算了前景的，YOLO v1 回避了样本不均衡的问题，这会影响网络的稳定性与背景的识别。</li></ol><h1 id="程序解析"><a href="#程序解析" class="headerlink" title="程序解析"></a>程序解析</h1><p>「如果对算法有疑问，就去读代码吧」这一经验帮助我理解了很多算法的困惑之处，不仅仅是 YOLO。如果要看懂一个深度学习的算法，核心有三要素，首先是网络模型，理解输入、输出和结构；其次是数据与损失，理解加载什么格式的数据，理解网络预测数据和加载的数据如何计算损失，所以这俩常常放在一起；最后是细枝末节，即数据增强、学习率策略、整体训练流程等。所以接下来整理网络模型和损失。<del>训练策略那些不是 YOLO 的重点。</del></p><h2 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h2><p>我们知道网络的输出是 <code>x.view(-1, S, S, 5 * B + C)</code> 这种类型的格式，这是预测数据，即 $S \times S $ 组 $5 \times B + C$ 这样的数据，$C$ 是类别数量。那么可想而知，在训练阶段，同样需要提供同等尺寸大小的标签数据。</p><h2 id="数据与损失"><a href="#数据与损失" class="headerlink" title="数据与损失"></a>数据与损失</h2><p>YOLO 处理目标时，使用的是目标中心点的坐标相对图像大小的占比。如果一张图像的大小是 224 X 224，目标中心点位于 112 X 112，那么中心点的坐标是 $(0.5,0.5)$。这有两点好处：</p><ol><li>如果一个图像的尺寸是 1920 X 1080，目标中心点的坐标是 1000 X 1000，直接输出 1000 对于网络来说难以把控，会造成梯度爆炸的现象。而占比只需要输出 [0,1] 之间的小数，不会导致梯度爆炸。</li><li>方便图像的标准化处理。网络常常使用多个 batch 进行训练，每个 batch 的数据要求大小统一，对于不同尺寸的图像应选择 <code>resize</code>。如果直接用坐标，<code>resize</code> 后会导致坐标错位，而如果用占比，位于之前图像 (0.5, 0.5) 处的点在 <code>resize</code> 后的坐标仍然是 (0.5, 0.5)。</li></ol><p>由于 YOLO 最初设计的方案是：物体中心落到哪个格子，就由这个格子预测这个目标，这一观点需要仔细阅读代码才能理解。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 和网络输出同等大小的标签</span></span><br><span class="line">target = torch.zeros(S, S, N)</span><br><span class="line"><span class="comment"># S=7，表示每个格子的占比</span></span><br><span class="line">cell_size = <span class="number">1.0</span> / float(S)</span><br><span class="line"><span class="comment"># 计算宽度和高度</span></span><br><span class="line">boxes_wh = boxes[:, <span class="number">2</span>:] - boxes[:, :<span class="number">2</span>]</span><br><span class="line"><span class="comment"># x,y 的中心点坐标，此时已经除以图像大小</span></span><br><span class="line">boxes_xy = (boxes[:, <span class="number">2</span>:] + boxes[:, :<span class="number">2</span>]) / <span class="number">2.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于 b 和 batch 的盒子进行处理</span></span><br><span class="line"><span class="keyword">for</span> b <span class="keyword">in</span> range(boxes.size(<span class="number">0</span>)):</span><br><span class="line">    xy, wh, label = boxes_xy[b], boxes_wh[b], int(labels[b])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算中心点位于哪个格子</span></span><br><span class="line">    ij = (xy / cell_size).ceil() - <span class="number">1.0</span></span><br><span class="line">    <span class="comment"># 取出 i j，用于 SXS 的填充</span></span><br><span class="line">    i, j = int(ij[<span class="number">0</span>]), int(ij[<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 格子左上角的坐标</span></span><br><span class="line">    x0y0 = ij * cell_size</span><br><span class="line">    <span class="comment"># 相对格子左上角的坐标</span></span><br><span class="line">    <span class="comment"># 除以 cell_size 没啥用，这人代码写的有问题，后面损失计算的时候又乘了回来</span></span><br><span class="line">    xy_normalized = (xy - x0y0) / cell_size</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始填充</span></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(B):</span><br><span class="line">        s = <span class="number">5</span> * k</span><br><span class="line">        target[j, i, s  :s+<span class="number">2</span>] = xy_normalized <span class="comment"># 坐标</span></span><br><span class="line">        target[j, i, s+<span class="number">2</span>:s+<span class="number">4</span>] = wh            <span class="comment"># 大小</span></span><br><span class="line">        target[j, i, s+<span class="number">4</span>    ] = <span class="number">1.0</span>           <span class="comment"># 置信度</span></span><br><span class="line">    target[j, i, <span class="number">5</span>*B + label] = <span class="number">1.0</span>           <span class="comment"># 类别标签</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> target</span><br></pre></td></tr></table></figure><p>在损失计算阶段，代码真的太长了不便展示，这里只记录核心要素：</p><ol><li>对于有目标计算损失，无目标忽略这一点，是通过对真实标签进行掩码处理实现的，只取出真实标签中置信度为 1 的标签记录维度，并在 predict 中取出同维度的数据就算损失，其余数据忽略。假设这一步保留了 $X$ 个盒子。</li><li>对于 $X$ 个盒子中的 $B$ 组数据继续处理，对于每组数据而言，选择和真实标签 IOU 最大的盒子计算损失，其余盒子忽略，也就是没有正负样本的概念。这里需要注意，如果网络初期计算到 IOU 为 0，那么默认第一个盒子和真实标签进行损失计算。</li></ol><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>我已经正负样本划分、格子、bounding box、anchor box 的概念已经搞混了，论文里不会写这太细节的东西，不然我也不会来读代码。毕竟整理理论知识太简单了，也容易自欺欺人，并不清楚网络的流程。所以 YOLO v2, v3, v4, v5 和 x 的内容等下几篇博客了。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol><li><a href="https://zhuanlan.zhihu.com/p/183261974" target="_blank" rel="noopener">你一定从未看过如此通俗易懂的YOLO系列(从v1到v5)模型解读</a></li><li><a href="https://fengweiustc.github.io/paper-reading/2020/06/17/yolo/" target="_blank" rel="noopener">YOLO v1/v2/v3/v4</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;忙里偷闲，写几篇长文，从 YOLO 的 v1 到 v5。没想到时隔多年会回来重新看 YOLO 系列的东西，相比两阶段检测，YOLO 真的太快了，加上一些训练的 trick，mAP 也不会很低。网上看了好多教程不明所以，索性还是直接去读原论文了，读了原论文有些东西还是不理解，索性又去读了源程序。不过为了便于理解，有的地方不会按照论文顺序进行整理。少问问题，读论文产生的疑问在代码里都有解答，不看代码永远不能被称为学会了。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>C++ 多线程</title>
    <link href="https://muyuuuu.github.io/2021/08/12/cpp-thread-safe/"/>
    <id>https://muyuuuu.github.io/2021/08/12/cpp-thread-safe/</id>
    <published>2021-08-12T10:05:47.000Z</published>
    <updated>2021-08-13T16:29:10.787Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>rush 项目的时候，有些地方可以并行化，可以借助 C++ 的多线程来加速程序的执行。多线程的基本概念在一年前整过了，这里只是来看一下 C++ 的多线程该怎么写，顺便查漏补缺。</p><a id="more"></a><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>在多线程进入 C++ 标准之前，人们使用 C++ 编写多线程的程序，只能依赖操作系统提供的 API。比如在 Linux 环境下就只能使用 pthread 库实现多线程，因此也一直被诟病。但有了 C++11 的 <code>std::thread</code> 以后，可以通过标准库在语言层面编写多线程程序了，直接的好处就是多线程程序的跨平台移植提供了便利。但是在编译的时候需要注意链接平台相关的线程库，如 <code>g++ demo.cpp -lpthread -o test.o</code>。</p><h1 id="简单实例"><a href="#简单实例" class="headerlink" title="简单实例"></a>简单实例</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">show_info</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">string</span> str)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; str &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> s&#123;<span class="string">"hello world"</span>&#125;;</span><br><span class="line">    <span class="built_in">std</span>::thread t&#123;show_info, s&#125;;</span><br><span class="line">    t.join();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上述程序为例，来详细的剖析一下多线程期间到底发生了什么：</p><ol><li>首先引入头文件 <code>thread</code>，在这个头文件中，C++ 11 提供了创建、管理线程的类和方法；</li><li>使用 <code>std::thread</code> 创建线程，并通过列表初始化传入函数名作为构造函数的参数。传入的函数会作为子线程的入口函数，也就是说，当子线程准备就绪之后，就会开始执行这个入口函数。由于函数名表示函数的地址，子线程可以快捷的找到函数地址进而执行。<blockquote><p>我们知道，每个程序都有一个入口。当程序被装载到内存，处于系统态完成一些初始化的工作之后，控制权就转交给程序入口，并以此为标志进入用户态，这是一个程序的开始。同样地，线程也需要有「开始」的地方。作为线程入口的函数，就是线程函数，也就是例子中的 show_info。线程函数必须在启动线程之前，就准备好，否则线程去执行什么呢？并在线程初始化后立即执行。<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p></blockquote></li><li>当线程函数返回时，线程也就随之终止了，上述程序中使用 <code>join</code> 衔接方法确保主线程在子线程退出之后才退出，因为主线程会阻塞住，直到该子线程退出为止。如果程序员没有显式的说明线程结束该如何处理，那么线程对象在被销毁时调用的析构函数中，会调用 <code>std::terminate()</code> 函数，销毁当前对象。如果程序写多了，应该不至于犯主线程退出子线程还没结束的低级错误。</li></ol><h2 id="detach"><a href="#detach" class="headerlink" title="detach"></a>detach</h2><p>前面说过线程的 <code>join</code> 会阻塞调用线程，可以使用 <code>detach</code> 来避免，但一定要做好控制：避免主线程退出子线程还没结束的低级错误。一个 cppreference 官网的例子：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;chrono&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">independentThread</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Starting concurrent thread.\n"</span>;</span><br><span class="line">    <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::seconds(<span class="number">2</span>));</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Exiting concurrent thread.\n"</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">threadCaller</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Starting thread caller.\n"</span>;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t</span><span class="params">(independentThread)</span></span>;</span><br><span class="line">    t.detach();</span><br><span class="line">    <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::seconds(<span class="number">1</span>));</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Exiting thread caller.\n"</span>;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    threadCaller();</span><br><span class="line">    <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::seconds(<span class="number">5</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Starting thread caller.</span></span><br><span class="line"><span class="comment">// Starting concurrent thread.</span></span><br><span class="line"><span class="comment">// Exiting thread caller.</span></span><br><span class="line"><span class="comment">// Exiting concurrent thread.</span></span><br></pre></td></tr></table></figure><h1 id="可调用类型"><a href="#可调用类型" class="headerlink" title="可调用类型"></a>可调用类型</h1><p>在创建线程对象时，传入的参数不仅是可被调用执行的函数，类的对象如果能被调用，也是可以作为线程对象的参数，用于构造函数初始化线程对象。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Task</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> cnt;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">Task</span><span class="params">()</span></span>=<span class="keyword">default</span>;</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">Task</span><span class="params">(<span class="keyword">int</span> a)</span> : cnt</span>&#123;a&#125; &#123;&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">operator</span><span class="params">()</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="keyword">this</span>-&gt;cnt &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::thread t&#123;Task&#123;<span class="number">1</span>&#125;&#125;;</span><br><span class="line">    t.join();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因为要调用对象，所以重载了 <code>()</code> 运算符，不然线程不知道去哪个地址执行。此外，构造函数传入的是一个类类型的对象，所以对象会被拷贝到线程的存储空间，而后再开始执行。因此，<strong>类必须做好足够的拷贝控制</strong>，不然将出现难以调试的 bug，<del>我大概只知道深浅拷贝，等有时间了去看下移动语义</del>。</p><p>当然，不重载 <code>()</code> 运算符，选择类中的函数执行也是可以的，不过需要注意以下两点：</p><ul><li>必须显式地使用函数指针，作为 <code>std::thread</code> 构造函数的第一个参数；知道执行哪个函数。</li><li>非静态成员函数的第一个参数，实际上是类实例的指针。所以在创建线程时，需要显式地填入这个参数；知道执行的函数在哪个对象。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>&#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> a;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">A</span><span class="params">()</span></span>=<span class="keyword">default</span>;</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">A</span><span class="params">(<span class="keyword">int</span> t)</span> : a</span>&#123;t&#125; &#123;&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">show_info</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="keyword">this</span>-&gt;a &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    A a&#123;<span class="number">12</span>&#125;;</span><br><span class="line">    <span class="built_in">std</span>::thread t&#123;&amp;A::show_info, &amp;a&#125;;</span><br><span class="line">    t.join();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="其他要注意的数据类型"><a href="#其他要注意的数据类型" class="headerlink" title="其他要注意的数据类型"></a>其他要注意的数据类型</h1><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><p>如果子线程函数的参数是引用类型，也需要格外注意。由于子线程的数据是主线程的拷贝，因此子线程函数得到的拷贝实际是「线程存储空间中的拷贝的引用」，并不是主线程中的变量，应该使用 <code>std::ref()</code> 来生成正确的引用绑定，否则会报错。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">show_info</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">string</span>&amp; s)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; s &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> s&#123;<span class="string">"hello world"</span>&#125;;</span><br><span class="line">    <span class="built_in">std</span>::thread t&#123;show_info, <span class="built_in">std</span>::ref(s)&#125;;</span><br><span class="line">    t.join();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><del>右值引用和移动语义等我后期开坑了。</del></p><h1 id="锁与线程安全"><a href="#锁与线程安全" class="headerlink" title="锁与线程安全"></a>锁与线程安全</h1><p>众所周知，<del>写代码的人都学过操作系统，学过操作系统都知道线程同步</del>。线程同步一般有三种机制：互斥量、信号量和条件变量，这三者到底什么已经在<a href="https://muyuuuu.github.io/2021/02/19/process-synchronization/">这篇博客</a>中详细的描写过了，所以不再多说。不过当时是用 C 语言写的，现在来了解下 C++ 的写法。</p><h2 id="mutex"><a href="#mutex" class="headerlink" title="mutex"></a>mutex</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;chrono&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> counter = <span class="number">0</span>;</span><br><span class="line"><span class="built_in">std</span>::mutex mtx;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">increase</span><span class="params">(<span class="keyword">int</span> time)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; time; i++) &#123;</span><br><span class="line">        mtx.lock();</span><br><span class="line">        <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::milliseconds(<span class="number">1</span>));</span><br><span class="line">        counter++;</span><br><span class="line">        mtx.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t1</span><span class="params">(increase, <span class="number">100</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t2</span><span class="params">(increase, <span class="number">100</span>)</span></span>;</span><br><span class="line">    t1.join();</span><br><span class="line">    t2.join();</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"counter:"</span> &lt;&lt; counter &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>引入 <code>mutex</code> 头文件，创建 <code>std::mutex</code> 对象 <code>mtx</code></li><li>对于 <code>mtx</code> 对象，任意时刻最多允许一个线程对其进行上锁，上锁后操作变量，就不会出错</li><li><code>mtx.try_lock()</code> 是尝试上锁，如果上锁不成功，当前线程不阻塞</li><li>在用完锁之后一定记得释放锁，否则会发生死锁现象</li></ol><h2 id="lock-guard"><a href="#lock-guard" class="headerlink" title="lock_guard"></a>lock_guard</h2><p>为了避免 <code>mutex</code> 忘记解锁等情况，可以使用 <code>std::lock_guard</code>，<a href="https://en.cppreference.com/w/cpp/thread/lock_guard" target="_blank" rel="noopener">这个类</a>只有构造函数和析构函数，搭配 <code>mutex</code> 使用，在创建这个对象时传入锁，调用锁的 <code>lock</code> 函数；变量销毁会调用析构函数，此时调用锁的 <code>unlock</code> 函数，这也就是传说中的 RAII 机制 <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。</p><p>如下述程序 <sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> ，避免一个线程意外退出没来得及释放锁，导致另一个线程无法获取资源而死锁。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;chrono&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdexcept&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> counter = <span class="number">0</span>;</span><br><span class="line"><span class="built_in">std</span>::mutex mtx;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">increase_proxy</span><span class="params">(<span class="keyword">int</span> time, <span class="keyword">int</span> id)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; time; i++) &#123;</span><br><span class="line">        <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lk</span><span class="params">(mtx)</span></span>;</span><br><span class="line">        <span class="keyword">if</span> (id == <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="built_in">std</span>::runtime_error(<span class="string">"throw excption...."</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 当前线程休眠1毫秒</span></span><br><span class="line">        <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::milliseconds(<span class="number">1</span>));</span><br><span class="line">        counter++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">increase</span><span class="params">(<span class="keyword">int</span> time, <span class="keyword">int</span> id)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        increase_proxy(time, id);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">catch</span> (<span class="keyword">const</span> <span class="built_in">std</span>::exception&amp; e)&#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"id:"</span> &lt;&lt; id &lt;&lt; <span class="string">", "</span> &lt;&lt; e.what() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t1</span><span class="params">(increase, <span class="number">100</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t2</span><span class="params">(increase, <span class="number">100</span>, <span class="number">2</span>)</span></span>;</span><br><span class="line">    t1.join();</span><br><span class="line">    t2.join();</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"counter:"</span> &lt;&lt; counter &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="lock-guard-与-adopt-lock"><a href="#lock-guard-与-adopt-lock" class="headerlink" title="lock_guard 与 adopt_lock"></a>lock_guard 与 adopt_lock</h2><p>还有一种为了防止死锁的方式是一次性申请所有临界资源的互斥量，只有申请到才能进行之后的操作，而 <code>std::lock</code> 提供了这种实现 <sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>。此外，为了防止没有锁定或提前释放互斥量导致危险，可以使用 <code>lock_guard</code> 并传入 <code>std::adopt_lock</code>，前者保证当变量销毁时释放互斥量，后者保证线程已经上锁成功时不再调用 <code>lock()</code> 函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">bank_account</span> &#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">bank_account</span><span class="params">(<span class="keyword">int</span> balance)</span> : <span class="title">balance</span><span class="params">(balance)</span> </span>&#123;&#125;</span><br><span class="line">    <span class="keyword">int</span> balance;</span><br><span class="line">    <span class="built_in">std</span>::mutex m;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">transfer</span><span class="params">(bank_account &amp;from, bank_account &amp;to, <span class="keyword">int</span> amount)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// avoid deadlock in case of self transfer</span></span><br><span class="line">    <span class="keyword">if</span>(&amp;from == &amp;to) </span><br><span class="line">        <span class="keyword">return</span>; </span><br><span class="line">    <span class="comment">// lock both mutexes without deadlock</span></span><br><span class="line">    <span class="built_in">std</span>::lock(from.m, to.m);</span><br><span class="line">    <span class="comment">// make sure both already-locked mutexes are unlocked at the end of scope</span></span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock1</span><span class="params">(from.m, <span class="built_in">std</span>::adopt_lock)</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock2</span><span class="params">(to.m, <span class="built_in">std</span>::adopt_lock)</span></span>;</span><br><span class="line"></span><br><span class="line">    from.balance -= amount;</span><br><span class="line">    to.balance += amount;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function">bank_account <span class="title">my_account</span><span class="params">(<span class="number">100</span>)</span></span>;</span><br><span class="line">    <span class="function">bank_account <span class="title">your_account</span><span class="params">(<span class="number">50</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t1</span><span class="params">(transfer, <span class="built_in">std</span>::ref(my_account), <span class="built_in">std</span>::ref(your_account), <span class="number">10</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::thread <span class="title">t2</span><span class="params">(transfer, <span class="built_in">std</span>::ref(your_account), <span class="built_in">std</span>::ref(my_account), <span class="number">5</span>)</span></span>;</span><br><span class="line">    t1.join();</span><br><span class="line">    t2.join();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>除了 <code>adopt_lock</code> 之外，还有 <code>try_to_lock</code>，<code>defer_lock</code>，他们都有不同的应用场景，还可以配合使用：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print_block</span> <span class="params">(<span class="keyword">int</span> n, <span class="keyword">char</span> c)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//unique_lock有多组构造函数, 这里std::defer_lock不设置锁状态</span></span><br><span class="line">    <span class="function"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">my_lock</span> <span class="params">(mtx, <span class="built_in">std</span>::defer_lock)</span></span>;</span><br><span class="line">    <span class="comment">//尝试加锁, 如果加锁成功则执行</span></span><br><span class="line">    <span class="comment">//(适合定时执行一个job的场景, 一个线程执行就可以, 可以用更新时间戳辅助)</span></span><br><span class="line">    <span class="keyword">if</span>(my_lock.try_lock()) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i)</span><br><span class="line">            <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; c;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">'\n'</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其他锁的内容实在是太多了，还有时间锁、递归锁、<code>lock_unique</code>，读写锁的 <code>shared_lock</code> 等等，等哪天用到在整理这些，这里只整理最简单的，详情可以参考 cppreference <sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>。</p><h1 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h1><p>如果按照之前 <code>C</code> 语言的写法，条件变量需要注意的是 <code>wait</code> 那边的判断一定是 <code>while</code> 循环。<a href="https://blog.7rule.com/2018/11/24/thread.html" target="_blank" rel="noopener"><code>C</code> 语言风格的代码</a>。</p><p>当然，如果按照 <code>C++</code> 的写法，我们发现条件变量的 <code>wait</code> 方法有<a href="https://en.cppreference.com/w/cpp/thread/condition_variable/wait" target="_blank" rel="noopener">两个参数</a>，第二个参数用于接受一个变量，如果继续等待，那么那个变量的取值是 <code>false</code>，如果不需等待，那么那个变量返回 <code>true</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;condition_variable&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="built_in">std</span>::mutex g_mutex;</span><br><span class="line"><span class="built_in">std</span>::condition_variable g_cond;</span><br><span class="line"><span class="keyword">int</span>  g_i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">bool</span> g_running = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ThreadFunc</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock</span><span class="params">(g_mutex)</span></span>; </span><br><span class="line">      ++g_i;</span><br><span class="line">      <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"plus g_i by func thread "</span> </span><br><span class="line">                &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 等待被唤醒</span></span><br><span class="line">  <span class="function"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock</span><span class="params">(g_mutex)</span></span>;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"wait for exit"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">  g_cond.wait(lock, [=] &#123;<span class="keyword">return</span> g_running;&#125;);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"func thread exit"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> n = <span class="number">100</span>;</span><br><span class="line">  <span class="function"><span class="built_in">std</span>::thread <span class="title">t1</span><span class="params">(ThreadFunc, n)</span></span>;</span><br><span class="line">  <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::seconds(<span class="number">1</span>));</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock</span><span class="params">(g_mutex)</span></span>;</span><br><span class="line">      ++g_i;</span><br><span class="line">      <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"plus g_i by main thread "</span> </span><br><span class="line">                &lt;&lt; <span class="built_in">std</span>::this_thread::get_id() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 唤醒</span></span><br><span class="line">  &#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock</span><span class="params">(g_mutex)</span></span>;</span><br><span class="line">    g_running = <span class="literal">true</span>;</span><br><span class="line">    g_cond.notify_one();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  t1.join();</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"g_i = "</span> &lt;&lt; g_i &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">plus g_i by func thread 140476623930944</span><br><span class="line">plus g_i by func thread 140476623930944</span><br><span class="line">wait for exit // 表示子线程等待唤醒</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">plus g_i by main thread 140476623935296</span><br><span class="line">func thread exit // 子线程被唤醒</span><br><span class="line">g_i = 200</span><br></pre></td></tr></table></figure><h1 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h1><p>因为一开始我也不知道该怎么去写信号量，所以打开了万能的搜索引擎，看到了关于 C++ 不支持信号量这样的东西 <sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>。如果想实现信号量，可以通过互斥量和条件变量来实现。而关于信号量和互斥量的区别，在<a href="https://muyuuuu.github.io/2021/02/19/process-synchronization/">这篇文章</a>中已经写明了。那么来实现一个信号量的类 <sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup>：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;mutex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;condition_variable&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Semaphore</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="built_in">std</span>::mutex mutex_;</span><br><span class="line">  <span class="built_in">std</span>::condition_variable cv_;</span><br><span class="line">  <span class="keyword">int</span> count_;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">Semaphore</span><span class="params">(<span class="keyword">int</span> count = <span class="number">0</span>)</span> : <span class="title">count_</span><span class="params">(count)</span> </span>&#123;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">Signal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">    ++count_;</span><br><span class="line">    cv_.notify_one();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">Wait</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::unique_lock&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock</span><span class="params">(mutex_)</span></span>;</span><br><span class="line">    <span class="comment">// 第二个参数，如果返回 false 继续等待, 如果为 true，可以继续申请资源</span></span><br><span class="line">    cv_.wait(lock, [=] &#123; <span class="keyword">return</span> count_ &gt; <span class="number">0</span>; &#125;);</span><br><span class="line">    --count_;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="built_in">std</span>::<span class="built_in">string</span> <span class="title">FormatTimeNow</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* format)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> now = <span class="built_in">std</span>::chrono::system_clock::now();</span><br><span class="line">  <span class="built_in">std</span>::<span class="keyword">time_t</span> now_c = <span class="built_in">std</span>::chrono::system_clock::<span class="keyword">to_time_t</span>(now);</span><br><span class="line">  <span class="built_in">std</span>::tm* now_tm = <span class="built_in">std</span>::localtime(&amp;now_c);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">char</span> buf[<span class="number">20</span>];</span><br><span class="line">  <span class="built_in">std</span>::strftime(buf, <span class="keyword">sizeof</span>(buf), format, now_tm);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">std</span>::<span class="built_in">string</span>(buf);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Semaphore <span class="title">g_semaphore</span><span class="params">(<span class="number">3</span>)</span></span>;</span><br><span class="line"><span class="comment">// 防止同时抢占输出资源</span></span><br><span class="line"><span class="built_in">std</span>::mutex g_io_mutex;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Worker</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  g_semaphore.Wait();</span><br><span class="line"></span><br><span class="line">  <span class="built_in">std</span>::thread::id thread_id = <span class="built_in">std</span>::this_thread::get_id();</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">string</span> now = FormatTimeNow(<span class="string">"%H:%M:%S"</span>);</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="function"><span class="built_in">std</span>::lock_guard&lt;<span class="built_in">std</span>::mutex&gt; <span class="title">lock</span><span class="params">(g_io_mutex)</span></span>;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"Thread "</span> &lt;&lt; thread_id &lt;&lt; <span class="string">": wait succeeded"</span> </span><br><span class="line">              &lt;&lt; <span class="string">" ("</span> &lt;&lt; now &lt;&lt; <span class="string">")"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Sleep 1 second to simulate data processing.</span></span><br><span class="line">  <span class="built_in">std</span>::this_thread::sleep_for(<span class="built_in">std</span>::chrono::seconds(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">  g_semaphore.Signal();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::thread&gt; v;</span><br><span class="line">  <span class="keyword">for</span> (<span class="built_in">std</span>::<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; ++i) &#123;</span><br><span class="line">    v.emplace_back(&amp;Worker);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="built_in">std</span>::thread&amp; t : v) &#123;</span><br><span class="line">    t.join();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>信号量的值为 3，表示能同时申请 3 个资源</li><li>当一个线程申请资源后，即执行了 <code>wait</code> 操作，<code>count_</code> 取值递减，表示有一个资源被占用</li><li>当 <code>count_</code> 取值小于 0 时，调用条件变量的 <code>wait</code> 方法，当先线程等待有了资源被唤醒</li><li>当一个线程释放资源后，执行了 <code>signal</code> 操作，<code>count_</code> 取值递增，表示有一个资源被释放，并执行 <code>notify_one</code> 方法，即唤醒一个等待的线程</li></ul><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;"><a href="https://liam.page/2017/05/16/first-step-on-multithread-programming-of-cxx/" target="_blank" rel="noopener">线程函数</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;"><a href="https://zhuanlan.zhihu.com/p/34660259" target="_blank" rel="noopener">RAII机制</a></span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;"><a href="https://zhuanlan.zhihu.com/p/91062516" target="_blank" rel="noopener">线程异常退出导致死锁</a></span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">4.</span><span style="display: inline-block; vertical-align: top;"><a href="https://en.cppreference.com/w/cpp/thread/lock" target="_blank" rel="noopener">std::lock申请多个互斥量</a></span><a href="#fnref:4" rev="footnote"> ↩</a></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">5.</span><span style="display: inline-block; vertical-align: top;"><a href="https://en.cppreference.com/w/cpp/thread/lock_tag_t" target="_blank" rel="noopener">cppreference_lock</a></span><a href="#fnref:5" rev="footnote"> ↩</a></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">6.</span><span style="display: inline-block; vertical-align: top;"><a href="https://www.boost.org/doc/libs/1_31_0/libs/thread/doc/faq.html" target="_blank" rel="noopener">C++不支持信号量</a></span><a href="#fnref:6" rev="footnote"> ↩</a></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">7.</span><span style="display: inline-block; vertical-align: top;"><a href="https://segmentfault.com/a/1190000006818772" target="_blank" rel="noopener">信号量实现</a></span><a href="#fnref:7" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;rush 项目的时候，有些地方可以并行化，可以借助 C++ 的多线程来加速程序的执行。多线程的基本概念在一年前整过了，这里只是来看一下 C++ 的多线程该怎么写，顺便查漏补缺。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="C++" scheme="https://muyuuuu.github.io/tags/C/"/>
    
      <category term="OS" scheme="https://muyuuuu.github.io/tags/OS/"/>
    
  </entry>
  
  <entry>
    <title>花样繁多的GAN</title>
    <link href="https://muyuuuu.github.io/2021/08/11/GAN-basic/"/>
    <id>https://muyuuuu.github.io/2021/08/11/GAN-basic/</id>
    <published>2021-08-11T01:39:51.000Z</published>
    <updated>2021-08-13T16:35:18.453Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在做对抗样本的时候，我发现对抗防御和 GAN 在某种程度上很像：</p><ul><li>对抗防御：内部生成对抗样本攻击分类器，分类器更新参数防御攻击；</li><li>GAN：生成器 $G$ 生成样本欺骗判别器，判别器更新防御 $G$ 的欺骗。</li></ul><p>所以说，这俩在某种程度上真的很像，所以决定整理一下 GAN 的知识，开拓一下思路，视频内容来自<a href="https://www.bilibili.com/video/BV1JE411g7XF?from=search&amp;seid=17206901754423397958" target="_blank" rel="noopener">这里</a>。警告：里面有大量数学公式的推导，而我就不一样了，<del>不仅有公式推导</del>还有代码。</p><a id="more"></a><h1 id="前情提要"><a href="#前情提要" class="headerlink" title="前情提要"></a>前情提要</h1><p>我发现我在看论文或者别人的博客的时候，经常发现数据分布、概率分布等，然而时间长了竟然不知道所谓的分布是什么，这里来提前说一下：</p><ul><li>数据分布：可以理解为字面意思，数据的分布。比如一个数据集：<code>1,2,3</code>，只有三条数据，可能是 1，可能是 2，可能是 3，这就是数据的分布；</li><li>概率分布：可以理解为字面意思，概率的分布。比如一枚硬币，正面朝上的概率是 50%，反面朝上的概率也是 50%，这就是概率分布，类似的，正态分布、泊松分布等都是概率分布。</li></ul><h1 id="朴素-GAN"><a href="#朴素-GAN" class="headerlink" title="朴素 GAN"></a>朴素 GAN</h1><p><img data-src="https://z3.ax1x.com/2021/08/11/fNaeNF.png" alt></p><p>以图像为例，GAN 的生成器 $G$ 输入为某种随机分布的数据，输出为一张图像；而判别器 $D$ 的输入是一张图像，输出是一个数字，数字越大表示当前图像的质量越高，我们设置 $G$ 生成的图片是假的。两者相互博弈，$G$ 企图去欺骗 $D$，$D$ 防止来自 $G$ 的欺骗。</p><ul><li>$G$ 只适合生成，不适合做判别，因为 $G$ 的主要任务是生成图像。如果 $G$ 要判别图像的好坏，如何定义生成图像的好坏？生成图像的每个像素点的位置、偏移、颜色、旋转，以及像素点之间的联系将会很复杂，模型将会很复杂，所以由 $D$ 来做判别；</li><li>$D$ 只适合判别，不适合生成。$D$ 的判别是宏观角度的判断当前图像好不好，并不会纠结于某个像素的颜色、旋转、偏移的好坏。如果 $D$ 要做生成，那么需要遍历所有数据 $x$，来看看哪个数据使得网络的输出得分最高。这样虽然可以生成，但枚举所有数据是不可能的操作。</li></ul><p>或者说，这是一种<strong>另类的小样本</strong>，网络不可能见过所有生成的数据，但是要求 $D$ 能判断没见过的数据是好是坏。此外，<strong>足够强的 $D$ 才能迫使 $G$ 生成的图片足够逼真，足够好的 $G$ 才会使 $D$ 的判别越来越准。</strong> 在接下来的实验中将见识到这一点。</p><p><img data-src="https://z3.ax1x.com/2021/08/11/fN64Kg.png" alt></p><p>如上图所示：横坐标为 $G$ 和 $D$ 的演化过程，纵坐标表示概率分布，红色曲线表示 $G$，红色的点表示 $G$ 生成的数据，绿色的线表示 $D$,绿色的点表示真实数据。</p><ol><li>首先，图的最左侧，$G$ 生成的数据和真是数据不符，那么判别器抑制 $G$ 把数据生成到其他分布，并希望 $G$ 生成的数据分布和真实数据的分布较为接近；</li><li>其次，图的中间，因为 $G$ 的目的是无限度找 $D$ 的漏洞，虽然相比左图，生成数据的分布和真实数据的分布接近了，但是把更多的数据生成到了另外的分布，这也是不行的；</li><li>经过多次的博弈，最终达到右侧图的效果。</li></ol><h2 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h2><h3 id="G-的目标"><a href="#G-的目标" class="headerlink" title="$G$ 的目标"></a>$G$ 的目标</h3><p>我们的目标可以用公式表述为：通过 $G$，寻找数据 $x$ 的分布 $P_G(x)$，但是目前只有数据 $x$，也就是知道近似的 $P(x)$。可以通过极大似然估计来求解问题，使 $P_G(x)$ 逐渐逼近 $P(x)$，即在 $P(x)$ 中采 $m$ 个样本，使得 $\prod_{i=1}^mP_G(x_i;\theta)$ 的概率最大，逐步采样与迭代求出模型的参数 $\theta$。</p><p>\begin{aligned}<br>\theta &amp;= \arg \max_\theta \prod_{i=1}^mP_G(x_i;\theta) \\<br>       &amp;\Leftrightarrow \arg \max_\theta \log \prod_{i=1}^mP_G(x_i;\theta) \\<br>       &amp;= \arg \max_\theta \sum_{i=1}^m \log P_G(x_i;\theta) \\<br>       &amp;\Leftrightarrow \arg \max_\theta \mathbb{E}_{x\sim p(x)} \bigl[ \log P_G(x;\theta) \bigr] \\<br>       &amp;\Leftrightarrow \arg \max_\theta \int_x p(x) \log P_G(x;\theta) dx - \int_x p(x) \log P(x) dx \\<br>       &amp;= \arg \min_\theta KL(P(x) || P_G(x;\theta))<br>\end{aligned}</p><p>也就是说，生成模型的求出的 $P_G(x;\theta)$ 最好情况就是与真是数据的分布 $P(x)$ 的 $KL$ 散度距离最小。当然你也可以用其他距离，详情可以参考 f-GAN <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> 这篇论文，不过究其到底，都可以描述为寻找一个 $P_G(x;\theta)$，使其生成的数据分布和 $P(x)$ 最为接近， $G^\star=\arg\min_G D(P_G(x;\theta), P(x))$。</p><p>当然在模型参数过多的情况下，极大似然估计求解困难，可以使用神经网络的反向传播，来求解出模型的参数。</p><h3 id="D-的目标"><a href="#D-的目标" class="headerlink" title="$D$ 的目标"></a>$D$ 的目标</h3><p>对于 $D$ 而言，其目标是期望真实数据的评分很高，$G$ 生成数据的评分很低，以此来鼓励 $G$ 生成更加逼真的数据达到内卷的目的。那么 $D$ 的目标可以描述为：</p><p>\begin{equation}\label{D}<br>\max \mathbb{E}_{x\sim P(x)} \bigl[ \log D(x) \bigr] + \mathbb{E}_{x\sim P_G(x;\theta)} \bigl[ \log(1-D(x)) \bigr]<br>\end{equation}</p><p>此时固定 $G$，训练 $D$，式 $\eqref{D}$ 继续推导：</p><p>\begin{aligned}<br>\eqref{D} &amp;= \int_x P(x) \log (D(x)) dx+ \int_x P_G(x) \log (1 - D(x)) dx \\<br>&amp;= \int_x P(x) \log (D(x)) + P_G(x) \log (1 - D(x)) dx\\<br>\end{aligned}</p><p>为了使积分最大，可以等价转换为使积分内部的元素取值最大，即对于以下公式求对 $D(x)$ 微分，微分等于0的时候，取得极值，且下述公式是极大值：</p><p>\begin{equation}<br>f(D(x)) = P(x) \log (D(x)) + P_G(x) \log (1 - D(x))<br>\end{equation}</p><p>此时求出的 $D(x)$：</p><p>\begin{equation}<br>D(x) = \frac{P(x)}{P(x)+P_G(x)}<br>\end{equation}</p><p>把 $D(x)$ 带回式 $\eqref{D}$ ：</p><p>\begin{aligned}<br>\eqref{D} &amp;= \mathbb{E}_{x\sim P(x)} \bigl[ \log \frac{P(x)}{P(x)+P_G(x)} \bigr] + \mathbb{E}_{x\sim P_G(x)} \bigl[ \log \frac{P_G(x)}{P(x)+P_G(x)} \bigr] \\<br>&amp;= \int_x P(x)\log \frac{P(x)}{P(x)+P_G(x)} dx + \int_x P_G(x)\log \frac{P_G(x)}{P(x)+P_G(x)} dx \\<br>&amp;= -2\log 2 + KL(P(x) || \frac{P(x) + P_G(x)}{2}) + KL(P_G(x) || \frac{P(x) + P_G(x)}{2}) \\<br>&amp;= -2\log 2 + 2 JS(P(x) || P_G(x))<br>\end{aligned}</p><p>而 JS 散度的取值范围是 $[0, \log2]$，因此 式 $\eqref{D}$ 的最大值为 0。而这里的代码实现可以使用 <code>torch.BCE</code>，但要按照负梯度进行反向传播，所以损失那里直接加了负数，因此代码的损失是正数不要感到意外。</p><h2 id="code"><a href="#code" class="headerlink" title="code"></a>code</h2><p>既然有了模型结构和公式推导，那么来看一下代码改怎么写，以 <code>MNIST</code> 数据集为例，全部代码在 <a href="https://github.com/muyuuuu/colab/blob/main/GAN/minmaxGAN.ipynb" target="_blank" rel="noopener"><code>github</code></a>。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment"># g_input_dim = 100, g_output_dim=784</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, g_input_dim, g_output_dim)</span>:</span></span><br><span class="line">        super(Generator, self).__init__()       </span><br><span class="line">        self.fc1 = nn.Linear(g_input_dim, <span class="number">256</span>)</span><br><span class="line">        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*<span class="number">2</span>)</span><br><span class="line">        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*<span class="number">2</span>)</span><br><span class="line">        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span> </span><br><span class="line">        x = F.leaky_relu(self.fc1(x), <span class="number">0.2</span>)</span><br><span class="line">        x = F.leaky_relu(self.fc2(x), <span class="number">0.2</span>)</span><br><span class="line">        x = F.leaky_relu(self.fc3(x), <span class="number">0.2</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.tanh(self.fc4(x))</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment"># d_input_dim = 784</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d_input_dim)</span>:</span></span><br><span class="line">        super(Discriminator, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(d_input_dim, <span class="number">1024</span>)</span><br><span class="line">        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//<span class="number">2</span>)</span><br><span class="line">        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//<span class="number">2</span>)</span><br><span class="line">        self.fc4 = nn.Linear(self.fc3.out_features, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.leaky_relu(self.fc1(x), <span class="number">0.2</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.3</span>)</span><br><span class="line">        x = F.leaky_relu(self.fc2(x), <span class="number">0.2</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.3</span>)</span><br><span class="line">        x = F.leaky_relu(self.fc3(x), <span class="number">0.2</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.3</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(self.fc4(x))</span><br><span class="line"></span><br><span class="line">n_epoch = <span class="number">200</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">1</span>, n_epoch+<span class="number">1</span>):           </span><br><span class="line">    D_losses, G_losses = [], []</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (x, _) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">            D_train(x)</span><br><span class="line">        D_losses.append(D_train(x))</span><br><span class="line">        G_losses.append(G_train(x))</span><br></pre></td></tr></table></figure><p>$D$ 为什么要比 $G$ 多训练两次？因为只有去够好的 $D$，此案能使得 $G$ 也好，$G$ 好了 $D$ 也会好；否则 $D$ 很差，$G$ 也懒得更新，生成的结果会很差。此外，如果两者都只训练一次，我发现 $D$ 的损失是逐步上升的。如下图所示，右侧是 $D$ 训练三次的，左侧是 $D$ 训练一次的效果，明显发现右侧的效果要好一些。</p><p><img data-src="https://z3.ax1x.com/2021/08/11/fNru9O.png" alt></p><h1 id="WGAN-GP"><a href="#WGAN-GP" class="headerlink" title="WGAN-GP"></a>WGAN-GP</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>通过前文我们可以了解到，如果 $D$ 训练得太弱，指示作用不显著，则 $G$ 不能进行有效的学习；但是，如果 $D$ 训练得太好， $G$ 就无法得到足够的梯度继续优化，这样一来， $D$ 的训练火候就非常难把控，这就是 GAN 训练难的根源。如下图所示：</p><p><img data-src="https://z3.ax1x.com/2021/08/11/fUlFNn.png" alt></p><ul><li>左侧的 $D$ 很弱，$G$ 也不知道哪边好哪边弱；</li><li>右侧的 $D$ 很强，存在梯度消失和梯度爆炸问题，即在区域 $G$ 获取到的梯度近似为0而无法获得有效的更新。</li></ul><blockquote><p>说点通俗的话，你在学习，你的老师太弱，你学不出来；你的老师太强，无论你怎么学老师都说你是错的，即使进步是有效的，但还是被你的老师说没用，那么之前的进步也可能会回退，你还是学不出来。</p></blockquote><h2 id="朴素-GAN-的缺陷"><a href="#朴素-GAN-的缺陷" class="headerlink" title="朴素 GAN 的缺陷"></a>朴素 GAN 的缺陷</h2><p>虽然有着完备的理论推导，但是朴素 GAN 仍有以下的缺陷：</p><ul><li>对于 $D$ 的目标，经过推导会发现竟然要最大化 $P(x)$ 和 $P_G(x;\theta)$ 的距离，显然违背了 $D$ 的初衷，或者说，不是这样判别的；关于 $D$ 计算距离的缺陷，这里 <sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> 有详细公式推导。</li><li>对于 $G$ 的目标，如果一味的最小化 $P_G(x;\theta)$ 和 $P(x)$ 的距离，会使生成的数据只有安全性，没有多样性，这显然也是不好的。</li></ul><h2 id="Wasserstein-距离"><a href="#Wasserstein-距离" class="headerlink" title="Wasserstein 距离"></a>Wasserstein 距离</h2><p>于是，如何巧妙的<strong>衡量生成分布与真实分布之间的距离</strong>，WGAN 定义了 Wasserstein 距离。即：</p><p>\begin{equation}<br>W(P(x), P_G(x;\theta))=\inf_{\gamma\sim\prod(P(x), P_G(x;\theta))} \mathbb{E}_{(x,y)\sim \gamma} \bigl[ \Vert| x-y \Vert \bigr]<br>\end{equation}</p><p>$\prod(P(x), P_G(x;\theta))$ 是 $P(x)$ 和 $P_G(x;\theta)$ 联合分布的集合，对于每一个联合分布 $\gamma$ 从中取样，得到一个真实样本 $x$ 和一个虚假样本 $y$，并计算联合分布 $\gamma$ 中两两样本的距离 $\Vert x-y \Vert$，这也就是 Wasserstein 距离。意思是，从 $y$ 移动到 $x$ 需要多远，即便两个分布没有重叠，Wasserstein 距离仍然能够反映它们的远近。</p><p>既然如此，那么就把 Wasserstein 距离用到 GAN 中，由于 $\inf$ 是最大下确界，所以：</p><p>\begin{aligned}<br>W(P(x), P_G(x;\theta)) &amp; \leq \int_{P(x), P_G(x;\theta)} \Vert x-y \Vert d\gamma \\<br>{ }&amp; = \mathbb{E}_{(x,y)\sim \gamma} \bigl[ \Vert x-y \Vert \bigr] \\<br>&amp;= \mathbb{E}_{x\sim P(x)} D(x) - \mathbb{E}_{x\sim P_G(x;\theta)} D(G(x))<br>\end{aligned} </p><p>至此，真实分布与生成分布之间的 Wasserstein 距离融入到了 GAN 中。朴素 GAN 的 $D$ 做的是真假二分类任务，所以最后一层是 sigmoid，但是现在 WGAN 中的 $D$ 做的是近似拟合 Wasserstein 距离，属于回归任务，所以要把 $D$ 最后一层的 sigmoid 拿掉。</p><p>接下来 $G$ 要最小化 Wasserstein 距离，$D$ 要最大化 Wasserstein 距离的优良性质，也不需要担心 $D$ 导致的梯度消失的问题，这样就得到了WGAN的两个loss，$G$ 的 loss 是 $- \mathbb{E}_{x\sim P_G(x;\theta)} D(G(x))$，$D$ 的 loss 是 $-\mathbb{E}_{x\sim P(x)} D(x) + \mathbb{E}_{x\sim P_G(x;\theta)} D(G(x))$ （距离最小，取负号）。</p><p>为了使距离不在梯度消失问题和梯度爆炸，后续有论文进行了改进 <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>，并不是直接对 $D$ 的权重进行裁剪限制在某个范围内，而是加入了惩罚项，因此 $D$ 的损失函数变为：</p><p>\begin{equation}<br>-\mathbb{E}_{x\sim P(x)} D(x) + \mathbb{E}_{x\sim P_G(x;\theta)} D(G(x)) + \lambda \mathbb{E}_{\hat{x}\sim P(\hat{x})} \bigl( \Vert \nabla_\hat{x} D(\hat{x}) \Vert_2 - 1 \bigr)^2<br>\end{equation}</p><p>$\hat{x}$ 是真实数据和虚假数据的随机采样，也就是说，希望 $D$ 对 $\hat{x}$ 数据的梯度保持在都是 1 左右，这样就不用再考虑梯度消失问题和梯度爆炸问题，虚假数据也好往真实数据去移动。最终的算法如下所示：</p><p><img data-src="https://z3.ax1x.com/2021/08/11/fU5bh4.png" alt></p><p>WGAN 有以下优势：</p><ul><li>不再需要纠结如何平衡 $G$ 和 $D$ 的训练程度，大大提高了GAN 训练的稳定性,$D$ 训练得越好，对提升 $G$ 就越有利。</li><li>即使网络结构设计得比较简陋，WGAN 也能展现出良好的性能，包括避免了样本不够多样性的现象，体现了出色的鲁棒性。</li><li>$D$ 的 loss 很准确地反映了 $G$ 生成样本的质量，因此可以作为展现 GAN 训练进度的定性指标。</li></ul><h2 id="code-1"><a href="#code-1" class="headerlink" title="code"></a>code</h2><p>完整代码在 <a href="https://github.com/muyuuuu/colab/blob/main/GAN/WGAN-GP.ipynb" target="_blank" rel="noopener"><code>github</code></a>，这里只展示计算惩罚项的部分：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_gradient_penalty</span><span class="params">(D, real_samples, fake_samples)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># [0, 1] 之间的随机数</span></span><br><span class="line">    alpha = torch.rand(<span class="number">1</span>).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成 \hat&#123;x&#125;</span></span><br><span class="line">    x = (alpha * real_samples + ((<span class="number">1</span> - alpha) * fake_samples)).requires_grad_(<span class="literal">True</span>).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># D 对生成数据的梯度控制为 1 左右，所以计算梯度</span></span><br><span class="line">    interpolates = D(x)</span><br><span class="line"></span><br><span class="line">    fake = torch.ones(bs, <span class="number">1</span>).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算 D(x) 对 interpolates 的梯度</span></span><br><span class="line">    gradients = torch.autograd.grad(</span><br><span class="line">        outputs=interpolates, <span class="comment"># 用来求导的</span></span><br><span class="line">        inputs=x,             <span class="comment"># 被求导的梯度值</span></span><br><span class="line">        grad_outputs=fake,    <span class="comment"># 求梯度时对输出的权重</span></span><br><span class="line">        create_graph=<span class="literal">True</span>,    <span class="comment"># 创建计算图</span></span><br><span class="line">    )[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    gradient_penalty = ((gradients.norm(<span class="number">2</span>, dim=<span class="number">1</span>) - <span class="number">1</span>) ** <span class="number">2</span>).mean()</span><br><span class="line">    <span class="keyword">return</span> gradient_penalty</span><br></pre></td></tr></table></figure><p>可能是我网络设置的比较简单，效果并不是很好：</p><div class="table-container"><table><thead><tr><th style="text-align:center"><center> After 100 epochs </center></th><th style="text-align:center"><center>After 200 epochs</center></th><th style="text-align:center"><center>After 300 epochs</center></th><th style="text-align:center"><center>After 400 epochs</center></th><th style="text-align:center"><center>After 500 epochs</center></th></tr></thead><tbody><tr><td style="text-align:center"><img data-src="https://z3.ax1x.com/2021/08/12/fwc9JA.png" alt></td><td style="text-align:center"><img data-src="https://z3.ax1x.com/2021/08/12/fwcnij.png" alt></td><td style="text-align:center"><img data-src="https://z3.ax1x.com/2021/08/12/fwclQ0.png" alt></td><td style="text-align:center"><img data-src="https://z3.ax1x.com/2021/08/12/fwcBy6.png" alt></td><td style="text-align:center"><img data-src="https://z3.ax1x.com/2021/08/12/fwcseO.png" alt></td></tr></tbody></table></div><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>本文涉及了大量的公式推导，从朴素的 GAN 推到了 WGAN-GP。此外，还有啥 conditional GAN，infoGAN，BigGAN，cycleGAN，XGAN 等等等等，不过那些东西脱离了我要做的内容，所以，等哪天空闲了，会简单的整理这些模型的框架和 idea，如果不忙会尝试复现一个 photo shop。</p><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;"><a href="https://arxiv.org/pdf/1606.00709.pdf" target="_blank" rel="noopener">f-GAN论文</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;"><a href="https://arxiv.org/pdf/1704.00028.pdf" target="_blank" rel="noopener">Improved WGAN</a></span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;"><a href="https://zhuanlan.zhihu.com/p/25071913" target="_blank" rel="noopener">判别器JS散度距离缺陷</a></span><a href="#fnref:3" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在做对抗样本的时候，我发现对抗防御和 GAN 在某种程度上很像：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对抗防御：内部生成对抗样本攻击分类器，分类器更新参数防御攻击；&lt;/li&gt;
&lt;li&gt;GAN：生成器 $G$ 生成样本欺骗判别器，判别器更新防御 $G$ 的欺骗。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以说，这俩在某种程度上真的很像，所以决定整理一下 GAN 的知识，开拓一下思路，视频内容来自&lt;a href=&quot;https://www.bilibili.com/video/BV1JE411g7XF?from=search&amp;amp;seid=17206901754423397958&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;这里&lt;/a&gt;。警告：里面有大量数学公式的推导，而我就不一样了，&lt;del&gt;不仅有公式推导&lt;/del&gt;还有代码。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DeepLearning" scheme="https://muyuuuu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
</feed>
