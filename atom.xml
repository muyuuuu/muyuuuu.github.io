<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Just for Life.</title>
  
  <subtitle>明月更几时</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://muyuuuu.github.io/"/>
  <updated>2021-07-31T20:44:32.937Z</updated>
  <id>https://muyuuuu.github.io/</id>
  
  <author>
    <name>兰铃</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Arch 折腾全记录，彻底告别 Windows</title>
    <link href="https://muyuuuu.github.io/2021/07/31/Arch-config/"/>
    <id>https://muyuuuu.github.io/2021/07/31/Arch-config/</id>
    <published>2021-07-31T19:51:26.000Z</published>
    <updated>2021-07-31T20:44:32.937Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>想来想去，以壮士断腕的决心决定抛弃垃圾 <code>windows</code> 了，实在是 <code>TMD</code> 卡的要死，但是以我电脑的配置，不可能卡的。加上 <code>C</code> 盘的无理由暴增，<code>TMD</code> 空间锐减，加上每次系统动不动更新，每次更新都 <code>TMD</code> 出 <code>bug</code> 直接卡死。我宁肯花一周的时间打造一款我的主力 <code>Arch Linux</code> ，再 <code>TMD</code> 也不向 <code>windows</code> 低头了。以本文记录 <code>Arch Linux</code> 的折腾全记录。</p><p>包括：代理、终端、字体、换源更新、软件、甚至是博客迁移等。最重要的是，关于向这个世界的妥协，如何使安装 QQ、微信和 word 等非必要但深入人心的软件。毕竟老板让你微信给他发文件还是很常见的，毕竟老板没手没脚，发一次不接收必须发第 $N$ 次，毕竟他用 LaTeX 也要手动编号。</p><a id="more"></a><h1 id="关于代理"><a href="#关于代理" class="headerlink" title="关于代理"></a>关于代理</h1><p>我用的是 <code>clash</code>，直接 <code>sudo pacman -s clash</code> 即可，而后将其设置为开机启动，后台自己执行。<a href="https://github.com/Sitoi/SystemdClash" target="_blank" rel="noopener">相关参考</a>。</p><p>不过刚到新系统，一般会面临先有鸡还是先有蛋的问题，即：代理服务在国外，没有代理买不了服务，没有服务就出不去。所以，提前找同学接好代理，注意：有些代理只能在 <code>windows</code> 使用，一定要看好 <code>linux</code> 是否可以用。</p><h1 id="关于输入法"><a href="#关于输入法" class="headerlink" title="关于输入法"></a>关于输入法</h1><p><a href="https://www.cnblogs.com/qscgy/p/13385905.html" target="_blank" rel="noopener">文章推荐</a>，关于安装和配置就这个写的比较好，网上其他教程太垃圾且过时。在配置输入法的时候记得选择里面的 <code>pinyin</code>，其他的中文输入不行，然后重启即可。</p><h1 id="关于更新与换源"><a href="#关于更新与换源" class="headerlink" title="关于更新与换源"></a>关于更新与换源</h1><p><code>sudo pacman -Syu</code>，同步仓库即同步本地软件和仓库中软件的最新状态，更新所有系统上被 <code>pacman</code> 管理的的软件。<code>Su</code> 升级系统；<code>Syy</code> 会只刷新数据库。</p><p><strong>Arch Linux 中文社区仓库</strong> 是由 Arch Linux 中文社区驱动的非官方软件仓库，包含许多官方仓库未提供的额外的软件包，以及已有软件的 git 版本等变种。一部分软件包的打包脚本来源于 AUR，但也有许多包与 AUR 不一样。以清华大学的源为例，在 <code>/etc/pacman.conf</code> 文件末尾添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[archlinuxcn]</span><br><span class="line">Server = https://mirrors.tuna.tsinghua.edu.cn/archlinuxcn/$arch</span><br></pre></td></tr></table></figure><p>因为所有软件包都是经过开发者私钥签名，验证签名需要导入对应的公钥，即：安装 <code>archlinuxcn-keyring</code> 包以导入 GPG key。</p><p>当然，有些软件不一定在 archlinuxcn 源中，所以其它软件的换源方式为：编辑 /etc/pacman.d/mirrorlist，文件顶端添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Server = https://mirrors.tuna.tsinghua.edu.cn/archlinux/$repo/os/$arch</span><br></pre></td></tr></table></figure><p>更新软件包缓存：<code>sudo pacman -Syy</code>。</p><h1 id="关于浏览器"><a href="#关于浏览器" class="headerlink" title="关于浏览器"></a>关于浏览器</h1><p>我使用的浏览器是 <code>google-chrome-stable</code>，因为 <code>chromium</code> 不支持登录谷歌帐号，插件、书签无法同步，且 <code>chromium wiki</code> 上提供的解决方案也是曲线救国，我不喜欢。</p><p><img data-src="https://z3.ax1x.com/2021/07/31/Wv01K0.png" alt></p><p>在 <code>pacman -S google-chrome-stable</code> 后，因为浏览器不能使用代理而无法为了科学上网。我查了一下可以使用 <code>proxychains</code>，但是配合 <code>google-chrome-stable</code> 使用时会直接 <code>core dumped</code>，查了一下据说是这俩软件水火不容。而后我又查到了其它用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">google-chrome-stable --proxy-server=&quot;socks5://127.0.0.1:7891&quot;</span><br></pre></td></tr></table></figure><p>这样开启的浏览器是有代理的，然后登录 <code>chrome</code>，登录谷歌，直接同步，一切都很舒服。</p><h1 id="关于字体"><a href="#关于字体" class="headerlink" title="关于字体"></a>关于字体</h1><p>掏出万能的 wiki 文档，发现安装字体的三种方式：</p><ul><li>如果有人打包，那么 <code>sudo pacman -S ttf-lxgw-wenkai</code>，这是一款我比较喜欢的字体，这样通过包管理器的方式安装；</li><li>如果没人打包，可以手动下载字体，将字体移动到 <code>/usr/share/fonts/</code> 目录，所有用户可用；如果是个人用户可用，那么就放到 <code>~/.local/share/fonts</code>，而后使用 <code>fc-cache -vf</code> 刷新字体缓存。字体权限是 <code>644</code>，-rw-r—r— 1。</li></ul><p>安装完毕后，可以在设置-&gt;字体中，配置自己喜欢的字体，如果没有立即生效，记得重启。关于 <code>latex</code> 如何调用系统的字体，时而文件名、时而字体名，时而镜像中克隆的名字，等改天单独写吧。</p><p>一般而言，<code>sans serif</code> 表示无衬线字体，<code>Serif</code> 表示衬线字体，<code>Noto</code> 表示谷歌命名的字体，<code>Mono</code> 是等宽字体。我一般使用的字体是：思源宋体黑体、<code>source code pro</code> 和 <code>IBM Plex Mono</code>，落霞孤鹜等。</p><h1 id="关于终端"><a href="#关于终端" class="headerlink" title="关于终端"></a>关于终端</h1><ul><li>更改系统默认终端：<code>sudo chsh -s /usr/bin/bash</code>，如果切换失败，可以尝试进入 <code>root</code> 切换或 <code>usermod -s /usr/bin/fish lanling</code> 命令，查看系统默认终端：<code>cat /etc/shells</code>；</li><li><code>shell</code> 用的是 <code>fish</code> 毕竟是真的舒服，<code>oh my zsh</code> 太乱了。系统自带的 <code>konsole</code> 配和 <code>oh my zsh</code> 时常乱码，但是，不可否认，<code>konsole</code> 分屏、配色、标签页等各个方面都极度强大。</li></ul><p><img data-src="https://z3.ax1x.com/2021/07/31/Wv07dS.jpg" alt></p><p>所以我决定抛弃 <code>zsh</code>。注意切换终端时需要注意：进入 <code>root</code> 切换，不能在当前用户切换，否则下次重启电脑无法进入系统（并不是密码错误，我确实遇到了这个问题）。然后我登录了 <code>root</code> 用户，发现切换到子用户时：<code>failed to execute /bin/zsh</code>，说明 <code>shell</code> 没切换成功，而后两种方案，一种是装回 <code>zsh</code> ，一种是在 <code>root</code> 端切换为 <code>bash</code>，这样用户端就能进入系统了。</p><ul><li>而后选择的新 <code>shell</code> 是 <code>fish</code>，<code>sudo pacman -S fish</code> 即可，在终端执行 <code>ish_config</code>，进入 <code>web</code> 端的颜色配置。</li><li><code>set -U fish_prompt_pwd_dir_length 0</code> 会在终端现实全部的路径，如 <code>code/github/Face/Detect</code>，否则是 <code>c/g/F/D</code> 很难看。</li></ul><h1 id="关于软件"><a href="#关于软件" class="headerlink" title="关于软件"></a>关于软件</h1><p>列出我使用的软件，对于如何安装 QQ，微信和 word，将在文末给出。</p><ul><li><code>telegram</code>，吹水与交流技术</li><li><code>peek</code>，录制 <code>gif</code></li><li><code>visual-studio-code-bin</code>，写代码</li><li><code>clash</code>，懂得都懂</li><li><code>google-chrome-stable</code>，浏览器</li><li><code>typora</code>，写 <code>markdown</code> 的东西</li><li><code>flameshot</code>，截图工具，比深度截图好用一百倍</li></ul><p>此外，还设置了一些软件开启自启动：<code>flameshot</code>，<code>clash</code> 等。</p><p>软件的快捷键自己设置吧，我只设置了终端、浏览器，截图的快捷键。位于设置、自定义快捷键、编辑、新建、全局快捷键、命令。</p><h1 id="关于美化"><a href="#关于美化" class="headerlink" title="关于美化"></a>关于美化</h1><p>众所周知，不美化还怎么写代码，但是我友情提示一下：以我多年美化的经验而言，美化的尽头绝对是系统默认。</p><ul><li>底部的 <code>dock</code> 栏可以使用 <code>plank</code> 这个软件，但是无法和状态栏配合双屏使用，于是卸载。</li><li>设置、外观里面设置主题。</li><li>如果设置无法打开，那么查看是否有 <code>systemsettings5</code> 进程没彻底杀死，如果有，杀死即可。</li><li>而后自己折腾吧，<code>i3wm</code> 有点无从下手的样子。我尝试折腾了一下，直接黑屏，除了鼠标啥都没有，然后不知道动了哪个配置文件，<code>KDE</code> 都回不去了，系统会自动退出到登陆界面，登陆后还是退出，一个死循环。无奈，删除账户，新建账户，第六次重装系统。</li></ul><h1 id="关于博客搬家"><a href="#关于博客搬家" class="headerlink" title="关于博客搬家"></a>关于博客搬家</h1><p>我的博客是基于 <code>hexo</code> 的，而之前的博客在 windows 上，所以要进行博客搬家。博客搬家倒是很容易，先安装必要依赖：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo pacman -S nodejs</span><br><span class="line">sudo pacman -S npm</span><br><span class="line">npm config set registry https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure><p>而后在安装 <code>hexo</code> 的时候有坑，有坑的是传统方案：<code>npm install -g hexo-cli</code>，这样会发现没权限，而后 <code>sudo npm install -g hexo-cli</code>，但这是很烂的行为，因为 <code>Arch</code> 的包最好用 <code>pacman</code> 管理起来，而 <code>npm</code> 安装的并不会被管理。所以，掏出万能的 <code>AUR</code>，发现里面有 <code>hexo</code>，安装即可。</p><p>之后的东西就简单了，新建博客路径，拷贝原始博客的文件到新的路径下：</p><ol><li>博客配置文件./_config.yml</li><li>主题配置文件夹./theme/</li><li>文章及相关内容的文件夹./source/</li><li>模板文件夹./scaffolds/</li><li>记录博客所有的插件的文件./package.json</li></ol><p>最后进入博客目录，执行 <code>npm install</code>，而后就可以使用博客了，这也是我换系统后的第一篇博客。</p><h1 id="关于善后"><a href="#关于善后" class="headerlink" title="关于善后"></a>关于善后</h1><p><code>word, excel, ppt, qq, wechat</code> 等软件如何使用或者寻找替代品也是必须要妥协的，毕竟很多人都在用，毕竟大部分人都不知道 latex 和 telegram 的存在。</p><h2 id="wps"><a href="#wps" class="headerlink" title="wps"></a>wps</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p ~/Software/AUR</span><br><span class="line">cd ~/Software/AUR</span><br><span class="line">git clone https://aur.archlinux.org/wps-office-cn.git</span><br><span class="line">cd wps-office-cn</span><br><span class="line">makepkg -si</span><br></pre></td></tr></table></figure><p>而后按下 <code>meta</code> 键，就可以搜到了。再把字体从自己的 <code>windows</code> 系统拷贝过来，这样 <code>wps</code> 就有字体了，我是把字体拷贝到了 <code>/usr/share/fonts</code>。注意，安装完毕之后，<code>Software/AUR</code> 是可以删除的。</p><h2 id="qq"><a href="#qq" class="headerlink" title="qq"></a>qq</h2><p>无论是安装 QQ 还是 Tim，我试了网上和 wiki 说的那些什么用 <code>yay</code> 安装 <code>qq, deepin, office, wine, light</code> 乱七八糟的无法装成功，不如直接用官方构建好的包。去 <a href="https://im.qq.com/pcqq" target="_blank" rel="noopener">官方</a> 下载对应的发行版的包，<code>arch</code> 就下载 <code>pacman</code> 的，而后 <code>sudo pacman -U linuxqq_2.0.0-b2-1089_x86_64.pkg.tar</code>。</p><h2 id="wechat"><a href="#wechat" class="headerlink" title="wechat"></a>wechat</h2><p>既然 QQ 都安装成功了，那么也就通过这种方式安装 wechat 吧。去 github 下载别人<a href="https://github.com/countstarlight/deepin-wine-wechat-arch" target="_blank" rel="noopener">打包好的</a>，安装方式同 QQ。因为 3.0+ 的不能发文件且我在 issue 里面也没看到啥特别好修复方法。建议下载 <code>2.9.5</code> 版本的，然后将 wine 替换为 deepin-wine5 修理一下，可以参考<a href="https://www.jianshu.com/p/11231b51ece0" target="_blank" rel="noopener">这里</a>。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;想来想去，以壮士断腕的决心决定抛弃垃圾 &lt;code&gt;windows&lt;/code&gt; 了，实在是 &lt;code&gt;TMD&lt;/code&gt; 卡的要死，但是以我电脑的配置，不可能卡的。加上 &lt;code&gt;C&lt;/code&gt; 盘的无理由暴增，&lt;code&gt;TMD&lt;/code&gt; 空间锐减，加上每次系统动不动更新，每次更新都 &lt;code&gt;TMD&lt;/code&gt; 出 &lt;code&gt;bug&lt;/code&gt; 直接卡死。我宁肯花一周的时间打造一款我的主力 &lt;code&gt;Arch Linux&lt;/code&gt; ，再 &lt;code&gt;TMD&lt;/code&gt; 也不向 &lt;code&gt;windows&lt;/code&gt; 低头了。以本文记录 &lt;code&gt;Arch Linux&lt;/code&gt; 的折腾全记录。&lt;/p&gt;
&lt;p&gt;包括：代理、终端、字体、换源更新、软件、甚至是博客迁移等。最重要的是，关于向这个世界的妥协，如何使安装 QQ、微信和 word 等非必要但深入人心的软件。毕竟老板让你微信给他发文件还是很常见的，毕竟老板没手没脚，发一次不接收必须发第 $N$ 次，毕竟他用 LaTeX 也要手动编号。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Computer" scheme="https://muyuuuu.github.io/tags/Computer/"/>
    
  </entry>
  
  <entry>
    <title>C++踩坑记录：构造与析构函数</title>
    <link href="https://muyuuuu.github.io/2021/07/21/constructor-and-destructor-with-inheritance/"/>
    <id>https://muyuuuu.github.io/2021/07/21/constructor-and-destructor-with-inheritance/</id>
    <published>2021-07-21T10:22:11.000Z</published>
    <updated>2021-07-21T20:51:56.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>我是练习时长一年的 <code>C++</code> 个人练习生，喜欢野指针、模板报错和未定义行为（undefined behavior）。之前在写设计模式的『工厂模式』时，一脚踩到了构造、继承和 <code>new</code> 组合起来的坑，现在也有时间来整理一下了。</p><a id="more"></a><h1 id="构造函数"><a href="#构造函数" class="headerlink" title="构造函数"></a>构造函数</h1><p>众所周知：在创建对象时，防止有些成员没有被初始化导致不必要的错误，在创建对象的时候自动调用构造函数（无声明类型），完成成员的初始化。即：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Class c <span class="comment">// 隐式，默认构造函数</span></span><br><span class="line">Class c = Class() <span class="comment">// 显示，默认构造函数</span></span><br><span class="line">Class c = Class(<span class="string">"name"</span>) <span class="comment">// 显示，非默认构造函数 </span></span><br><span class="line">Class* c = <span class="keyword">new</span> Class <span class="comment">// 隐式，默认构造函数</span></span><br></pre></td></tr></table></figure><ul><li>构造函数执行前，对象不存在</li><li>构造函数创建对象后，对象不能调用构造函数</li><li>类中如果不定义构造函数，编译器提供有默认的构造函数，无参数，也不执行任何额外的语句</li><li>如果提供非默认构造函数，没有默认构造函数将会出错。所以要定义一个不接受任何参数的构造函数，并为成员定义合理的值</li><li>一般而言，默认的构造函数是用来对所有类成员做隐式初始化的</li><li>自己定义的构造函数一般用使用列表初始化来初始化参数</li><li>通过构造函数对成员赋值，要优于通过函数为成员赋值</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Stone</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> weight&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="keyword">double</span> radius&#123;<span class="number">0.0</span>&#125;;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Stone() &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Class Stone was created by default creator"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">    Stone(<span class="keyword">int</span> w, <span class="keyword">double</span> r) : weight&#123;w&#125;, radius&#123;r&#125; &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Class Stone was created by custom creator"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">showInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Weight: "</span> &lt;&lt; <span class="keyword">this</span>-&gt;weight &lt;&lt; <span class="string">", Radius: "</span> </span><br><span class="line">             &lt;&lt; <span class="keyword">this</span>-&gt;radius &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// 隐式，成员有默认值</span></span><br><span class="line">    Stone s1;</span><br><span class="line">    s1.showInfo();</span><br><span class="line">    <span class="comment">// 显式，通过列表初始化，为成员赋值</span></span><br><span class="line">    Stone s2 = Stone(<span class="number">12</span>, <span class="number">3.3</span>);</span><br><span class="line">    s2.showInfo();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="通过构造函数实现的类型转换"><a href="#通过构造函数实现的类型转换" class="headerlink" title="通过构造函数实现的类型转换"></a>通过构造函数实现的类型转换</h2><p>观察以下的代码，我们发现 <code>Stone s2;s2 = 3.3;</code> 这样将一个 <code>double</code> 类型的数据赋值给类类型并没有出错，这是隐式类型转换，从参数类型到类类型。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Stone</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> weight&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="keyword">double</span> radius&#123;<span class="number">0.0</span>&#125;;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Stone() &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Class Stone was created by default creator"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// 都关闭</span></span><br><span class="line">    Stone(<span class="keyword">double</span> r) : radius&#123;r&#125; &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Class Stone was created by parameter radius"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    Stone(<span class="keyword">int</span> w) : weight&#123;w&#125; &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Class Stone was created by parameter weight"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">showInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Weight: "</span> &lt;&lt; <span class="keyword">this</span>-&gt;weight &lt;&lt; <span class="string">", Radius: "</span> </span><br><span class="line">             &lt;&lt; <span class="keyword">this</span>-&gt;radius &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    Stone s2;</span><br><span class="line">    s2 = <span class="number">3.3</span>;</span><br><span class="line">    s2.showInfo();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是因为：接受一个参数的构造函数允许使用赋值语法来为对象赋值。<code>s2=3.3</code> 会创建 <code>Stock(double)</code> 临时对象，临时对象初始化后，逐成员赋值的方式复制到对象中，在几个构造函数中加入了 <code>cout &lt;&lt; this</code> 的语句，由对象的地址不同，可以判断该赋值语句额外生成了临时对象。</p><p>为了防止隐式转换带来的危险，可以使用关键字 <code>explicit</code> 关闭这一特性，这样就得显式完成参数类型到类类型的转换：<code>s = Stock(1.3)</code>；不过，得保证没有二义性。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Stone</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> weight&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="keyword">double</span> radius&#123;<span class="number">0.0</span>&#125;;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Stone() &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Class Stone was created by default creator"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// 都关闭</span></span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">Stone</span><span class="params">(<span class="keyword">double</span> r)</span> : radius</span>&#123;r&#125; &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Class Stone was created by parameter radius"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">explicit</span> <span class="title">Stone</span><span class="params">(<span class="keyword">int</span> w)</span> : weight</span>&#123;w&#125; &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Class Stone was created by parameter weight"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">showInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Weight: "</span> &lt;&lt; <span class="keyword">this</span>-&gt;weight &lt;&lt; <span class="string">", Radius: "</span> </span><br><span class="line">             &lt;&lt; <span class="keyword">this</span>-&gt;radius &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    Stone s2;</span><br><span class="line">    s2 = Stone(<span class="number">3</span>);</span><br><span class="line">    s2.showInfo();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码中，如果 <code>Stone(int w)</code> 没有被关闭，那么 <code>s2=3.3</code> 将调用这一构造函数。所以构造函数建议都加上 <code>explicit</code> 声明。</p><h2 id="派生类的构造函数"><a href="#派生类的构造函数" class="headerlink" title="派生类的构造函数"></a>派生类的构造函数</h2><p>派生类要注意的是：派生类被构造之前，通过调用一个基类的构造函数，创建基类完成基类数据成员的初始化；也就是说，基类对象在程序进入派生类构造函数之前被创建。那么，可以通过初始化列表传递给基类参数，不传递的话，调用基类的默认的构造函数，如下述程序中的：<code>Gem(){}:Stone()</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Stone</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> weight&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="keyword">double</span> radius&#123;<span class="number">0.0</span>&#125;;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Stone() &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"This object was in address: "</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">    Stone(<span class="keyword">int</span> w, <span class="keyword">double</span> r) : weight&#123;<span class="number">2</span>&#125;, radius&#123;r&#125; &#123;&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">showInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Weight: "</span> &lt;&lt; <span class="keyword">this</span>-&gt;weight &lt;&lt; <span class="string">", Radius: "</span> &lt;&lt; <span class="keyword">this</span>-&gt;radius;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getWeight</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>-&gt;weight;</span><br><span class="line">    &#125;</span><br><span class="line">    auto getRadius() -&gt; double &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>-&gt;radius;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Gem</span> :</span> <span class="keyword">public</span> Stone &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">double</span> price;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Gem()&#123;&#125;;</span><br><span class="line">    Gem(<span class="keyword">double</span> p, <span class="keyword">int</span> w, <span class="keyword">double</span> r) : Stone(w, r), price&#123;p&#125; &#123;&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Weight: "</span> &lt;&lt; <span class="keyword">this</span>-&gt;getWeight() &lt;&lt; <span class="string">", Radius"</span> </span><br><span class="line">             &lt;&lt; <span class="keyword">this</span>-&gt;getRadius();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    Gem g1; <span class="comment">// call default</span></span><br><span class="line">    Gem g2 = Gem(<span class="number">1300</span>, <span class="number">1</span>, <span class="number">2.3</span>); <span class="comment">// call custom </span></span><br><span class="line">    <span class="comment">// g.setWeight(130);</span></span><br><span class="line">    g2.show();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>首先创建基类对象</li><li>派生类通过初始化列表（只能用在构造函数）将基类信息传递给基类的构造函数</li><li>派生类构造函数可以为派生类初始化新的成员</li></ul><h1 id="析构函数"><a href="#析构函数" class="headerlink" title="析构函数"></a>析构函数</h1><p>对象过期时，程序会调用对象的析构函数完成一些清理工作，如释放变量开辟的空间等。如构造函数使用了 <code>new</code> 来申请空间，析构就需要 <code>delete</code> 来释放空间。如果没有特别声明析构函数，编译器会为类提供默认的析构函数，在对象作用域到期、被删除时自动被调用。</p><p>如 <code>stock1 = Stock()</code>，这种就申请了一个临时变量，变量消失时会调用析构函数。此外，这种局部变量放在栈区，先入后出，也就是，最后被申请的变量最先被释放。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Stone</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> weight&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="keyword">double</span> radius&#123;<span class="number">0.0</span>&#125;;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Stone() &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"This object was in address: "</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">    ~Stone() &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="string">" Object was deleted."</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    &#123;</span><br><span class="line">        Stone s1;</span><br><span class="line">        Stone s2;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="继承中的析构函数"><a href="#继承中的析构函数" class="headerlink" title="继承中的析构函数"></a>继承中的析构函数</h2><p>继承类比较容易理解，毕竟都学过面向对象。公有继承的时候，基类的公有成员也是派生类的共有成员；私有成员也是派生类的一部分，不过需要共有或保护方法来访问。但是但是但是，派生类和基类的析构函数之间，也是一个坑。在继承中：</p><ul><li>如果一个方法不是虚方法，那么将根据引用类型或指针类型选择执行的方法</li><li>如果一个方法是虚方法，将根据指针或引用指向对象的类型选择执行的方法</li></ul><p>在继承中，对象的销毁顺序和创建相反。创建时先创建基类，而后创建子类；销毁时，先调用子类的析构函数，而后自动调用基类的析构函数。因此，对于基类而言，建议将析构函数写成虚方法。如果析构不是虚方法，对于以下情况，只有基类的析构被调用；如果析构是虚方法，子类、基类的析构方法都被调用。可以尝试删除下述代码的 <code>virtual</code> 来观察结果：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Stone</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span> weight&#123;<span class="number">0</span>&#125;;</span><br><span class="line">    <span class="keyword">double</span> radius&#123;<span class="number">0.0</span>&#125;;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Stone() &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"This object was in address: "</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;;</span><br><span class="line">    Stone(<span class="keyword">int</span> w, <span class="keyword">double</span> r) : weight&#123;<span class="number">2</span>&#125;, radius&#123;r&#125; &#123;&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">showInfo</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Weight: "</span> &lt;&lt; <span class="keyword">this</span>-&gt;weight &lt;&lt; <span class="string">", Radius: "</span> </span><br><span class="line">             &lt;&lt; <span class="keyword">this</span>-&gt;radius;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getWeight</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>-&gt;weight;</span><br><span class="line">    &#125;</span><br><span class="line">    auto getRadius() -&gt; double &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>-&gt;radius;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">virtual</span> ~Stone() &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Stone class was deleted."</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Gem</span> :</span> <span class="keyword">public</span> Stone &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">double</span> price;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    Gem() &#123;&#125;;</span><br><span class="line">    Gem(<span class="keyword">double</span> p, <span class="keyword">int</span> w, <span class="keyword">double</span> r) : Stone(w, r), price&#123;p&#125; &#123;&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">show</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Weight: "</span> &lt;&lt; <span class="keyword">this</span>-&gt;getWeight() &lt;&lt; <span class="string">", Radius"</span> </span><br><span class="line">             &lt;&lt; <span class="keyword">this</span>-&gt;getRadius();</span><br><span class="line">    &#125;</span><br><span class="line">    ~Gem() &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"Gem class was deleted."</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    Stone* s1 = <span class="keyword">new</span> Gem(<span class="number">2.3</span>, <span class="number">2</span>, <span class="number">3.2</span>);</span><br><span class="line">    <span class="keyword">delete</span> s1;</span><br><span class="line">    <span class="comment">// Gem* g1 = new Gem(2.3, 2, 1.2);</span></span><br><span class="line">    <span class="comment">// delete g1;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><p>大概常见的坑在上面都记录好了，来看一段我写的危险的程序（我大概抽象了一下），覆盖了：野指针和为定义行为：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span> &#123;</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="keyword">int</span>* a;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="keyword">int</span>* <span class="title">create</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        a = <span class="keyword">new</span> <span class="keyword">int</span>();</span><br><span class="line">        <span class="keyword">return</span> a;</span><br><span class="line">    &#125;</span><br><span class="line">    ~A()&#123;</span><br><span class="line">        <span class="keyword">delete</span> a;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span> </span>&#123;</span><br><span class="line">    A a;</span><br><span class="line">    <span class="keyword">int</span>* b = a.create();</span><br><span class="line">    <span class="keyword">delete</span> b;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>每次调用 create 都会 new 一次，但只 delete 了一次。</li><li>如果没有调用 create 直接析构，未定义行为</li><li>如果 b 持有了 a.create() 的指针，然后 a 提前析构，那么 b 是野指针</li><li>delete b 是没必要的。这样会 double free，也是未定义行为</li><li>上述代码没有区分类里面 new 且 返回的东西要在哪删除合适</li><li>可以让类来管理这一个 new，修改一下 create 的实现或者干脆在构造 new，在析构 delete</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我是练习时长一年的 &lt;code&gt;C++&lt;/code&gt; 个人练习生，喜欢野指针、模板报错和未定义行为（undefined behavior）。之前在写设计模式的『工厂模式』时，一脚踩到了构造、继承和 &lt;code&gt;new&lt;/code&gt; 组合起来的坑，现在也有时间来整理一下了。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="C++" scheme="https://muyuuuu.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++函数进阶：内联、重载和模板</title>
    <link href="https://muyuuuu.github.io/2021/07/18/cpp-advanced-function/"/>
    <id>https://muyuuuu.github.io/2021/07/18/cpp-advanced-function/</id>
    <published>2021-07-18T15:11:53.000Z</published>
    <updated>2021-07-18T22:07:02.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>C++ 细节逐步填坑中，还有几个大坑预计 8 月前结束。普通的函数没啥意思了，本文涉及函数的进阶使用，包括：函数的默认参数、内联函数、函数重载和函数模板。</p><a id="more"></a><h1 id="函数原型"><a href="#函数原型" class="headerlink" title="函数原型"></a>函数原型</h1><p>也就是某些教材上常说的函数声明，如果没有函数原型，那么函数首次使用前出现的整个函数定义充当了函数原型。函数由三部分组成：</p><ul><li>函数原型，约定好返回值的类型与接受参数的类型。这就描述了函数到编译器的接口，将参数类型和数量提前告知编译器。这样当函数的返回值放到某个寄存器时，编译器也知道检索多少个字节来解释返回值。如果不告知函数原型，<code>main</code> 函数的编译只能终止然后去寻找函数原型，这样会导致效率不高，甚至有些文件没有搜索的权限，这样会报错。而 <code>C++</code> 的编程风格，习惯将 <code>main</code> 函数放在前面，这样更需要函数原型。</li><li>函数定义，函数头 + 函数体，实现完整的函数功能。</li><li>函数调用，主函数调用子函数完成功能。</li></ul><p>因此，函数原型有以下的作用：</p><ul><li>正确处理函数的返回值</li><li>检查参数的数目、类型是否正确；如果不正确，尽可能转换为正确类型</li></ul><h1 id="内联函数"><a href="#内联函数" class="headerlink" title="内联函数"></a>内联函数</h1><p>常规函数和内联函数的<strong>主要区别</strong>不在于编写方式不同，更多的是程序组合到程序中的方式不同。</p><ul><li><p>对于普通函数而言，程序在执行到函数调用指令时，存储当前指令的地址（保护现场），将函数参数复制到堆栈帧，跳转到子函数起始的内存地址，执行子函数，执行的临时变量放入堆栈帧。执行完毕后，跳回指令被保存的地址处（恢复现场），继续往下执行。使用子函数会造成来回的记录和跳转，造成一定的开销。</p></li><li><p>内联函数会代替函数调用，内联函数直接被插入到主函数中，这样就无需跳转而是顺序执行。执行速度快，但是需要更大的内存。</p></li></ul><blockquote><p>如果函数执行的时间远大于跳转时间，则内联函数的意义不大；如果代码执行时间很短，且需要多次调用，那么内联调用会节省很多时间；如果节省的时间所占执行的时间并不大，或者很少调用，则不需要内联函数。注意，内联函数不能递归。</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="keyword">double</span> <span class="title">sqrt</span><span class="params">(<span class="keyword">double</span> x)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> x * x;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> a&#123;<span class="number">12.3</span>&#125;;</span><br><span class="line">    <span class="keyword">double</span> b = <span class="built_in">sqrt</span>(a);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; b;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="默认参数"><a href="#默认参数" class="headerlink" title="默认参数"></a>默认参数</h1><p>这个倒是不难，就是为一些参数提供默认值。如果一个参数有默认值，那么，它右边的参数必须也要有默认值，且赋值的时候不允许跳过。按照 <code>main</code> 函数放前面这样的编程风格来试一下，默认值在函数原型中提供，函数定义不需要，否则报错。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">show_info</span><span class="params">(<span class="keyword">int</span>, <span class="keyword">int</span>, <span class="keyword">int</span> a=<span class="number">1</span>, <span class="keyword">int</span> b=<span class="number">2</span>, <span class="keyword">int</span> c=<span class="number">3</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> d&#123;<span class="number">12</span>&#125;, e&#123;<span class="number">13</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> x&#123;<span class="number">11</span>&#125;;</span><br><span class="line">    show_info(d, e, x);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">show_info</span><span class="params">(<span class="keyword">int</span> d, <span class="keyword">int</span> e, <span class="keyword">int</span> a, <span class="keyword">int</span> b, <span class="keyword">int</span> c)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; a &lt;&lt; <span class="string">" "</span> &lt;&lt; b &lt;&lt; <span class="string">" "</span> &lt;&lt; c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="函数重载"><a href="#函数重载" class="headerlink" title="函数重载"></a>函数重载</h1><p>对于一个打印函数 <code>print</code> ，可能传入 <code>int</code> 类型的数据，也可能传入 <code>double</code> 类型的数据，这个时候就需要函数重载。函数重载的重点是函数的特征标，也就是函数的参数列表，也就是参数的数目、类型和排列顺序。比如可以这样重载：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* str, <span class="keyword">int</span> t)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; str &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">double</span> str, <span class="keyword">int</span> t)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; str &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">int</span> str, <span class="keyword">int</span> t)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; str &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a&#123;<span class="number">10</span>&#125;;</span><br><span class="line">    <span class="keyword">double</span> b&#123;<span class="number">1.23</span>&#125;;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span>* str = <span class="string">"void"</span>;</span><br><span class="line">    print(str, <span class="number">1</span>);</span><br><span class="line">    print(a, <span class="number">1</span>);</span><br><span class="line">    print(b, <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是，如果调用函数出现了未匹配的类型，很可能错误，如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span> a&#123;<span class="number">12</span>&#125;;</span><br><span class="line">print(a, <span class="number">1</span>);</span><br></pre></td></tr></table></figure><p><code>double</code> 和 <code>int</code> 都可以接受 <code>unsigned int</code> 的参数，二义性的程序会导致错误。</p><h2 id="const-重载"><a href="#const-重载" class="headerlink" title="const 重载"></a>const 重载</h2><p><code>const</code> 可以构成重载，不过只能是指针，非指针不构成重载。这也很容易理解，对于非指针而言，<code>const</code> 或非 <code>const</code> 都不重要，因为原数据无法修改，因此不构成重载；指针则不一样，<code>const</code> 表示原数据或指针不修改，非 <code>const</code> 表示原数据或指针任意修改。这是两个含义的特征标，因此可以构成重载。而编译器根据实参是否为 <code>const</code> 来决定匹配的原型函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">int</span>* a)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; *a &lt;&lt; <span class="string">"---"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span>* a)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; *a &lt;&lt; <span class="string">"==="</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> p&#123;<span class="number">1</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span>* a = &amp;p;</span><br><span class="line">    *a = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span>* b = &amp;p;</span><br><span class="line">    print(a);</span><br><span class="line">    print(b);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于 <code>void print(const int* a)</code> 这样的函数，如果没有重载，那么这个函数是可以接收非 <code>const</code> 数据的。</p><blockquote><p>此外，对于没有任何参数的函数，且不希望函数修改任何变量，可以将 <code>const</code> 关键字放到函数括号的后面。</p></blockquote><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 错误</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">show</span><span class="params">(<span class="keyword">int</span> a)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    a++;</span><br><span class="line">    <span class="keyword">return</span> a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="引用重载"><a href="#引用重载" class="headerlink" title="引用重载"></a>引用重载</h2><p>引用无法构成重载，因为无论是否引用，都可以接收参数：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 错误</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">double</span> x)</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">double</span>&amp; x)</span></span></span><br></pre></td></tr></table></figure><p>但是引用加上 <code>const</code>，含义改变，就可以重载。而对于引用的重载，调用最为匹配的版本：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">double</span>&amp; x)</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">const</span> <span class="keyword">double</span>&amp; x)</span></span></span><br><span class="line"><span class="function"><span class="comment">// 右值引用，没有的话就调用 print(const double&amp; x)</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">double</span>&amp;&amp; x)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="keyword">double</span> x</span>&#123;<span class="number">33.3</span>&#125;;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">double</span> y&#123;<span class="number">12.3</span>&#125;;</span><br><span class="line">print(x);      <span class="comment">// print(double&amp; x)</span></span><br><span class="line">print(y);      <span class="comment">// print(const double&amp; x)</span></span><br><span class="line">print(x + y);  <span class="comment">// print(double&amp;&amp; x)</span></span><br></pre></td></tr></table></figure><h2 id="如何实现重载"><a href="#如何实现重载" class="headerlink" title="如何实现重载"></a>如何实现重载</h2><p><code>C++</code> 通过名称修饰来跟踪重载函数，根据函数原型的函数特征标对函数进行加密。也就是根据特征标对函数进行编码，在函数上添加一组符号后，函数换了个名字作为自己的内部表示，不同特征标的函数名也不一样，不过使用者看不到这一层。具体如何修饰，这取决于编译器。</p><p>重载诱人，但使用时一定要注意类型，只有用相同的形式处理不同类型的数据，才会考虑重载。</p><h1 id="函数模板"><a href="#函数模板" class="headerlink" title="函数模板"></a>函数模板</h1><p>模板比重载还要更省事一点。使用泛型来定义函数，也就是，类型作为参数传递给模板代码，编译器生成指定类型的函数。也就是说，模板通过泛型（参数化类型）来解决任务。使用背景一般是：同一算法需要处理多种类型的参数。</p><p>重载也可以完成这些任务，比如说要交换两个同类型的数，<code>int, double, float, const, char, str, vector</code> 等等等等，重载可以，但是写很多遍会很累。</p><p>模板例子：使用 <code>template &lt;typename T&gt;</code> 来建立模板，编译器检查传入的类型参数，生成相应的函数以供执行。程序员看不到生成的代码，但代码确实被生成以及被使用。且最终生成的代码不包含模板，只包含为程序生成的实际代码。如下所示的模板，交换任意简单类型的数据：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(T&amp; a, T&amp; b)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> a&#123;<span class="number">1.2</span>&#125;, b&#123;<span class="number">2.1</span>&#125;;</span><br><span class="line">    swap(a, b);</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; a &lt;&lt; <span class="string">" "</span> &lt;&lt; b &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">int</span> c&#123;<span class="number">1</span>&#125;, d&#123;<span class="number">2</span>&#125;;</span><br><span class="line">    swap(c, d);</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; c &lt;&lt; <span class="string">" "</span> &lt;&lt; d &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(T&amp; a, T&amp; b)</span> </span>&#123;</span><br><span class="line">    T t;</span><br><span class="line">    t = a;</span><br><span class="line">    a = b;</span><br><span class="line">    b = t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一般而言，对不同类型使用相同算法会考虑模板。但是，不是所有类型用相同的算法都能实现，比如，对象、数组等会涉及深浅拷贝、地址等，并不像简单数据类型那样容易处理。</p><p>举个例子，以交换函数而言，如果是数值类型，就交换；如果是数组类型，交换前 2 个元素；如果是类，有的成员交换有的成员不交换。总之，模板具有局限性，判断相等时，数组不能直接用等号。所以编写的模板很可能无法处理某些类型，大概有两种解决方案：</p><ul><li>在类中重载运算符，如大小、相等的比较；</li><li>为特定类型提供具体化的模板定义</li></ul><p>但是这部分坑准备留在类的重载运算符、移动语义和深浅拷贝之后了，方便对比。</p><h2 id="模板重载"><a href="#模板重载" class="headerlink" title="模板重载"></a>模板重载</h2><p>如果重载模板，函数的特征标同样不能相同。注意，泛型并不是所有参数都得是模板参数类型：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(T&amp; a, T&amp; b)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(T a[], T b[], <span class="keyword">int</span> i = <span class="number">2</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> a&#123;<span class="number">1.2</span>&#125;, b&#123;<span class="number">2.1</span>&#125;;</span><br><span class="line">    swap(a, b);</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; a &lt;&lt; <span class="string">" "</span> &lt;&lt; b &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">int</span> c[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> d[<span class="number">4</span>] = &#123;<span class="number">9</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">6</span>&#125;;</span><br><span class="line">    swap(c, d);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++) &#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; c[i] &lt;&lt; <span class="string">" &lt;=&gt; "</span> &lt;&lt; d[i] &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(T&amp; a, T&amp; b)</span> </span>&#123;</span><br><span class="line">    T t;</span><br><span class="line">    t = a;</span><br><span class="line">    a = b;</span><br><span class="line">    b = t;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(T a[], T b[], <span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">    T t[<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; j++) &#123;</span><br><span class="line">        t[j] = a[j];</span><br><span class="line">        a[j] = b[j];</span><br><span class="line">        b[j] = t[j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="模板的发展"><a href="#模板的发展" class="headerlink" title="模板的发展"></a>模板的发展</h2><p>在 <code>C++98</code> 中，编写模板函数时会一个问题，不知道该声明为哪一种类型：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T1, <span class="keyword">typename</span> T2&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">(T1 x, T2 y)</span> </span>&#123;</span><br><span class="line">    z = x + y;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码中的 <code>z</code> 是什么类型呢？而 <code>C++11</code> 新增的关键字 <code>decltype</code> 提供了解决方案，按照给定的 <code>expression</code> 类型创建指定类型的变量，即 <code>decltype (x) y</code>，<code>y</code> 和 <code>x</code> 同类型。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;typeinfo&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> x&#123;<span class="number">12.3</span>&#125;;</span><br><span class="line">    <span class="keyword">decltype</span> (x) y;</span><br><span class="line">    <span class="comment">// d</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="keyword">typeid</span>(y).name() &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>那么上述模板代码就有了解决方案。而 <code>decltype (expr) var</code> 为确定 <code>var</code> 的类型，遍历一个核对表，只要有一项匹配，那么类型确定完毕，不用在判断后面的。</p><ol><li><code>expr</code> 是一个没有括号标识符，那么 <code>var</code> 与 <code>expr</code> 相同；</li><li><code>expr</code> 是一个函数，<code>var</code> 与函数返回值类型相同；</li><li>如果 <code>expr</code> 是一个左值，<code>var</code> 为 <code>expr</code> 类型的引用，以 <code>double</code> 为例， <code>decltype ((x)) y</code>，<code>y</code> 就是 <code>double</code> 类型的引用；</li><li>如果不满足以上，那么 <code>expr</code> 与 <code>var</code> 同类型，如 <code>int&amp; x, int&amp; y, decltype (x+y) z</code>，<code>z</code> 是 <code>int</code> 类型，不是引用类型；</li></ol><p>但是尽管解决了函数中对变量类型的赋值，但是没有解决模板返回值的问题：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T1, <span class="keyword">typename</span> T2&gt;</span><br><span class="line">? gt (T1 x, T2 y)</span><br></pre></td></tr></table></figure><p>函数的返回值类型和 <code>T1</code> 和 <code>T2</code> 相关，但是要运算后才知道。但是返回值区域， <code>x,y</code> 还不在作用域内就无法使用，这就成了先有鸡还是先有蛋的问题，那么如何提前知道运算结果的类型呢？即使在函数内部知道了返回值类型，也没办法反馈到函数的声明中。</p><p>这个可以通过后置返回值类型 (tailing return type) 可以实现，写法：<code>auto f1(int x, float y) -&gt; double</code>，对应到函数声明，写法如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T1, <span class="keyword">typename</span> T2&gt;</span><br><span class="line">auto f1(T1 x, T2 y) -&gt; decltype(x + y)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;C++ 细节逐步填坑中，还有几个大坑预计 8 月前结束。普通的函数没啥意思了，本文涉及函数的进阶使用，包括：函数的默认参数、内联函数、函数重载和函数模板。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="C++" scheme="https://muyuuuu.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++ 中的引用</title>
    <link href="https://muyuuuu.github.io/2021/07/15/Cpp-refer/"/>
    <id>https://muyuuuu.github.io/2021/07/15/Cpp-refer/</id>
    <published>2021-07-15T22:49:24.000Z</published>
    <updated>2021-07-17T09:08:24.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>引用是 C++ 中一个比较神奇的东西。在这之前或者说 C 语言中，一般是使用指针来减少传参所带来的不必要的开销。如函数传递的参数是数组或结构体时，使用指针会省很多事，毕竟传递的是地址。而 C++ 中引用变量的主要用途也是函数传参，子函数直接操作原始数据，而不是其副本，这样处理大型数据结构也会佷便捷。</p><a id="more"></a><h1 id="指针"><a href="#指针" class="headerlink" title="指针"></a>指针</h1><h2 id="一维数组"><a href="#一维数组" class="headerlink" title="一维数组"></a>一维数组</h2><p>以一维数组为例。众所周知数组名是是数组首元素的地址。因此调用子函数时，主函数传递的是数组首元素的地址，所以子函数接收的是地址，无法预知数组的长度，需要增加额外的参数指明数组元素的数量。</p><p>对于函数，一般用 <code>int arr[]</code> 这样的形式指明 <code>arr</code> 接收的是数组，这样的可读性强；换一种方法，因为传递的是数组首元素的地址，而数组首元素为 <code>int</code> 类型，地址是 <code>int*</code> 类型，因此可以用 <code>int* arr</code> 来接收一个数组，但是这样表意不明确。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> arr[], <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> t = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">        t += arr[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> arr[<span class="number">4</span>] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;;</span><br><span class="line">    sum(arr, <span class="number">4</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="二维数组"><a href="#二维数组" class="headerlink" title="二维数组"></a>二维数组</h2><p>升级到二维数组，二维数组的类型本质就是指向『多个 <code>int</code> 组成的数组』的指针，因此参数的形式为 <code>int (*arr)[4]</code>，而不是 <code>int* arr[4]</code>。</p><ul><li>前者是一个『由 4 个指向 int 的指针』组成的数组；即一个数组，数组元素是四个 int 指针；</li><li>后者是一个指向『由 4 个 int 组成数组』的指针；即一个指针，指向 4 个 int 的数组。为了更好的可读性，一般声明如下：</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> arr[][<span class="number">4</span>], <span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> t = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">4</span>; j++) &#123;</span><br><span class="line">            t += arr[i][j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// 数组有三个元素，每个元素是数组</span></span><br><span class="line">    <span class="keyword">int</span> arr[<span class="number">3</span>][<span class="number">4</span>] = &#123;&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>&#125;, &#123;<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>&#125;, &#123;<span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>&#125;&#125;;</span><br><span class="line">    sum(arr, <span class="number">3</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p>二维数组的指针是不是感觉有点晕？先来看一下简单的引用：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a&#123;<span class="number">11</span>&#125;;</span><br><span class="line"><span class="comment">// 类型是 int&amp;，指向 int 的引用</span></span><br><span class="line"><span class="keyword">int</span>&amp; b = a;</span><br></pre></td></tr></table></figure><p>这样 <code>b</code> 和 <code>a</code> 就指向了相同的值和内存单元，只是名字不一样。此外，引用必须在声明的时候进行初始化，否则这个变量不知道指向哪个内存单元和值，但是指针可以先声明在赋值。</p><p>此外，声明一旦绑定，就无法在修改。可以通过初始化声明来设置引用，不能通过赋值来设置。如下所示的程序，只是对引用 <code>b</code> 进行了赋值，而不是修改引用。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> a&#123;<span class="number">11</span>&#125;;</span><br><span class="line"><span class="keyword">int</span>&amp; b = a;</span><br><span class="line"><span class="keyword">int</span> c&#123;<span class="number">32</span>&#125;;</span><br><span class="line">b = c;</span><br></pre></td></tr></table></figure><h2 id="引用传参"><a href="#引用传参" class="headerlink" title="引用传参"></a>引用传参</h2><p>回到主题，一般将引用用做函数传参时。主函数中的变量名是被调用函数中对应变量的别名，在调用时用实参初始化形参，因此引用参数被初始化为：函数调用时传递过来的实参。如下所示：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span>&amp; a, <span class="keyword">int</span>&amp; b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> t;</span><br><span class="line">    t = a;</span><br><span class="line">    a = b;</span><br><span class="line">    b = t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">int</span> n1&#123;<span class="number">12</span>&#125;, n2&#123;<span class="number">21</span>&#125;;</span><br><span class="line">swap(n1, n2);</span><br></pre></td></tr></table></figure><p>此外，传递引用时对类型的限制更加严格，以求和函数为例：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sum</span><span class="params">(<span class="keyword">double</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; n;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">int</span> a&#123;<span class="number">12</span>&#125;;</span><br><span class="line"><span class="comment">// 临时变量</span></span><br><span class="line">sum(a);</span><br><span class="line">sum(<span class="number">6.2</span>);</span><br><span class="line"><span class="comment">// 临时变量</span></span><br><span class="line">sum(a + <span class="number">6.3</span>);</span><br></pre></td></tr></table></figure><p>换句话说，当实参和形参的类型不匹配时，将会生成临时变量传给形参。但是引用则不行，限制相对严格，<code>sum(a + 6.3)</code> 会报错，传递的实参是表达式不是变量，而引用不能绑定到表达式上，且此时不会生成临时变量。</p><p>但是当参数为 const 引用时，会创建一个临时的无名变量，临时变量的值初始化为 <code>a + 6.3</code>，而后再将无名变量赋给引用：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sum</span><span class="params">(<span class="keyword">const</span> <span class="keyword">double</span>&amp; len)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; len;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a&#123;<span class="number">10</span>&#125;;</span><br><span class="line">    sum(a + <span class="number">6.3</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也许你会有疑问，这个时候为什么会生成临时变量？<code>const</code> 为什么合理呢？如果引用参数是 <code>const</code>，两种情况会生成临时变量：</p><ul><li>实参类型正确，但不是左值，如 <code>a + 6.3</code> 这样的表达式</li><li>实参类型不正确，但可以转为正确类型，如 <code>int</code> 隐式转换为 <code>double</code>；<code>double</code> 到 <code>int</code> 则错误</li></ul><blockquote><p>左值：左值是可以被引用的数据对象，变量、数组、元素等，非左值有字面常量，多项的表达式等。或者说，可以放在赋值语句左侧 and 能访问地址的就是左值，也就是说，赋值语句左侧是可修改的内存块，const 变量也是左值，只是不可修改。</p></blockquote><p>回到原问题，如果形参加上 <code>const</code> 修饰，意思是函数只使用这个值，不修改这个值。即使因类型不匹配生成了临时变量，引用参数引用这个临时变量，都不会造成任何不好的副作用。但此时就是值传递而不是地址传递，因为要用临时变量来存储数值。所以也推荐尽可能使用 <code>const</code>：</p><ul><li>避免无意修改数据造成结果错误</li><li>能更好的接收实参，生成并使用临时变量</li></ul><h2 id="返回值为引用"><a href="#返回值为引用" class="headerlink" title="返回值为引用"></a>返回值为引用</h2><p>对于传统的调用函数而言，返回结果的这个值被复制到临时位置，也就是产生值的副本，调用程序将使用这个值。如：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> len)</span> </span>&#123;</span><br><span class="line">    len += <span class="number">10</span>;</span><br><span class="line">    <span class="comment">// len 复制到临时位置</span></span><br><span class="line">    <span class="keyword">return</span> len;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">int</span> a&#123;<span class="number">10</span>&#125;;</span><br><span class="line"><span class="comment">// 从临时位置获取值</span></span><br><span class="line">a = sum(a);</span><br></pre></td></tr></table></figure><p>而返回引用的函数实际上是返回被引用变量的别名。返回引用值时，并不产生值的副本。而是将返回值直接复制给接收函数的变量或对象，言简意赅，当函数返回引用类型时，没有复制返回值创建临时变量，相反，返回的是对象本身，并复制到接收变量那里。</p><p>对于一个大型的数据结构如结构体，将结构体复制到额外的地址的开销会很大；如果返回引用，将返回的引用的结构体直接赋值给接收值，避免额外的开销。</p><p>但是，避免返回指向临时变量的引用，临时变量在执行完毕后会消失，引用会指向乱七八糟的地址，就跟避免指向临时变量的指针一样。有两种解决方法：</p><ul><li>使用 new，将数据放到堆区，不过内存模型的坑准备后续开</li><li>传递一个额外的参数，传递给函数的引用，将该参数返回。因此返回引用时，要求在函数的参数中，包含有以引用方式需要被返回的参数。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> arr[<span class="number">10</span>];</span><br><span class="line">    <span class="keyword">double</span> value&#123;<span class="number">0</span>&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 返回变量 t 的引用</span></span><br><span class="line"><span class="function">node&amp; <span class="title">sum</span><span class="params">(<span class="keyword">int</span> len, node&amp; n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">        n.value += i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> n;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    node t;</span><br><span class="line">    <span class="comment">// a 被 t 的引用给赋值</span></span><br><span class="line">    node a = sum(<span class="number">5</span>, t);</span><br><span class="line">    <span class="comment">// 修改 a 不会修改 t</span></span><br><span class="line">    a.value = <span class="number">13.2</span>;</span><br><span class="line">    <span class="comment">// a 是 t 的引用，修改 a 也会修改 b</span></span><br><span class="line">    <span class="comment">// node&amp; a = sum(5, t);</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; a.value &lt;&lt; <span class="string">" "</span> &lt;&lt; t.value;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>此外，非引用函数的返回值类型是右值，这种语句位于表达式的右侧，也无法通过地址访问这个值，也无法放到复制语句的左侧。因为返回值的地址在执行完毕后就消失了，也就是说无法引用。如果一定要引用返回值，将返回值类型声明为引用，这样返回的就是左值，就可以引用。</p><p>总结一下：当返回结果需要做为左值时，就要用引用返回。即重载函数的返回结果需要出现在赋值语句左边时，必须用引用返回。如果不用引用返回，那么重载函数的返回结果会是一个临时变量，临时变量是不能放在赋值语句左边的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 错误，右值不能在赋值语句左侧</span></span><br><span class="line"><span class="function">node <span class="title">sum</span><span class="params">(<span class="keyword">int</span> len, node&amp; n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">        n.value += i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> n;</span><br><span class="line">&#125;</span><br><span class="line">sum(<span class="number">5</span>, t).value = <span class="number">12.3</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; t.value;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 正确，返回的引用是左值</span></span><br><span class="line"><span class="function">node&amp; <span class="title">sum</span><span class="params">(<span class="keyword">int</span> len, node&amp; n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">        n.value += i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> n;</span><br><span class="line">&#125;</span><br><span class="line">sum(<span class="number">5</span>, t).value = <span class="number">12.3</span>;</span><br><span class="line"><span class="built_in">cout</span> &lt;&lt; t.value;</span><br></pre></td></tr></table></figure><p>如果不想返回的引用被修改，就加 <code>const</code> 修饰：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> arr[<span class="number">10</span>];</span><br><span class="line">    <span class="keyword">double</span> value&#123;<span class="number">0</span>&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// 返回变量 t 的引用</span></span><br><span class="line"><span class="function"><span class="keyword">const</span> node&amp; <span class="title">sum</span><span class="params">(<span class="keyword">int</span> len, node&amp; n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">        n.value += i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> n;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    node t;</span><br><span class="line">    <span class="comment">// 将 t 引用的值赋值给 a，所以可以修改 a</span></span><br><span class="line">    node a = sum(<span class="number">5</span>, t);</span><br><span class="line">    a.value = <span class="number">13</span>;</span><br><span class="line">    <span class="comment">// b 引用 t，不可修改</span></span><br><span class="line">    node&amp; b = sum(<span class="number">5</span>, t);</span><br><span class="line">    <span class="comment">// 错误</span></span><br><span class="line">    b.value = <span class="number">14</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;引用是 C++ 中一个比较神奇的东西。在这之前或者说 C 语言中，一般是使用指针来减少传参所带来的不必要的开销。如函数传递的参数是数组或结构体时，使用指针会省很多事，毕竟传递的是地址。而 C++ 中引用变量的主要用途也是函数传参，子函数直接操作原始数据，而不是其副本，这样处理大型数据结构也会佷便捷。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="C++" scheme="https://muyuuuu.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>python __init__.py 文件的用法</title>
    <link href="https://muyuuuu.github.io/2021/07/11/python-init-file/"/>
    <id>https://muyuuuu.github.io/2021/07/11/python-init-file/</id>
    <published>2021-07-11T19:09:07.000Z</published>
    <updated>2021-07-11T20:14:58.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近 <code>rush</code> 代码遇到一些问题，如一种典型的结构</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">|-main/</span><br><span class="line">|----test1/</span><br><span class="line">|--------module1.py</span><br><span class="line">|----test2/</span><br><span class="line">|--------module2.py</span><br></pre></td></tr></table></figure><p>如上，想在 <code>module2.py</code> 中调用 <code>module1.py</code> 中的某个类，如果在 <code>module2.py</code> 中写：<code>from ..test1 import module1</code>，在 <code>test2</code> 文件夹下执行 <code>python module2.py</code> 会提示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ImportError: attempted relative import with no known parent package</span><br></pre></td></tr></table></figure><p>会遇到这样的错误。那么，如何解决呢？如果你只想看如何解决问题，直接翻到文末即可；网上大概搜了一下，需要 <code>__init__.py</code> 来解决下这个问题，但是网上搜了一圈，没啥写的特别好的教程，实在是烂的可以，特此来填坑。</p><a id="more"></a><h1 id="init-py-是什么-1"><a href="#init-py-是什么-1" class="headerlink" title="__init__.py 是什么 1"></a>__init__.py 是什么 <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></h1><p>假设此时的路径结构为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">|-main/</span><br><span class="line">|----__init__.py</span><br><span class="line">|----test1/</span><br><span class="line">|--------__init__.py</span><br><span class="line">|--------module1.py</span><br><span class="line">|----test2/</span><br><span class="line">|--------__init__.py</span><br><span class="line">|--------module2.py</span><br></pre></td></tr></table></figure><p>在 <code>test1</code> 目录下的 <code>__init__.py</code> 中写入：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'module1 was called'</span>)</span><br></pre></td></tr></table></figure><p>在 <code>test2</code> 目录下的 <code>__init__.py</code> 中写入：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'module2 was called'</span>)</span><br></pre></td></tr></table></figure><p>在 <code>main</code> 目录下的 <code>__init__.py</code> 中写入：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'parent package was called'</span>)</span><br><span class="line"><span class="comment"># 导入 [] 里面定义的模块</span></span><br><span class="line">__all__ = [<span class="string">'test1'</span>, <span class="string">'test2'</span>]</span><br></pre></td></tr></table></figure><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>通俗来说，<code>__init__.py</code> 可以将文件封装成包，将多个文件合并到一个逻辑命名空间。但是这么说太突兀了，由浅入深，一点一点来。先来看看文件夹中添加 <code>__init__.py</code> 会发生什么。假设此时的路径为 <code>main</code> 文件夹下，尝试导入模块，会发现上述信息被打印：</p><p><img data-src="https://z3.ax1x.com/2021/07/11/WCmmuT.png" alt></p><p>同理，在 <code>main</code> 文件夹的 <strong>上一级路径</strong> 下执行导入，也会有同样的效果，但是不会导入子模块。</p><p><img data-src="https://z3.ax1x.com/2021/07/11/WCm05d.png" alt></p><p>如果想导入单个子模块，可以 <code>import main.test1</code>，此时会打印 <code>module1 was called</code>；如果再次调用 <code>import main.test1</code>，也就是在模块已经导入的情况下再次导入，则不会打印任何信息。</p><p>如果导入全部子模块，也是可以的。因为声明了 <code>__all__</code>，所以子模块被导入。</p><p><img data-src="https://z3.ax1x.com/2021/07/11/WCmyxP.png" alt></p><p>但是你也许会有疑问，我经常写 <code>import math</code>，而 <code>math.sin</code> 等函数是导入的，且可以使用，为什么这里就不行了呢？如果想行，也是可以的，只需要在 <code>main</code> 目录下的 <code>__init__.py</code> 中写入以下信息就可以了，也就是 <code>import main; main.test1</code> 可用。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'parent package was called'</span>)</span><br><span class="line"><span class="comment"># 删除 __all__</span></span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> test1</span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> test2</span><br></pre></td></tr></table></figure><p>通过以上例子，我们可以看出，<code>__init__.py</code> 会起到以下作用：</p><ul><li>导入模块时初始化一些信息，如 <code>web</code> 项目中，启动 <code>session</code> 等</li><li>在父目录中，导入多个子模块</li></ul><h1 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h1><p>也许你会觉得以上功能比较弱，或者说没啥用。那么来看一些实用的简化工作量的写法 <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> 。此时的目录结构如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">├─ main.py</span><br><span class="line">└─ network</span><br><span class="line">       ├─ __init__.py</span><br><span class="line">       ├─ msg</span><br><span class="line">       │    └─ info</span><br><span class="line">       │           └─ send.py</span><br><span class="line">       └─ parse.py</span><br></pre></td></tr></table></figure><p>在 <code>send.py</code> 中，定义如下函数：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send_msg</span><span class="params">(msg)</span>:</span></span><br><span class="line">    print(<span class="string">'send:'</span>, msg)</span><br></pre></td></tr></table></figure><p>如果想在 <code>main.py</code> 中调用这个函数，需要以下写法：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> network.msg.info <span class="keyword">import</span> send</span><br><span class="line">send.send_msg(<span class="string">'hello'</span>)</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="comment"># from network.msg.info.send import send_msg</span></span><br><span class="line"><span class="comment"># send_msg('hello')</span></span><br></pre></td></tr></table></figure><p>但无论那种方法，都要写长长的路径，甚为不便。这个时候，我们可以在 <code>network</code> 文件夹下面创建一个 <code>__init__.py</code> 文件，并在里面填写如下内容：<code>from .msg.info.send import send_msg</code>。而 <code>main.py</code> 文件中的内容可以修改为：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> network <span class="keyword">import</span> send_msg</span><br><span class="line">send_msg(<span class="string">'hello'</span>)</span><br></pre></td></tr></table></figure><p>是不是简短了很多。这是因为，当一个文件夹里面有 <code>__init__.py</code> 以后，这个文件夹就会被 <code>python</code> 作为一个包 <code>package</code> 来处理。此时，对于这个包里面层级比较深的函数、常量、类，我们可以先把它们导入到 <code>__init__.py</code> 中。这样以来，包外面再想导入这些内容时，就可以用 <code>from 包名 import 函数名</code> 来导入了。</p><p>这样做有很多好处，由于调用包的其他模块所在的绝对路径是千变万化的，当有一些代码会在很多地方被使用时，我们可以把这些代码打包起来，作为一个公共的接口提供给其他模块调用，这会方便很多。</p><p>所以在<strong>包的内部</strong>调用自身其他文件中的函数、常量、类，就不应该使用相对路径，而是绝对路径。这里以添加新功能为例，如下所示，在 <code>parse.py</code> 文件中添加以下内容：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 两种都可以</span></span><br><span class="line"><span class="comment"># from .msg.info.send import send_msg</span></span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> send_msg</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_msg</span><span class="params">(msg)</span>:</span></span><br><span class="line">    print(<span class="string">'parse:'</span>, msg)</span><br><span class="line">    send_msg(msg)</span><br></pre></td></tr></table></figure><p>可以看到，在包里面的一个文件调用这个包里面的另一个文件，只需要知道另一个文件的相对位置就可以了，不用关心这个包被放在哪里。上 面<code>parse.py</code> 中导入 <code>send_msg</code> 函数的代码还可以进一步简化，由于 <code>send_msg</code> 函数已经被导入到了 <code>__init__.py</code> 中，所以我们可以直接从 <code>.</code> 里面导入 <code>send_msg</code> 函数。</p><p>之后在 <code>__init__.py</code> 中追加：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> .parse <span class="keyword">import</span> parse_msg</span><br></pre></td></tr></table></figure><p>此时，<code>main.py</code> 的写法可以如下，可以看到，即使追加了新的模块，<code>main.py</code> 调用起来也会很方便，并不需要知道 <code>parse_msg</code> 这个方法的任何位置信息。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> network <span class="keyword">import</span> parse_msg</span><br><span class="line">parse_msg(<span class="string">'hhh'</span>)</span><br></pre></td></tr></table></figure><p>此外，当一个文件夹里面包含 <code>__init__.py</code> 时，这个文件夹会被 <code>python</code> 认为是一个包 <code>package</code>，此时，包内部的文件之间互相导入可以使用相对导入，并且通过提前把函数、常量、类导入到 <code>__init__.py</code> 中再在其他文件中导入，可以精简代码。</p><h1 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h1><p>既然了解了 <code>__init__.py</code> 的用法，那么去解决文章最开始提到的问题。目录结构如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">main</span><br><span class="line">├─ main.py</span><br><span class="line">├─ test1</span><br><span class="line">│    ├─ __init__.py</span><br><span class="line">│    └─ m1.py</span><br><span class="line">└─ test2</span><br><span class="line">       └─ m2.py</span><br></pre></td></tr></table></figure><p>实现的想法也很简单，<code>m2.py</code> 调用 <code>m1.py</code> 中的函数。</p><p><code>m1.py</code> 定义如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">send</span><span class="params">(msg)</span>:</span></span><br><span class="line">    print(msg)</span><br></pre></td></tr></table></figure><p><code>m2.py</code> 定义如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> test1 <span class="keyword">import</span> m1</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">    m1.send(<span class="string">'hello'</span>)</span><br></pre></td></tr></table></figure><p>距离成功只差一步，那就是修改 <code>test1</code> 中的 <code>__init__.py</code> 的内容，把 <code>test1</code> 看成一个 <code>package</code>，暴露其中的 <code>m1</code> 即可。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> test1 <span class="keyword">import</span> m1</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="comment"># from . import m1</span></span><br></pre></td></tr></table></figure><p>这样，在外部的 <code>main</code> 函数中：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> test2.m2 <span class="keyword">as</span> m2</span><br><span class="line">m2.run()</span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="comment"># from test2 import m2</span></span><br><span class="line"><span class="comment"># m2.run()</span></span><br></pre></td></tr></table></figure><p>就可以了。</p><h1 id="references"><a href="#references" class="headerlink" title="references"></a>references</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">https://zhuanlan.zhihu.com/p/130927618</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">https://www.kingname.info/2020/03/23/init-in-python/</span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近 &lt;code&gt;rush&lt;/code&gt; 代码遇到一些问题，如一种典型的结构&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;|-main/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;|----test1/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;|--------module1.py&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;|----test2/&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;|--------module2.py&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;如上，想在 &lt;code&gt;module2.py&lt;/code&gt; 中调用 &lt;code&gt;module1.py&lt;/code&gt; 中的某个类，如果在 &lt;code&gt;module2.py&lt;/code&gt; 中写：&lt;code&gt;from ..test1 import module1&lt;/code&gt;，在 &lt;code&gt;test2&lt;/code&gt; 文件夹下执行 &lt;code&gt;python module2.py&lt;/code&gt; 会提示：&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ImportError: attempted relative import with no known parent package&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;会遇到这样的错误。那么，如何解决呢？如果你只想看如何解决问题，直接翻到文末即可；网上大概搜了一下，需要 &lt;code&gt;__init__.py&lt;/code&gt; 来解决下这个问题，但是网上搜了一圈，没啥写的特别好的教程，实在是烂的可以，特此来填坑。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Python" scheme="https://muyuuuu.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>对抗训练篇：MART 防御算法论文笔记</title>
    <link href="https://muyuuuu.github.io/2021/06/22/MART/"/>
    <id>https://muyuuuu.github.io/2021/06/22/MART/</id>
    <published>2021-06-22T21:26:54.000Z</published>
    <updated>2021-07-22T09:20:26.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>MART(Misclassification Aware adveRsarial Training) 是 2020 年提出的最好的对抗防御算法。传统对抗训练算法中 min-max 时不会考虑当前样本是否被正确分类，统一制作对抗样本。而作者抓住了这一点，发现对于 max 制作对抗样本期间没有被网络正确分类的样本，对结果的影响很大。换句话说，<strong>网络连干净样本都不认识，何谈认识它的对抗样本？</strong> MART 算法的创新点在于区别对待错分类和正确分类的样本。</p><a id="more"></a><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>MART 防御的仍然是微小扰动的图像，也就是人眼察觉不出来的那种。论文用$p$ 范数满足这一限制：$\Vert x’-x \Vert_p \leq \epsilon$。对抗训练可以视为使用对抗样本进行数据增强，解决的是以下优化问题：</p><p>\begin{equation}<br>\min<em>\theta \frac{1}{n} \sum</em>{i=1}^{n} \max<em>{\Vert x’-x \Vert_p \leq \epsilon} L(h</em>\theta(x_i’), y_i)<br>\end{equation}</p><p>$n$ 是一个 batch 的大小，$L$ 是分类的损失函数。内部通过最大化损生成对抗样本，外部最小化对抗样本的分类损失来训练更好的 DNN，如 <a href="https://muyuuuu.github.io/2021/04/26/DNN-safe-basic/">PGD</a> 就是使用的这种方案。</p><p>而本文的关注点在对抗训练的对抗样本上，其实许多对抗训练算法忽略了一点，有些样本被正确分类，有些样本被错误分类，但无论哪种样本，都在 min-max 中直接制作对抗样本。因此本文也就抛出例如下疑问：</p><blockquote><p>由错分类样本和正确分类的样本产生的对抗样本，对模型的鲁棒性贡献程度是一样的吗？如果不是，如何利用这个差异，来提升模型的鲁棒性？</p></blockquote><p>本文针对这个被忽略的一点做了一些探索，发现被错分类和正确分类的样本对最终模型的鲁棒性的确有不同的影响。</p><p>本文做了这样的实验，在 CIFAR-10 数据集上做白盒攻击，扰动值 $\epsilon=8/255$。使用 PGD-10 算法制作对抗样本，以对抗训练的形式训练得到的网络的准确率是 87%。然后选择被错分类的样本记为 $S^-$，在选择被正确分类的样本记为 $S^+$。之后使用这两类样本，用不同的方式训练上述网络，最后用 PGD-20 算法制作的对抗样本评估最终模型的鲁棒性。结果如下图所示：</p><p><img data-src="https://z3.ax1x.com/2021/06/22/RmVckj.png" alt></p><p>在图 a 中：错分类样本对鲁棒性有明显影响。</p><ol><li>蓝色的线是标准对抗训练的对抗鲁棒性</li><li>绿色的线表示没有对 $S^-$ 制作对抗样本，其它样本仍然是对抗样本，鲁棒性降低很大；</li><li>橙色的线表示没有对 $S^+$ 制作对抗样本，其它样本仍然是对抗样本，鲁棒性变换其实不大。</li></ol><p>图 b 中：为了更深理解『错分类样本和其它样本』的影响是不同的，外部 min 采用交叉熵，内部 max 采用攻击强度很弱的 <a href="https://muyuuuu.github.io/2021/04/26/DNN-safe-basic/">FGSM</a> 算法：</p><ol><li>蓝色的线是标准对抗训练的对抗鲁棒性</li><li>绿色的线表示在 $S^-$ 上产生的对抗样本对鲁棒性几乎没有提升。这可以说明不同的 max 方法在 $S^-$ 上会对模型鲁棒性有不同程度的影响。然而，</li><li>橙色的线表示，低强度的攻击算法在 $S^+$ 上制作的对抗样本会使鲁棒性退化。</li></ol><p>图 c 中，内部 max 选择 PGD-10 算法，外部 min 尝试不同的函数。发现对错分类的样本使用不同的 min 方法，对最终鲁棒性的结果影响也很大。</p><ol><li>蓝色的线是，对传统对抗训练，外部 min 使用交叉熵函数</li><li>绿色的线是，对错分类样本添加额外的 KL 散度作为正则化项，鲁棒性有明显的提升</li><li>绿色的线是，将同样的 KL 散度作为正则化项添加到正确分类的样本上，鲁棒性也有提升，但不如绿色的线明显。</li></ol><p>基于以上实验发现，论文考虑了错分类样本对鲁棒性的影响，提出了一个新的防御算法，以一种动态的方式实现对抗训练。主要贡献是：</p><ul><li>研究了错分类和正确分类的样本对『对抗训练』最终鲁棒性的影响，结果表明，在 min-max 框架下，对错分类样本的处理对模型最终鲁棒性的影响佷大，且 min 方法比 max 方法更为关键。</li><li>提出一种正则化的对抗风险，将错误分类的样本做显式区分，作为正则化项添加到损失函数中。</li></ul><h1 id="MART-算法"><a href="#MART-算法" class="headerlink" title="MART 算法"></a>MART 算法</h1><p>临时通知一周后期末考试，去准备期末考试了，考完了回来填坑。其实这个算法的缺陷显而易见，可以尝试往 GAN 那边走一走。考完了，回来填坑。</p><h2 id="前期定义"><a href="#前期定义" class="headerlink" title="前期定义"></a>前期定义</h2><p>对于一个 $K$ 分类问题，给定数据集 $(x<em>i,y_i)$，深度模型 $h</em>\theta$，对于每个样本而言，网络的输出如下：</p><p>\begin{equation}<br>\begin{aligned}<br>h<em>\theta(x_i) &amp;= \arg \max p_k(x_i, \theta) \<br>p_k(x_i, \theta) &amp;= \exp(z_k(x_i,\theta)) / \sum</em>{j=1}^K \exp(z_j(x_i,\theta))<br>\end{aligned}<br>\end{equation}</p><p>其中，$z_k(x_i,\theta)$ 是网络的逻辑输出，<code>softmax</code> 后获得类别标签。对抗风险定义为：一个 batch 中被分类错误的样本数除以 batch 数。对抗样本的制作为：</p><p>\begin{equation}<br>\hat{x} = \arg\max \mathbb{I}(h_\theta(x_i) \neq y_i)<br>\end{equation}</p><h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><blockquote><p>注，原文第二章写了一些0-1损失，后面又说不用这个，所以我没有写0-1损失</p></blockquote><p>首先将训练样本分为正样本 $S^+<em>{h\theta}$ 和错样本 $S^-</em>{h\theta}$，即能被网络正确识别的样本和不能被正确识别的样本。</p><ul><li>对于 $S^-<em>{h\theta}$ 而言，添加正则化项，使得网络能稳定的防御错分类对抗样本。因为对抗样本的分类需要更强的分类器和更光滑的决策边界，损失函数定义为 $\mathbb{I}(h</em>\theta(\hat{x<em>i}) \neq y_i) + \mathbb{I}(h</em>\theta(x<em>i) \neq h</em>\theta(\hat{x_i}))$，意思是，第一项优化的目标是，使对抗样本被分类正确；第二项优化的目标是，使网络认识原始样本和对抗样本。</li><li>对于 $S^+<em>{h\theta}$ 而言，正则化不会明显提升网络鲁棒性。在这种情况下，已经有 $h</em>\theta(x<em>i)=y_i$，因此此时的优化目标是 $\mathbb{I}(h</em>\theta(x<em>i) \neq h</em>\theta(\hat{x}))=\mathbb{I}(h_\theta(\hat{x_i})\neq y_i)$，也就是说，网络将干净样本和对抗样本视为两个类别且对抗样本分类错误的概率。</li><li>其中 $\mathbb{I}$ 是指示函数，意思是，错了损失值为1，正确损失值为0。</li></ul><p>但是这个指示函数难以优化，本文提出 BCE(boosted cross entropy) 损失函数，用于代替 $\mathbb{I}(h(\hat{x} \neq y))$，定义如下：</p><p>\begin{equation}<br>\begin{aligned}<br>\text{BCE}(p(\hat{x}, \theta), y<em>i) &amp;= -\log(p</em>{y<em>i}(\hat{x},\theta)) - \log (1-\max</em>{k\neq y_i}p_k(\hat{x}, \theta))<br>\end{aligned}<br>\end{equation}</p><p>第一项是普通的交叉熵损失函数，第二项用于提升模型决策边界的间隙。</p><p>使用 $KL$ 散度代替 $\mathbb{I}(h<em>\theta(x) \neq h</em>\theta(\hat{x}))$，定义如下：</p><p>\begin{equation}<br>\text{KL}(p(x<em>i,\theta)||p(\hat{x}, \theta))=\sum</em>{k=1}^K p_k{(x_i,\theta)} \log \frac{p_k(x_i,\theta)}{p_k(\hat{x_i},\theta)}<br>\end{equation}</p><p>对于制作对抗样本使用的指示函数 $\mathbb{I}(h<em>\theta(x_i) \neq y_i)$，通过 $1-p</em>{y_i}(x_i, \theta)$ 的形式选择对抗样本。因此，内部最大化的损失定义如下，攻击方式选择 PGD。</p><p>\begin{equation}<br>\hat{x} = \arg \max \text{CE} (p(x_i, \theta), y_i)<br>\end{equation}</p><p>将两中损失结合起来到对抗训练的框架中，最终的损失函数为：</p><p>\begin{equation}<br>L = \text{BCE}(p(\hat{x}, \theta), y<em>i) + \lambda \text{KL} (p(x_i,\theta)||p(\hat{x}, \theta))(1-p</em>{y_i}(x_i, \theta))<br>\end{equation}</p><p>$\lambda$ 参数用于平衡两个损失。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MART(Misclassification Aware adveRsarial Training) 是 2020 年提出的最好的对抗防御算法。传统对抗训练算法中 min-max 时不会考虑当前样本是否被正确分类，统一制作对抗样本。而作者抓住了这一点，发现对于 max 制作对抗样本期间没有被网络正确分类的样本，对结果的影响很大。换句话说，&lt;strong&gt;网络连干净样本都不认识，何谈认识它的对抗样本？&lt;/strong&gt; MART 算法的创新点在于区别对待错分类和正确分类的样本。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DeepLearning" scheme="https://muyuuuu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>C++ 中的常量与指针</title>
    <link href="https://muyuuuu.github.io/2021/06/22/const-pointer/"/>
    <id>https://muyuuuu.github.io/2021/06/22/const-pointer/</id>
    <published>2021-06-22T20:26:47.000Z</published>
    <updated>2021-06-22T20:33:22.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>和指针联用有佷微妙的地方，之前一直佷晕，现在来继续研究下。诸如以下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> <span class="keyword">const</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span>* p;</span><br><span class="line"><span class="keyword">int</span> <span class="keyword">const</span>* p;</span><br><span class="line"><span class="keyword">int</span>* <span class="keyword">const</span> p;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span>* <span class="keyword">const</span> p;</span><br></pre></td></tr></table></figure><a id="more"></a><p><code>const</code> 是一种处理符号常量的方法，以 <code>const</code> 声明的变量，一般首字母大写，声明之后无法被修改。相比于 <code>define</code>，<code>const</code> 会显式的指定类型。除定义符号外，一般可用于函数声明，表示函数不会修改任何值；用于参数，表示函数不会修改参数；甚至可以用于声明数组的长度。</p><h1 id="解读"><a href="#解读" class="headerlink" title="解读"></a>解读</h1><p>const默认作用于其左边的东西。左边没东西的情况下，作用于其右边的东西。<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p><ol><li><code>const int* p</code>，只有右边有东西，修饰的为 <code>int</code>，所以数值不能被修改。在与 <code>*</code> 结合，意思是<code>*p</code>不能被修改，其它的都可以。即不可通过该指针改变其指向的内容，但可改变指针本身所指向的地址。</li><li><code>int const* p</code>，先作用于左侧的 <code>int</code> 为 <code>int const</code>，在叠加上右侧的 <code>*</code>，所以修饰的为 <code>int* p</code>，所以，<code>*p</code>不能被修改，其它的都可以。即不可通过该指针改变其指向的内容，但可改变指针本身所指向的地址。也就是，和上面的是一样的。</li><li><code>int* const p</code>，左边是 <code>*</code>，所以 <code>const</code> 作用于指针，指向一个 <code>int</code> 变量。即不可以修改 <code>p</code>，但可以修改 <code>*p</code>，即不可改变指向的地址。</li><li><code>const int* const p</code>，对于第一个 <code>const</code>，左边没东西，修饰右边的 <code>int</code>，指向的值不能修改；对于第二个 <code>const</code> 修饰 <code>*</code>，指针不能修改。即不可改变指针本身所指向的地址，也不可通过指针改变其指向的内容。同 <code>int const* const p</code>。</li><li><code>int const* const* p</code>，第一个 <code>const</code> 修饰 <code>int</code>，第二个 <code>const</code> 修饰第一个 <code>*</code>，也就是，指向 <code>const int* const p</code> 的指针，最后一个 <code>*</code> 没有被修饰，因此可以指向其它变量。<code>int const* const* const</code> 就不可以了。</li><li>之后再出现此类情况，也可以慢慢分析满天飞的 <code>const</code> 和指针。</li></ol><h1 id="一些例子"><a href="#一些例子" class="headerlink" title="一些例子"></a>一些例子</h1><p>为了更好的理解上述内容，这里来举一些例子。常见的一般有两种选择：</p><ul><li>常指针指向一个变量，防止修改指针修改变量值</li><li>常指针指向一个常量</li><li>非常指针指向常量（错误）</li></ul><p>先看第一种情况：解引用只是取出指向内存区域的值，因此指向内存区域的值是可以直接修改的，但不能通过指针修改。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a&#123;<span class="number">34</span>&#125;;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> *p = &amp;a;</span><br><span class="line">    <span class="comment">// *p 为 const，不能被修改</span></span><br><span class="line">    <span class="comment">// 错误</span></span><br><span class="line">    <span class="comment">// *p ++;</span></span><br><span class="line">    <span class="comment">// p 指向的不是常量，因此，可以修改 a</span></span><br><span class="line">    a ++;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; *p &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> b&#123;<span class="number">12</span>&#125;;</span><br><span class="line">    p = &amp;b;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; *p &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于第二种情况：不能修改变量，也不能修改常量。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> a&#123;<span class="number">34</span>&#125;;</span><br><span class="line">    <span class="comment">// *p 为 const，不能被修改，a 也不能被修改</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> *p = &amp;a;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; *p &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> b&#123;<span class="number">12</span>&#125;;</span><br><span class="line">    p = &amp;b;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; *p &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于第三种情况：修改指针来修改常量会显得佷荒谬，因此编译会直接报错：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> a&#123;<span class="number">34</span>&#125;;</span><br><span class="line">    <span class="comment">// error: invalid conversion from 'const int*' to 'int*'</span></span><br><span class="line">    <span class="keyword">int</span> *p = &amp;a;</span><br><span class="line">    *p ++;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; *p ;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="二级指针"><a href="#二级指针" class="headerlink" title="二级指针"></a>二级指针</h2><p>之前说到，常指针可以指向变量，但是涉及二级指针后，情况又会发生逆转。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> a&#123;<span class="number">12</span>&#125;;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span>** p1;</span><br><span class="line">    <span class="keyword">int</span>* p2;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// error: invalid conversion from 'int**' to 'const int**'</span></span><br><span class="line">    p1 = &amp;p2;</span><br><span class="line">    *p1 = &amp;a;</span><br><span class="line"></span><br><span class="line">    *p2 = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果上述代码通过，那么完全可以通过 <code>p2</code> 指针修改常量。因此我们可以得到以下结论：</p><ul><li>若数据类型本身不是指针，可以将 <code>const</code> 数据或非 <code>const</code> 数据的地址赋给指向 <code>const</code> 的指针，但指针可以修改，指向别的值。因此，<code>const</code> 修饰的数组不能传参给非常量指针。</li><li>如果数据类型是指针，非 <code>const</code> 数据的地址只能赋值给非 <code>const</code> 指针，如二级指针中，<code>p1 = &amp;p2</code> 是错误的。</li></ul><h1 id="references"><a href="#references" class="headerlink" title="references"></a>references</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">https://www.zhihu.com/question/443195492</span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;和指针联用有佷微妙的地方，之前一直佷晕，现在来继续研究下。诸如以下：&lt;/p&gt;
&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;const&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;* p;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;const&lt;/span&gt;* p;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;* &lt;span class=&quot;keyword&quot;&gt;const&lt;/span&gt; p;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;* &lt;span class=&quot;keyword&quot;&gt;const&lt;/span&gt; p;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
    
      <category term="C++" scheme="https://muyuuuu.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>C++ 的名称空间</title>
    <link href="https://muyuuuu.github.io/2021/06/20/cpp-namespace/"/>
    <id>https://muyuuuu.github.io/2021/06/20/cpp-namespace/</id>
    <published>2021-06-20T17:43:46.000Z</published>
    <updated>2021-06-21T20:37:24.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>之前在学 C++ 的时候，第一个例子大概是：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"hello world"</span> &lt;&lt; <span class="built_in">endl</span>; </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 或者</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"hello world"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>; </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当时也没多想，<code>std</code> 这个东西是什么。后来在接触了其它库后，发现也需要 <code>std</code> 的配合使用，如 <code>std::sort()</code>。今日来仔细研究下名称空间这个东西。</p><a id="more"></a><p>先掏出 cplusplus.com 来看看 <code>&lt;iostream&gt;</code> 是什么东西，官方的定义如下：</p><blockquote><p>Header that defines the standard input/output stream objects. After C++11, including <code>&lt;iostream&gt;</code> automatically includes also <code>&lt;ios&gt;</code>, <code>&lt;streambuf&gt;</code>, <code>&lt;istream&gt;</code>, <code>&lt;ostream&gt;</code> and <code>&lt;iosfwd&gt;</code>.</p></blockquote><p>而对于 <code>std</code> 而言，<code>std</code> 是一个名称空间，<code>::</code> 是作用域解析运算符，<code>std::cout</code> 的意思就是使用 <code>std</code> 名称空间中的 <code>cout</code> 标识符，也就是这个对象。而这个对象的定义在 <code>&lt;iostream&gt;</code> 这个标准库文件中，所以要包含这个头文件，才能使用 <code>cout</code> 这个对象。</p><p>除此之外，C++ 标准库中的<strong>函数或对象</strong>都是在名称空间 <code>std</code> 中定义的，所以我们要使用标准函数库中的<strong>函数或对象</strong>都要使用 <code>std</code> 来限定。所以使用 <code>cout</code> 的时候要加上 <code>std::</code> 时，编译器就会明白我们调用的 <code>cout</code> 是名字空间 <code>std</code>中的 <code>cout</code>，而不是其它名称空间中的 <code>cout</code>。</p><ul><li><code>#include</code> 是预处理器编译指令，表示使用预处理器在主编译之前对源文件进行整理。这里并不需要任何指令调用预处理器，编译时自动调用执行。这里的意思就是将 <code>iostream</code> 文件中的内容添加到程序中，即合成为一个新文件。这里的用途就是，在源文件被编译之前，替换或添加文本，这也是典型的一种预处理器操作。</li><li><code>using namespcec std</code> 是编译指令，如果是 <code>#include &lt;xxx.h&gt;</code> 则不需要 <code>using</code> 编译指令，因为老式的头文件没有使用名称空间。新头文件使用了 <code>std</code> 名称空间，标准库的类、函数、变量是 C++ 编译器的标准组件，被放到了 <code>std</code> 空间中。</li></ul><p>但是，尽量不要使用 <code>using namespace std</code>，这句话的意思是告诉编辑器我们将要使用空间 <code>std</code> 中的函数或者对象。或者说，能不用就不用，能在大括号里面用就不要在外面用，尤其是在 <code>.h</code> 等头文件中。幻想一下，你写的 <code>.h</code> 文件被其它人使用，你的名字空间和他人的名字空间不一样，但名字空间下面的函数名一样，就会导致冲突。跟 <code>python</code> 中写 <code>from numpy import *</code> 一个道理。</p><h1 id="自定义名称空间"><a href="#自定义名称空间" class="headerlink" title="自定义名称空间"></a>自定义名称空间</h1><p>名称空间提供了一个声明名称的区域，而可以通过作用域解析运算符 <code>::</code> 访问其中的名称。如下是一种简单的写法：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// mylib/show_info.h 文件下</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 名称空间</span></span><br><span class="line"><span class="keyword">namespace</span> std1 &#123;</span><br><span class="line">    <span class="comment">// 名称</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">cout</span> <span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"first"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> std2 &#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">cout</span> <span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"second"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// main.cpp 文件下</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"mylib/show_info.h"</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std1;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">cout</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="using-声明与编译指令"><a href="#using-声明与编译指令" class="headerlink" title="using 声明与编译指令"></a>using 声明与编译指令</h2><p>有的时候并不希望每次使用名称时都进行限定，所以 <code>C++</code> 提供了两种机制，<code>using</code> 声明使得特定的名称可用，<code>using</code> 编译指令使名称空间中的所有名称可用，两者都可以简化名称空间中名称的使用，也都会增加名称冲突的可能性。</p><p>对于 <code>using</code> 声明而言，将指定的的名称添加到声明区域，使其可用。如下所示的代码：</p><ul><li>在声明的作用域内，不能在声明其它同名变量；</li><li>屏蔽全局同名变量。除用户定义的名称空间外，还存在一个全局名称空间，全局变量在这里面。同 <code>C++</code> 的局部变量会屏蔽全局变量一样，名称空间也是如此，但两个名称空间中的同名变量并不会冲突。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> test &#123;</span><br><span class="line">    <span class="keyword">int</span> a;</span><br><span class="line">    <span class="keyword">int</span> b;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> a&#123;<span class="number">12</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 冲突</span></span><br><span class="line">    <span class="comment">// int a;</span></span><br><span class="line">    <span class="keyword">using</span> test::a;</span><br><span class="line">    <span class="comment">// 冲突</span></span><br><span class="line">    <span class="comment">// int a;</span></span><br><span class="line">    a = <span class="number">10</span>;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; a &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;    <span class="comment">// 10</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; ::a &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;  <span class="comment">// 12</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于 <code>using</code> 编译指令而言，会使所有名称可用，包括可能不会使用的名称。如下所示的代码：</p><ul><li><code>test::a</code> 位于局部名称空间，不会影响全局变量；</li><li>局部同名变量会屏蔽名称空间里的变量和全局变量。</li></ul><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> test &#123;</span><br><span class="line">    <span class="keyword">int</span> a = <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">int</span> b;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局名称空间</span></span><br><span class="line"><span class="comment">// using namespace test;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> a&#123;<span class="number">0</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// 编译指令</span></span><br><span class="line">    <span class="comment">// 局部名称空间</span></span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">namespace</span> test;</span><br><span class="line">    <span class="comment">// 不冲突</span></span><br><span class="line">    <span class="keyword">int</span> a&#123;<span class="number">1</span>&#125;;</span><br><span class="line">    <span class="comment">// 局部变量</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; a &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="comment">// 全局变量</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; ::a &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="comment">// 名称空间的变量</span></span><br><span class="line">    test::a = <span class="number">3</span>;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; test::a &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>总结一下就是，当名称空间和声明区域定义了相同的名称：</p><ol><li><code>using</code> 声明导入时，会冲突；</li><li><code>using</code> 编译指令导入时，局部名称会屏蔽名称空间里面的名称，且没有警告。</li></ol><p>因此，使用 <code>using</code> 声明会更加安全，编译指令可能会掩盖一些同名变量。此外，还有一些其它要注意的点：</p><ul><li>名称空间可以嵌套，但最好加上限定，表明这个名称的来源；</li><li>以函数为例，名称空间里面的函数的声明和定义要在同一名称空间内；</li><li>如果函数被重载，那么一个 <code>using</code> 声明将导入所有版本；</li><li><p>对于未命名的名称空间，不能显式使用 <code>using</code>，不能在名称空间之外的文件使用名称空间中的名称。这可以作为<strong>链接性为内部静态变量的替代品</strong>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> &#123;</span><br><span class="line">    <span class="keyword">int</span> a = <span class="number">100</span>;</span><br><span class="line">    <span class="keyword">int</span> b;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// 名称空间中的 a</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; a &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>当名称空间很长时，可以简化名称空间：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> MEF = math::element::fire;</span><br><span class="line"><span class="keyword">using</span> MEF::flame;</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前在学 C++ 的时候，第一个例子大概是：&lt;/p&gt;
&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#&lt;span class=&quot;meta-keyword&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;meta-string&quot;&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;namespace&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span class=&quot;string&quot;&gt;&quot;hello world&quot;&lt;/span&gt; &amp;lt;&amp;lt; &lt;span class=&quot;built_in&quot;&gt;endl&lt;/span&gt;; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// 或者&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#&lt;span class=&quot;meta-keyword&quot;&gt;include&lt;/span&gt; &lt;span class=&quot;meta-string&quot;&gt;&amp;lt;iostream&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;cout&lt;/span&gt; &amp;lt;&amp;lt; &lt;span class=&quot;string&quot;&gt;&quot;hello world&quot;&lt;/span&gt; &amp;lt;&amp;lt; &lt;span class=&quot;built_in&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;built_in&quot;&gt;endl&lt;/span&gt;; &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;当时也没多想，&lt;code&gt;std&lt;/code&gt; 这个东西是什么。后来在接触了其它库后，发现也需要 &lt;code&gt;std&lt;/code&gt; 的配合使用，如 &lt;code&gt;std::sort()&lt;/code&gt;。今日来仔细研究下名称空间这个东西。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="C++" scheme="https://muyuuuu.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>二分搜索的亿点点细节</title>
    <link href="https://muyuuuu.github.io/2021/06/18/binary-search/"/>
    <id>https://muyuuuu.github.io/2021/06/18/binary-search/</id>
    <published>2021-06-18T20:26:53.000Z</published>
    <updated>2021-06-20T11:47:46.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>不能继续开坑了，得整理一下。最近在刷二分法，思路很简单，细节是魔鬼。时而减一时而不用，仿佛在面向玄学编程，所以特意来整理一下。<a href="https://github.com/labuladong/fucking-algorithm/blob/master/%E7%AE%97%E6%B3%95%E6%80%9D%E7%BB%B4%E7%B3%BB%E5%88%97/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E8%AF%A6%E8%A7%A3.md" target="_blank" rel="noopener">本文参考</a>。</p><a id="more"></a><p>对于最常见的二分查找框架：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binarySearch</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> left = <span class="number">0</span>, right = ...;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(...) &#123;</span><br><span class="line">        <span class="keyword">int</span> mid = left + (right - left) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (nums[mid] == target) &#123;</span><br><span class="line">            ...</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &lt; target) &#123;</span><br><span class="line">            left = ...</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &gt; target) &#123;</span><br><span class="line">            right = ...</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ...;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>分析二分查找的一个技巧是：不要出现 <code>else</code>，而是把所有情况用 <code>else if</code> 写清楚，这样可以清楚地展现所有细节。本文都会使用 <code>else if</code>，旨在讲清楚，读者理解后可自行简化。</p><ol><li>其中 <code>...</code> 标记的部分，就是可能出现细节问题的地方，当你见到一个二分查找的代码时，首先注意这几个地方。后文用实例分析这些地方能有什么样的变化。</li><li>另外声明一下，计算 <code>mid</code> 时需要防止溢出，代码中 <code>left + (right - left) / 2</code> 就和 <code>(left + right) / 2</code> 的结果相同，但是有效防止了 <code>left</code> 和 <code>right</code> <strong>太大直接相加导致溢出。</strong></li></ol><h1 id="查找一个数"><a href="#查找一个数" class="headerlink" title="查找一个数"></a>查找一个数</h1><p>这个场景是最简单的，在一个数组中搜索一个数，如果存在，返回其索引，否则返回 -1。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binarySearch</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> left = <span class="number">0</span>; </span><br><span class="line">    <span class="keyword">int</span> right = nums.size() - <span class="number">1</span>; <span class="comment">// 注意</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(left &lt;= right) &#123;</span><br><span class="line">        <span class="keyword">int</span> mid = left + (right - left) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(nums[mid] == target)</span><br><span class="line">            <span class="keyword">return</span> mid; </span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &lt; target)</span><br><span class="line">            left = mid + <span class="number">1</span>; <span class="comment">// 注意</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &gt; target)</span><br><span class="line">            right = mid - <span class="number">1</span>; <span class="comment">// 注意</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 0 1 2 3 4 5 6  7  8  9  10</span></span><br><span class="line">    <span class="comment">// 1 3 5 5 8 9 12 23 34 56 84</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v&#123;<span class="number">12</span>, <span class="number">34</span>, <span class="number">23</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">8</span>, <span class="number">56</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">9</span>, <span class="number">84</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> target = <span class="number">23</span>;</span><br><span class="line">    <span class="comment">// 有序是使用二分的前提</span></span><br><span class="line">    sort(v.begin(), v.end());</span><br><span class="line">    <span class="keyword">int</span> a = binarySearch(v, target);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>为什么 <code>while</code> 循环的条件中是 &lt;=，而不是 &lt;？因为初始化 <code>right</code> 的赋值是 <code>nums.length - 1</code>，而不是 <code>nums.length</code>。这二者可能出现在不同功能的二分查找中，区别是：前者相当于两端都闭区间 <code>[left, right]</code>，后者相当于左闭右开区间 <code>[left, right)</code>。我们这个算法中使用的是前者 <code>[left, right]</code> 两端都闭的区间，<strong>这个区间其实就是每次进行搜索的区间。</strong></li><li>那 <code>while</code> 循环什么时候应该终止？搜索区间为空的时候应该终止，意味着你没得找了，就等于没找到嘛。<code>while(left &lt;= right)</code> 的终止条件是 <code>left == right + 1</code>，写成区间的形式就是 <code>[right + 1, right]</code>，或者带个具体的数字进去 <code>[3, 2]</code>，可见这时候区间为空，因为没有数字既大于等于 3 又小于等于 2 。所以这时候 while 循环终止是正确的，直接返回 -1 即可。</li><li>为什么 <code>left = mid + 1</code>，<code>right = mid - 1</code>？我看有的代码是 <code>right = mid</code> 或者 <code>left = mid</code>，或者时而减时而不减，到底怎么回事，怎么判断？答：这也是二分查找的一个难点，不过只要你能理解前面的内容，就能够很容易判断。刚才明确了「搜索区间」这个概念，而且本算法的搜索区间是两端都闭的，即 <code>[left, right]</code>。那么当我们发现索引 <code>mid</code> 不是要找的 <code>target</code> 时，下一步应该去搜索哪里呢？之前提到搜索区间是闭区间，所以当然是去搜索 <code>[left, mid-1]</code> 或者 <code>[mid+1, right]</code> ，因为 mid 已经搜索过，应该从搜索区间中去除。之后还有有这方面的细节。</li><li>扩展一些，如果不返回 -1 而是直接返回 <code>left</code>。如果数字在数组中，返回的就是索引；如果不在数组中且以升序为例，返回的就是这个元素插入数组中应该放到哪个位置。</li><li>而对于 <code>while(left &lt; right)</code> 这种情况，也就是搜索区间是 <code>[left, right)</code>，那么终止条件是 <code>left == right</code>，写成区间的形式就是 <code>[right, right]</code>，或者带个具体的数字进去 <code>[2, 2]</code>，这时候区间非空，还有一个数 2，但此时 <code>while</code> 循环终止了。也就是说这区间 <code>[2, 2]</code> 的第一个 2 被漏掉了，索引 <code>2</code> 没有被搜索，如果这时候直接返回 -1 就是错误的。我们已经知道了出错的原因，就打个补丁好了：<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(left &lt; right) &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> left &lt; right ? left : <span class="number">-1</span>;</span><br></pre></td></tr></table></figure></li></ol><h1 id="搜索左侧边界"><a href="#搜索左侧边界" class="headerlink" title="搜索左侧边界"></a>搜索左侧边界</h1><p>给定一个数组，<code>1 2 2 2 3</code>，搜索数字 2 最开始出现的左侧区间，这里就返回索引 1。代码如下，这里写成左闭右开的形式：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binarySearch</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> left = <span class="number">0</span>; </span><br><span class="line">    <span class="keyword">int</span> right = nums.size(); <span class="comment">// 注意</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(left &lt; right) &#123;</span><br><span class="line">        <span class="keyword">int</span> mid = left + (right - left) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(nums[mid] == target)</span><br><span class="line">            right = mid;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &lt; target)</span><br><span class="line">            left = mid + <span class="number">1</span>; <span class="comment">// 注意</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &gt; target)</span><br><span class="line">            right = mid; <span class="comment">// 注意</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (left == nums.size())</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">    <span class="keyword">return</span> left;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 0 1 2 3 4 5 6  7  8  9  10</span></span><br><span class="line">    <span class="comment">// 1 3 5 5 8 9 12 23 34 56 84</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v&#123;<span class="number">12</span>, <span class="number">34</span>, <span class="number">23</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">8</span>, <span class="number">56</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">9</span>, <span class="number">84</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> target = <span class="number">1000</span>;</span><br><span class="line">    sort(v.begin(), v.end());</span><br><span class="line">    <span class="keyword">int</span> a = binarySearch(v, target);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>为什么 <code>while</code> 中是 &lt; 而不是 &lt;=? 用相同的方法分析，因为 <code>right = nums.length</code> 而不是 <code>nums.length - 1</code>。因此每次循环的「搜索区间」是 <code>[left, right)</code> 左闭右开。<code>while(left &lt; right)</code> 终止的条件是 <code>left == right</code>，此时搜索区间 <code>[left, left)</code> 为空，所以可以正确终止。</li><li>如果 <code>nums</code> 中不存在 <code>target</code> 这个值，怎么办？对于一个数组 <code>1 2 2 2 3</code>，<code>target</code> 为 2 返回 1，含义是：<code>nums</code> 中小于 2 的元素有 1 个；<code>target = 1</code>，算法会返回 0，<code>nums</code> 中小于 1 的元素有 0 个；<code>target = 8</code>，算法会返回 4，<code>nums</code> 中小于 8 的元素有 4 个。综上可以看出，函数的返回值（即 left 变量的值）取值区间是闭区间 <code>[0, nums.length]</code>，所以我们简单添加两行代码就能在正确的时候 <code>return -1</code>。</li><li>为什么 <code>left = mid + 1，right = mid</code> 和之前的算法不一样？因为我们的「搜索区间」是 <code>[left, right)</code> 左闭右开，所以当 <code>nums[mid]</code> 被检测之后，下一步的搜索区间应该去掉 <code>mid</code> 分割成两个区间，即 <code>[left, mid)</code> 或 <code>[mid + 1, right)</code>。</li><li>为什么返回 <code>left</code> 而不是 <code>right</code>？都是一样的，因为 <code>while</code> 终止的条件是 <code>left == right</code>。</li><li>能不能想办法把 <code>right</code> 变成 <code>nums.length - 1</code>，也就是继续使用两边都闭的「搜索区间」？这样就可以和第一种二分搜索在某种程度上统一起来了。由于 <code>while</code> 的退出条件是 <code>left == right + 1</code>，所以当 <code>target</code> 比 <code>nums</code> 中所有元素都大时，会存在以下情况使得索引越界。<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binarySearch</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> left = <span class="number">0</span>; </span><br><span class="line">    <span class="keyword">int</span> right = nums.size() - <span class="number">1</span>; <span class="comment">// 注意</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(left &lt;= right) &#123;</span><br><span class="line">        <span class="keyword">int</span> mid = left + (right - left) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(nums[mid] == target)</span><br><span class="line">            right = mid - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &lt; target)</span><br><span class="line">            left = mid + <span class="number">1</span>; <span class="comment">// 注意</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &gt; target)</span><br><span class="line">            right = mid - <span class="number">1</span>; <span class="comment">// 注意</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (left == nums.size())</span><br><span class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">return</span> left;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 0 1 2 3 4 5 6  7  8  9  10</span></span><br><span class="line">    <span class="comment">// 1 3 5 5 8 9 12 23 34 56 84</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v&#123;<span class="number">12</span>, <span class="number">34</span>, <span class="number">23</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">8</span>, <span class="number">56</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">9</span>, <span class="number">84</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> target = <span class="number">1000</span>;</span><br><span class="line">    sort(v.begin(), v.end());</span><br><span class="line">    <span class="keyword">int</span> a = binarySearch(v, target);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><h1 id="寻找右侧边界"><a href="#寻找右侧边界" class="headerlink" title="寻找右侧边界"></a>寻找右侧边界</h1><p>给定一个数组，<code>1 2 2 2 3</code>，搜索数字 2 最开始出现的最右侧区间，这里就返回索引 3。代码如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">right_bound</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (nums.length == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">int</span> left = <span class="number">0</span>, right = nums.length;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> (left &lt; right) &#123;</span><br><span class="line">        <span class="keyword">int</span> mid = (left + right) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (nums[mid] == target) &#123;</span><br><span class="line">            left = mid + <span class="number">1</span>; <span class="comment">// 注意</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &lt; target) &#123;</span><br><span class="line">            left = mid + <span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &gt; target) &#123;</span><br><span class="line">            right = mid;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nums[left<span class="number">-1</span>] == target ? (left<span class="number">-1</span>) : <span class="number">-1</span>; <span class="comment">// 注意</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>搜索区间」是 <code>[left, right)</code> 左闭右开，所以当 <code>nums[mid]</code> 被检测之后，下一步的搜索区间应该去掉 <code>mid</code> 分割成两个区间，即 <code>[left, mid)</code> 或 <code>[mid + 1, right)</code>。</li><li>为什么最后返回 <code>left - 1</code> 而不像左侧边界的函数，返回 <code>left</code> ？而且我觉得这里既然是搜索右侧边界，应该返回 <code>right</code> 才对。首先，<code>while</code> 循环的终止条件是 <code>left == right</code>，所以 <code>left</code> 和 <code>right</code> 是一样的，你非要体现右侧的特点，返回 <code>right - 1</code> 好了。</li><li>至于为什么要减一，这是搜索右侧边界的一个特殊点，关键在<strong>等式条件</strong> <code>nums[mid] == target</code> 下的判断：<code>left = mid + 1</code>，因为最后一定是找到了和 <code>target</code> 相等的数字，且是最右侧的。对 <code>left</code> 的更新是 <code>left = mid + 1</code>，就是说 <code>while</code> 循环结束时，<code>nums[left]</code> 一定不等于 <code>target</code> 了，而 <code>nums[left-1]</code> 可能是 <code>target</code>。</li></ol><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binarySearch</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums, <span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> left = <span class="number">0</span>; </span><br><span class="line">    <span class="keyword">int</span> right = nums.size(); <span class="comment">// 注意</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(left &lt; right) &#123;</span><br><span class="line">        <span class="keyword">int</span> mid = left + (right - left) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(nums[mid] == target)</span><br><span class="line">            left = mid + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &lt; target)</span><br><span class="line">            left = mid + <span class="number">1</span>; <span class="comment">// 注意</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (nums[mid] &gt; target)</span><br><span class="line">            right = mid; <span class="comment">// 注意</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nums[left - <span class="number">1</span>] == target ? left - <span class="number">1</span> : <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 0 1 2 3 4 5 6  7  8  9  10</span></span><br><span class="line">    <span class="comment">// 1 3 5 5 8 9 12 23 34 56 84</span></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v&#123;<span class="number">12</span>, <span class="number">34</span>, <span class="number">23</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">8</span>, <span class="number">56</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">9</span>, <span class="number">84</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> target = <span class="number">34</span>;</span><br><span class="line">    sort(v.begin(), v.end());</span><br><span class="line">    <span class="keyword">int</span> a = binarySearch(v, target);</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; a &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="STL-开车"><a href="#STL-开车" class="headerlink" title="STL 开车"></a>STL 开车</h1><p>对于一些高级语言而言，其实都内置了二分搜索。以 <code>C++</code> 为例，搜索数组 <code>1 2 2 2 3</code> 中有几个 2。第一种方案是搜索 2 出现的左边界，而后搜索出现的右边界。但是也可以通过 <code>lower_bound</code> 和 <code>upper_bound</code> 来解决，因为在某些复杂应用下，二分只是一个小点，没必要花费大多精力在不重要的点。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; v&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line">    <span class="keyword">int</span> target = <span class="number">2</span>;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;::iterator lower, upper;</span><br><span class="line"></span><br><span class="line">    lower = lower_bound(v.begin(), v.end(), target);</span><br><span class="line">    upper = upper_bound(v.begin(), v.end(), target);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="keyword">static_cast</span>&lt;<span class="keyword">int</span>&gt;(upper - lower) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;不能继续开坑了，得整理一下。最近在刷二分法，思路很简单，细节是魔鬼。时而减一时而不用，仿佛在面向玄学编程，所以特意来整理一下。&lt;a href=&quot;https://github.com/labuladong/fucking-algorithm/blob/master/%E7%AE%97%E6%B3%95%E6%80%9D%E7%BB%B4%E7%B3%BB%E5%88%97/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E8%AF%A6%E8%A7%A3.md&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;本文参考&lt;/a&gt;。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DataStructure" scheme="https://muyuuuu.github.io/tags/DataStructure/"/>
    
  </entry>
  
  <entry>
    <title>对抗攻击篇：一些关于对抗补丁的论文</title>
    <link href="https://muyuuuu.github.io/2021/06/13/adversial-patch/"/>
    <id>https://muyuuuu.github.io/2021/06/13/adversial-patch/</id>
    <published>2021-06-13T14:32:14.000Z</published>
    <updated>2021-06-22T21:28:48.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在对抗攻击中，有人尝试着去用对抗样本攻击目标检测的网络。但是，检测网络与分类网络不同，检测网络还有检测器，存在 RPN、ROI-Align 以及边界框回归器等。而分类接受的图像来自检测器的输出，并不是原始的输入。所以只在图片上产生细微的扰动很可能不起做作用 <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>。所以衍生出了一些基于 patch （补丁）的攻击。</p><a id="more"></a><h1 id="Adversial-Patch"><a href="#Adversial-Patch" class="headerlink" title="Adversial Patch"></a>Adversial Patch</h1><p>这篇论文 <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> 是最开始的，创建一些通用的小 patch，可以放到任何场景下去干扰分类，使得网络忽略真实的物体，而输出诱导的错误分类。传统的对抗攻击，都是在输入上叠加一些微小的扰动，人眼察觉不出来的那种，但需要修改图像中的每一个像素，对于 $1000\times 1000$ 的像素点，需要操作一百万个像素点，在现实世界难以应用。</p><p>而本文中，不在满足这一约束，而是生成一个独立于任何场景（光照、角度）的 patch 放到图片的任何位置，相反，这个 patch 大于只有 $20\times 20$ 的大小，所以这个计算量是可以在现实世界应用的。这个 patch 很容易被网络看到，但仍然可以导致网络错误的输出。当 patch 使用了很大的扰动，传统的防御算法只能防御小扰动的样本，对大扰动的样本鲁棒性反而很差，毕竟数据分布不同。如下所示：</p><p><img data-src="https://z3.ax1x.com/2021/06/13/2IOvY4.png" alt></p><p>所以，这个补丁攻击的仍然是分类网络。</p><h2 id="训练方式"><a href="#训练方式" class="headerlink" title="训练方式"></a>训练方式</h2><p>在全部数据集上进行训练，对 patch 进行各种各样的转换、缩放、旋转，这个 patch 允许被设置为任何形状。对于给定图像 $x$，patch $p$，位置 $l$，变换 $t$，定义一个补丁操作 $A(p,x,l,t)$，将 $t$ 应用到 $p$ 上，在把 $p$ 放到 $x$ 的 $l$ 位置。</p><p>而 patch 是经过训练的，以诱导网络输出错误的标签 $\hat{y}$，这个训练过程为：</p><p>\begin{equation}<br>p = \arg \max<em>p \mathbb{E}</em>{x\sim X,t\sim T, l\sim L}[\log P(\hat{y}|A(p,x,l,t))]<br>\end{equation}</p><p>$X$ 是训练数据的分布，$T$ 是 patch 变换的分布，$L$ 是位置。通过这个公式，生成的 patch 会忽略背景，所以生成的 patch 通用性较强。而为了伪装 patch，使得最终的 patch 不太离谱，加入了一个限制 $|p-p<em>{orig}|</em>\inf &lt; \epsilon$。</p><h1 id="DPATCH"><a href="#DPATCH" class="headerlink" title="DPATCH"></a>DPATCH</h1><p>这个补丁 <sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> 就正儿八经的攻击目标检测的网络了。不同于上一个补丁只误导分类器，同时也攻击边界框回归器，以产生错误的定位。其实目标检测是很难攻击的，毕竟有很多 anchor 和候选框，样本不一定能被选中。攻击目标检测的网络时，与传统分类不同的是，需要定位到不同大小的目标及其位置。</p><p>在无目标攻击中，让检测器不能检测到物体的位置，所以最大化真实类别和边界框回归器的损失，这里的类别 $y$ 是背景类。也就是，通过放置补丁，让网络的将真实的目标视为背景。</p><p>\begin{equation}<br>P_u=\arg \max_P \mathbb{E} [L(A(x,s,P);y;B)]<br>\end{equation}</p><p>在有目标攻击中，目标是只能检测到 patch 而忽略其它真正的目标。所以需要最小化 patch 的类别损失和边界损失，类别是自己选择的误导类别。也就是，让网络将补丁视为目标。</p><p>\begin{equation}<br>P_t=\arg \min_P \mathbb{E} [L(A(x,s,P);y_t;B_t)]<br>\end{equation}</p><p>$A(x,s,P)$ 表示将补丁 $P$ 通过变换 $s$ 添加到图像 $x$ 上。在补丁进入网络前，首先先添加一个随机噪音，而后定义 patch 的边界框。训练流程如下：</p><p><img data-src="https://z3.ax1x.com/2021/06/13/2Ijf2j.png" alt></p><ul><li>为了分析不同位置下 DPATCH 的影响，随机对 DPATCH 的位置进行变换，而保持像素点数值不变，在每轮训练时候都随机初始化变换 $s$</li><li>为了分析不同类别下 DPATCH 的影响，将 DAPTCH 的类别都设置为人，随机指定了四个类别</li><li>为了分析不同大小的 DPATCH 的影响，所以做了一些实验，分别分析 20 40 80 大小的 DPATCH 对结果的影响</li></ul><p>实验结果大概证明了，DAPTCH 在可以出现在图片的任何位置，更大的 DAPTCH 攻击性更强。</p><p>DPATCH 起作用的原因：DPATCH 的攻击目标就是目标检测网络，使得 ROI 提取到的区域被 DPATCH 覆盖，所以提取到的 ROI 区域，将会忽略其它目标。如果攻击成功了，许多提取到的 ROI 应该会有 DPATCH 的存在。为此，统计每个区域被提取为 ROI 的次数，也发现那里正好是 DPATCH 出现的地方。故此验证了攻击成功的原因是：DPATCH 欺骗了检测器，使得 ROI 含有 DPATCH，而不是正常目标，如下图所示：</p><p><img data-src="https://z3.ax1x.com/2021/06/13/2IvWTK.png" alt></p><h1 id="物理世界的补丁"><a href="#物理世界的补丁" class="headerlink" title="物理世界的补丁"></a>物理世界的补丁</h1><p>这篇论文 <sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> 做了一个演示<a href="https://youtu.be/WXnQjbZ1e7Y" target="_blank" rel="noopener">视频</a>。与之前不同的是，不需要 patch 放到图像上误导分类和检测，而是设计了一个 patch 抑制其它目标的表达。所以可以 patch 到任何地点甚至是远离目标的地点。而且不需要训练位置参数，且不需要修改场景中的目标。</p><p>本文构造一个物理上的 patch，放到图像中，抑制其它目标的表达。寻找与制作 patch 的方式也很简单：</p><p>\begin{equation}<br>\arg \max<em>{\delta} \mathbb{E}</em>{(x, y) \sim D, t\sim T} [L(h_\theta(A(\delta, x, t)), y)]<br>\end{equation}</p><p>其中 $\delta$ 是补丁，$D$ 是数据分布，$T$ 是变换分布，$A$ 是将补丁 $\delta$ 经过 $t$ 变换放到 $x$ 上。但是，对 $\delta$ 的最大期望可能会超出预期，所以不够通用。所以像 PGD 一样，让扰动朝着其它目标移动：</p><p>\begin{equation}<br>\delta := \delta - \alpha \nabla<em>\delta [L(h</em>\theta(A(\delta, x, t)), \hat{y})]<br>\end{equation}</p><p>但是事实证明这种做法很差。所以尝试最大化与真实目标的损失，不对补丁设置任何的边界框和目标类别，而是直接抑制检测的其它类别：</p><p>\begin{equation}<br>\delta := clip<em>{[0,1]} (\delta + \alpha \nabla</em>\delta [L(h_\theta(A(\delta, x, t)), y)])<br>\end{equation}</p><p>这种方法成功的原因和上述的 DPATCH 是一样的，提取到的 ROI 还有 PATCH。作者和 DPATCH 做了对比，分析 DPatch 之所以时好时差，是因为它将 patch 放到了 ground truth box 的周围，patch 最终驻留在一个单一的单元中。这意味着损失由『负责』该单元的 rpn 控制。只要补丁被识别，模型在预测所有其他对象时受到的惩罚就很小，且边界框或类标签上不会受到惩罚。所以在实践中，补丁经常被检测到，但是，<strong>并没有抑制其他目标被检测</strong>。反而言之，一旦 patch 没被检测到，网络还是能识别到目标。</p><p>而在本文的方法中，patch 可以置于任何位置，当 patch 与任何一个 ground truth box 重叠都会造成损失，也就是，当前目标检测失败。当模型不能预测任何 ground truth box 时，损失增加最多。</p><h1 id="references"><a href="#references" class="headerlink" title="references"></a>references</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;"><a href="https://arxiv.org/abs/1712.02494" target="_blank" rel="noopener">为什么难以攻击目标检测网络</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;"><a href="https://arxiv.org/abs/1712.09665" target="_blank" rel="noopener">Adversial Patch</a></span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;"><a href="https://arxiv.org/abs/1806.02299" target="_blank" rel="noopener">DPATCH</a></span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">4.</span><span style="display: inline-block; vertical-align: top;"><a href="https://arxiv.org/abs/1906.11897" target="_blank" rel="noopener">物理世界的补丁</a></span><a href="#fnref:4" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在对抗攻击中，有人尝试着去用对抗样本攻击目标检测的网络。但是，检测网络与分类网络不同，检测网络还有检测器，存在 RPN、ROI-Align 以及边界框回归器等。而分类接受的图像来自检测器的输出，并不是原始的输入。所以只在图片上产生细微的扰动很可能不起做作用 &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;。所以衍生出了一些基于 patch （补丁）的攻击。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DeepLearning" scheme="https://muyuuuu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>面向长尾目标检测的 Seesaw Loss</title>
    <link href="https://muyuuuu.github.io/2021/05/28/seesaw-loss/"/>
    <id>https://muyuuuu.github.io/2021/05/28/seesaw-loss/</id>
    <published>2021-05-28T15:54:02.000Z</published>
    <updated>2021-06-08T23:02:56.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>论文好像是 2020 年底传到 arxiv <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> 的，还比较新。正好最近遇到的问题是类别数量是长尾分布，恰好最近看到 mmdetection 也支持了这个损失函数，索性来看一看这篇论文，算是做个论文笔记吧。不过为了能更容易理解论文的思想，没有按照原论文的内容结构进行整理。</p><a id="more"></a><h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>在现实世界中，只有少部分类有充足的数据，大部分类别其实只有小部分数据，这就是类别数量呈现长尾分布。如下图 <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> 所示：</p><p><img data-src="https://z3.ax1x.com/2021/05/28/2FWClj.jpg" alt></p><p>而头部类实例在长尾数据集中占主导地位，这些实例为尾部类提供了大量的负样本。所以正样本和负样本在尾类上的梯度严重不平衡。说人话的意思是，含有尾部类别的样本本是正样本，头部类别的样本是负样本。由于负样本的数量大于正样本，所以负样本对尾部类别的影响大于正样本对尾部类别的影响，具体为啥可以看公式 $\eqref{why}$。由于交叉熵公式的原因，负样本的梯度在学习过程中起到了决定性影响，导致尾部类别被识别为背景或头部类别。如下图所示：</p><p><img data-src="https://z3.ax1x.com/2021/05/28/2FhmQJ.png" alt></p><ul><li>那些鸟明明是正样本，但目标小，类别少，导致不如右侧常见的负样本的梯度大。负样本梯度指：就是负样本对当前类别的惩罚。</li></ul><p>以传统的交叉熵损失函数为例：</p><p>\begin{equation}<br>L(z) = -\sum<em>{i=1}^C y_i \log(\sigma_i), \sigma_i = \frac{e^{z_i}}{\sum</em>{j=1}^Ce^{z_j}}<br>\end{equation}</p><p>$z$ 表示为网络的逻辑预测输出，$\sigma$ 表示网络对每个类别的预测概率。如果当前类别是 $i$，那么对 $z_i$ 和 $z_j$ 的梯度为：</p><p>\begin{equation}\label{why}<br>\frac{\partial L}{\partial z_i} = \sigma_i - 1, \frac{\partial L}{\partial z_j} = \sigma_j<br>\end{equation}</p><p>上述公式中可以看到，第 $i$ 类样本在分类时，也惩罚了类别 $j$，换句话说，类别 $j$ 的输出单元也要受到影响。如果类别 $i$ 是头部类别，类别 $j$ 是尾部类别，那么类别 $j$ 的输出单元、backbone 等网络参数将会在大多数样本中会受到惩罚，于是类别 $j$ 的预测就会受到抑制，导致上图所示的结果。<strong>务必看懂这一步，这也是论文要改进的点。</strong></p><p>现有的一些处理长尾分布的做法是（这部分就是 related works 抄来的，我没看里面的论文）：</p><ul><li>根据不同的类别统计，调整损失来重新计算权重</li><li>重采样技术，保证类别平衡</li><li>在预训练的模型上，用类平衡技术重新训练分类头</li><li>对不同的类别使用不同的分类器去预测</li></ul><h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><h2 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h2><ol><li>对于每一个类别，通过缓解（mitigation）因子 $M<em>{ij}$ 和补偿（compensation）因子 $C</em>{ij}$ 动态的重新平衡正负样本的梯度</li><li>$M_{ij}$ 在累积的训练过程中，在不同类别之间，减少对尾部类别的惩罚。</li><li>但是只减轻惩罚是不够的，因为其他类别的样本在被误分类为尾类时，尾部类别受到的惩罚仍然较小。说人话的意思是，类别 $j$ 相关的神经元受到的惩罚小，神经网络为了最小化损失，所以不管输入的是什么类，有可能直接输出第 $j$ 类，所以盲目地降低负样本的梯度会增加导致尾类假阳性的风险。所以增加 $C_{ij}$ 增加对<strong>错分类</strong>实例的惩罚，避免假阳性的出现，算是一种补偿机制。</li></ol><p>所以 seesaw loss 有以下优点：</p><ol><li>是动态的，它可以汇总全部训练集的信息，知道哪些是尾类，哪些被错分类，能够更好的调整损失</li><li>是自校准的，因为 $M<em>{ij}$ 和 $C</em>{ij}$ 能避免尾部类别被过度惩罚和假阳性</li><li>能更好的处理未知分布的数据集，毕竟在训练期间会统计各个类别的数目，所以能获得更好的正负样本梯度平衡</li></ol><h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><p>文中定义的 seesaw loss 是：</p><p>\begin{equation}<br>L(z) = -\sum<em>{i=1}^C y_i \log(\hat{\sigma_i}), \hat{\sigma_i} = \frac{e^{z_i}}{\sum</em>{j\neq i}^CS_{ij}e^{z_j}+e^{z_i}}<br>\end{equation}</p><p>所以对 $z_j$ 的偏导数就是：</p><p>\begin{equation}<br>\frac{\partial L}{\partial z<em>j} = S</em>{ij} \frac{e^z<em>j}{e^z_i} \hat{\sigma_i}, S</em>{ij} = M<em>{ij} \cdot C</em>{ij}<br>\end{equation}</p><p>$S<em>{ij}$ 表示一种可调节的因子，表示类别为 $i$ 的正样本对类别 $j$ 的惩罚。其中，$M</em>{ij}$ 表示头部类别 $i$ 降低对尾部类别 $j$ 的惩罚，$C_{ij}$ 表示增加对类别 $j$ 的惩罚，当类别 $i$ 被误分类为 $j$ 时。</p><h3 id="缓和因子"><a href="#缓和因子" class="headerlink" title="缓和因子"></a>缓和因子</h3><p>seesaw loss 在训练期间，会统计类别 $i$ 的数量为 $N_i$，对于正样本，也就是当前网络正在处理的类别 $i$，通过缓解因子调整对其它类别的惩罚，公式如下：</p><p>\begin{equation}<br>M_{ij} =<br>\begin{cases}<br>    1, &amp; N_i \leq N_j \\<br>    \biggl(\frac{N_j}{N_i}\biggr)^p, &amp; N_i &gt; N_j<br>\end{cases}<br>\end{equation}</p><p>如上述公式，当类别 $i$ 的数量 $N_i$ 远远大于其它类别时，对其它类别的惩罚力度会降低。$p$ 是控制惩罚程度的超参数。需要注意的是，seesaw loss 会在训练期间统计类别数量，而不是事先统计。这样做有两个好处：</p><ul><li>能适应不可见数据集，如训练数据来自流数据</li><li>每个类别的训练样本能被其它类别的数据适度的影响，更加鲁棒。比如当前每个类只有 5 个数据，就算不上谁是尾部，谁是头部，惩罚力度可以都一样，能更加均匀的初始化和光滑的适应真实世界的数据</li></ul><p><img data-src="https://z3.ax1x.com/2021/05/28/2kVrNR.png" alt></p><h3 id="补偿因子"><a href="#补偿因子" class="headerlink" title="补偿因子"></a>补偿因子</h3><p>这个计算就和上面的公式类似了，假设当前类别是 $i$ 时，被误分类为 $j$，那么缓和因子的计算公式为：</p><p>\begin{equation}<br>C_{ij} =<br>\begin{cases}<br>    1, &amp; \sigma_j \leq \sigma_j \\<br>    \biggl(\frac{\sigma_j}{\sigma_i}\biggr)^q, &amp; \sigma_j &gt; \sigma_i<br>\end{cases}<br>\end{equation}</p><p>$q$ 仍然是控制惩罚程度的超参数，被误分类的程度越大，补偿惩罚的力度就越大。</p><p><img data-src="https://z3.ax1x.com/2021/05/28/2keIpt.png" alt></p><h3 id="标准化线性层与输入"><a href="#标准化线性层与输入" class="headerlink" title="标准化线性层与输入"></a>标准化线性层与输入</h3><ul><li>对于头部类别 $i$，与其相关的分类参数 $W_i$ 可能会比较大，抑制了其它类别的表达，所以对分类层进行 $L_2$ 正则化处理</li><li>输入也要做正则化处理，我好奇为啥不是标准化</li></ul><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><p>不知道读到现在有没有发现论文的一个明显漏洞。在目标检测领域，从候选框到 ROI Pooling，到处都有背景类的存在，所以背景类会是头部类别，且数量远远大于其它类，对其它类产生抑制。所以，seesaw loss 会减少对<strong>所有</strong>前景类的抑制，但由于采样问题，背景类数量几乎不会低于前景类，所以不会有对前景类的<strong>补偿因子</strong>，这样，可能会将背景识别为前景。</p><p>所以论文的想法是，增加一个前景背景的二分类器，预测目标属于前景的概率 $\sigma_i^{obj}$ 还是背景的概率，背景会被抛弃，前景会被保留。而预测阶段，会保留这个二分类器。最终预测的目标概率就是：</p><p>\begin{equation}<br>\sigma_i = \sigma_i^{obj} \cdot \sigma_i^{class}<br>\end{equation}</p><h1 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h1><p>这篇论文的想法讲真还是不错的。忙猜一下，会有论文说这篇论文的 $p,q$ 是手工设定的不太好，$M<em>{ij}$ 和 $C</em>{ij}$ 直接相乘不太好没有道理。然后写篇论文，用神经网络自适应的学习参数 $p,q$ 或 $M_{ij}$，然后说这是改进，性能好了一些。<del>这样的东西我见过太多了，没意思，不过都是为了混一碗饭。</del></p><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;"><a href="https://arxiv.org/abs/2008.10032" target="_blank" rel="noopener">Seesaw Loss for Long-Tailed Instance Segmentation 论文</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;"><a href="https://tianchi.aliyun.com/competition/entrance/531888/information" target="_blank" rel="noopener">长尾分布图片来源</a></span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;论文好像是 2020 年底传到 arxiv &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 的，还比较新。正好最近遇到的问题是类别数量是长尾分布，恰好最近看到 mmdetection 也支持了这个损失函数，索性来看一看这篇论文，算是做个论文笔记吧。不过为了能更容易理解论文的思想，没有按照原论文的内容结构进行整理。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>可变形卷积 DCN，从 V1 到 V2</title>
    <link href="https://muyuuuu.github.io/2021/05/26/Deform-CNN/"/>
    <id>https://muyuuuu.github.io/2021/05/26/Deform-CNN/</id>
    <published>2021-05-26T20:42:34.000Z</published>
    <updated>2021-05-27T17:17:54.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>之前了解到，可变形卷积 DCN（Deformable Convolutional Networks）是上分常用小技巧，所以把论文找来读了一下，V1 和 V2 两个版本都读了一下，个人感觉以及他人复现的结果显示 <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> ，V1写的很好且够用，V2 写的实在是晕头转向。感觉还挺有创意，后期准备复现后，以后可能会用到。</p><a id="more"></a><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>传统的 CNN 在建模时，几何变化能力受限，感受野都是规则的相邻矩形。于是，提出了可变形卷积，通过无监督的形式学习额外的偏移参数，加强模型的几何变换能力。也就是说，有了偏移参数，此时的卷积核读取的输入不再是规则的矩阵。且像传统 CNN 一样，支持端到端训练和反向传播，可以通过插拔的形式替换传统模型中的 CNN 。</p><ul><li>偏移参数是在输入的特征图上增加额外的网络分支，自己学出来的，所以这是一种自适应的方式</li><li>在 ROI 时，也可以学习这种偏移参数，自适应的定位到感兴趣区域</li><li>两者都是通过添加额外的网络分支实现的，但计算量不大</li></ul><p>其实这种形式挺重要的，尤其是算法部署到真实世界，是无法提前预知目标和图像的大小的。而如果模型有这种自适应感知目标区域大小和调节感受野的能力则再好不过。如下图所示，DCN 相比 CNN 而言，能更好的感知目标区域。</p><p><img data-src="https://z3.ax1x.com/2021/05/27/2P4Q1J.png" alt></p><h1 id="变形卷积算法"><a href="#变形卷积算法" class="headerlink" title="变形卷积算法"></a>变形卷积算法</h1><p>首先定义区域 $R$ 是输入特征图 $x$ 中的规则矩形，卷积核的权重是 $w$，区域 $R$ 中的元素的含义为横坐标的偏移与纵坐标的偏移量，所以可以通过 $R$ 了解到卷积核的大小和扩张大小。</p><p>\begin{equation}<br>R = \bigl( (-1, 1), (-1, 0), \cdots, (0,1), (1,1) \bigr)<br>\end{equation}</p><p>上面公式中，卷积核的大小就是 3，元素数量是 9，扩张大小为 1。以 $y$ 表示输出特征图，那么 $y$ 在 $p_0$ 位置的取值为 ：</p><p>\begin{equation}<br>y(p<em>0) = \sum</em>{p_n \in R} w(p_n) x (p_0 + p_n)<br>\label{traditional}<br>\end{equation}</p><p>$(p_0 + p_n)$ 的意思是偏移到目标像素 $p_n$，原文没有解释，我看了半天才看懂。这也就是传统的卷积。如果我们对 $R$ 中的每一个位置的元素都有一个通过神经网络学习得来的偏移量 $(\Delta p_n | n=1,\cdots,N)$，那么公式 $\eqref{traditional}$ 可以改写为：</p><p>\begin{equation}<br>y(p<em>0) = \sum</em>{p_n \in R} w(p_n) x (p_0 + p_n + \Delta p_n)<br>\end{equation}</p><p>此时的卷积可视化如下图中的 b c d 部分，a 是标准的卷积。</p><p><img data-src="https://z3.ax1x.com/2021/05/27/2Py8mD.png" alt></p><p>因为 $p_n + \Delta p_n$ 可能是一个小数，所以需要使用双线性插值来对坐标取整，用 $p$ 来表示 $p_0 + p_n + \Delta p_n$，公式如下：</p><p>\begin{equation}<br>x(p) = \sum_{q} G(q,p)x(q)<br>\end{equation}</p><p>$q$ 是输入特征图中的像素，其实只用到了和 $p$ 相邻的一部分。而 $G$ 是一个二维的双线性插值核函数，可以用两部分表示：</p><p>\begin{equation}<br>G(q,p) = g(q_x,p_x) \cdot g(q_y,p_y)<br>\end{equation}</p><p>其中，$g(a,b) = \max(0, 1- |a-b|)$，所以这里也能看出来，如果 $a,b$ 相差很大，取值会为 0，所以每次计算取 $q$ 时，其实只用到了和 $p$ 相邻的一部分。</p><h1 id="变形卷积训练流程"><a href="#变形卷积训练流程" class="headerlink" title="变形卷积训练流程"></a>变形卷积训练流程</h1><p><img data-src="https://z3.ax1x.com/2021/05/27/2Pg4jP.png" alt></p><p>如上图所示，假设 $R$ 中卷积核的元素数量是 $N$，比如 $3\times 3$ 卷积核的元素数量就是 9。那么就增加一个旁路卷积，这个卷积的通道数就是 $2N$，且卷积前后尺寸不变。这样做的原因是，计算 $x$ 方向和 $y$ 方向共两个方向的偏移量。取前两个通道，就是当前卷积核处理像素点的横坐标偏移和纵坐标偏移。</p><h1 id="变形-ROI-Pooling"><a href="#变形-ROI-Pooling" class="headerlink" title="变形 ROI Pooling"></a>变形 ROI Pooling</h1><p>其实道理也和上面一样了，假设此时在目标检测中将特征图 ROI pool 到 $k\times k$ 的矩阵中，以平均池化为例，输出 $y$ 中第 $(i,j)$ 个元素的取值就是</p><p>\begin{equation}<br>y(i,j)=\sum<em>{p\in bin(i,j)} x(p + p_0) / n</em>{ij}<br>\end{equation}</p><p>$bin$ 表示要被池化的区域，$n<em>{ij}$ 是对应区域中的像素点的数量。而此时，可以学习一个偏移量参数 $\Delta p</em>{ij}$，新的 ROI Pooling 公式就是</p><p>\begin{equation}<br>y(i,j)=\sum<em>{p\in bin(i,j)} x(p + p_0 + \Delta p</em>{ij}) / n_{ij}<br>\end{equation}</p><p>双线性取整部分就和之前的一样了。不过论文中注明了一点，网络学习到的是 $\Delta \hat{p}_{ij}$，如下图所示，使用全连接计算每个像素点的偏移量。</p><p><img data-src="https://z3.ax1x.com/2021/05/27/2PhOOI.png" alt></p><p>而 $\Delta p<em>{ij} = \gamma \cdot \Delta \hat{p}</em>{ij} \circ (w,h)$，$\gamma$ 的取值是 0.1，$(w,h)$ 是 ROI Pooling 之前的特征图的宽度和高度，$\circ$ 运算是什么，文中没有声明。</p><h1 id="V2"><a href="#V2" class="headerlink" title="V2"></a>V2</h1><p>DCN V2 看的我属实头晕，不过大体贡献还是能看清的，集中改进了两点：</p><ul><li>采样时，如果采到了背景区域，会对目标分类与检测造成影响，所以要抑制背景区域的贡献</li><li>训练一个教师网络，类似判别器，用于指导检测网络的检测，文中称为特征模仿（feature mimicking），没读懂这个和前文改进的联系，唯一的相似点是摘要中指出的：提高模型捕获特征的能力，但我感觉这里是重点</li></ul><p>以可变形卷积为例，原有 DCN 的输出通道是 $2N$，那么作者将输出通道改为 $2N+1$，最后一个维度用 sigmoid 激活到 (0, 1) ，表示为符号 $\Delta m_k$ ，含义为当前像素点的贡献程度，如果是背景噪音，那么贡献会趋于 0。所以此时可变形卷积的公式为：</p><p>\begin{equation}<br>y(p<em>0) = \sum</em>{p_n \in R} w(p_n) x (p_0 + p_n + \Delta p_n) \cdot \Delta m_k<br>\end{equation}</p><p>至于 ROI Pooling 也是一个道理了。</p><h2 id="特征模仿"><a href="#特征模仿" class="headerlink" title="特征模仿"></a>特征模仿</h2><p>而另一个创新点是特征模仿，在主干网络 RPN 后，将得到的题夷旷送到另一个 RCNN 分支，两个分支的输出的相似性做对比作为损失，相似度越高，损失越小，相似度越低，损失越大。相似度是用 $\cos$ 函数计算的。</p><ul><li>测试时，不适用右侧的 RCNN分支</li><li>两个分支的 bacbone 部分共享参数</li><li>三个损失一起反向传播</li></ul><p><img data-src="https://z3.ax1x.com/2021/05/27/2PTMUx.png" alt></p><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">https://github.com/open-mmlab/mmdetection/tree/master/configs/dcn</span><a href="#fnref:1" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前了解到，可变形卷积 DCN（Deformable Convolutional Networks）是上分常用小技巧，所以把论文找来读了一下，V1 和 V2 两个版本都读了一下，个人感觉以及他人复现的结果显示 &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; ，V1写的很好且够用，V2 写的实在是晕头转向。感觉还挺有创意，后期准备复现后，以后可能会用到。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>分割篇：Mask R-CNN</title>
    <link href="https://muyuuuu.github.io/2021/05/25/Mask-R-CNN/"/>
    <id>https://muyuuuu.github.io/2021/05/25/Mask-R-CNN/</id>
    <published>2021-05-25T10:15:16.000Z</published>
    <updated>2021-05-25T17:33:18.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>不同于 FCN 的语义分割，Mask R-CNN 是用于实体分割的。借鉴 FCN 的思想，通过在 Faster R-CNN 的用于边界框识别分支上添加了一个并行的用于预测目标掩码的分支 Mask，在实现目标检测的同时，实现实例分割（object instance segmentation），即把每个目标像素分割出来。而 Faster R-CNN 和 FCN 在之前介绍过，所以本文的重点将会放在损失函数的设计和 ROI-Align 上。</p><p>实体分割不同于语义分割的是，不仅要检测出所属类别，还要区分同一类别下的不同实例。</p><p><img data-src="https://z3.ax1x.com/2021/05/25/gxXEss.png" alt></p><a id="more"></a><p>按着前文描述，网络结构如下，蓝色分支是 Faster R-CNN 中用于预测类别和回归框的分支，红色分支是新加入的预测掩码的分支。</p><p><img data-src="https://z3.ax1x.com/2021/05/25/gxOoa6.png" alt></p><h1 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h1><p>语义分割问题只需要在语义上对像素点进行区分即可。而实例分割问题不仅需要正确地检测出所有的目标，还需要在单个目标的基础上对每一个实例进行准确的分割。而作者基于 Faster R-CNN 目标检测的框架和 FCN 的语义分割提出了 Mask R-CNN。所以流程就是：</p><ol><li>输入一副图片，将图片输入到特征提取层 backbone，也可以融合 FPN 机制，最终获得对应的 feature map。下图中，左图是 Mask R-CNN 和 Faster R-CNN 结合的方式，右图是 Mask R-CNN 和 FPN 结合的方式。</li><li>对 feature map 中获得多个候选 ROI，候选的 ROI 送入 RPN 网络进行二值分类和 bbox 回归，截止到这一步，Mask R-CNN 和 Faster R-CNN 完全相同</li><li>Mask R-CNN 中，取消 ROI pooling，替换为 ROI-Align</li><li>对这些 ROI 进行分类、box 回归和 MASK 生成</li></ol><p><del>如果看不懂建议重新看 Faster R-CNN 和 FCN</del></p><p><img data-src="https://z3.ax1x.com/2021/05/25/gxvu2F.png" alt></p><h1 id="ROI-Align"><a href="#ROI-Align" class="headerlink" title="ROI-Align"></a>ROI-Align</h1><p>对于传统的 ROI pooling 而言，难免会有精度损失。比如 <code>20X20</code> 的特征图 pool 到 <code>7X7</code>，自然无法整除，就需要对像素点进行取舍，带来精度上的损失。RoI 对应至特征图和 ROI 进行划分这两步取整量化操作会导致 ROI 与抽取出的特征图在空间位置上不匹配。这一问题不会对目标的分类造成大的影响，但会对 mask 预测造成极大的负面影响。如下图所示 <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> ，并非均匀划分：</p><p><img data-src="https://z3.ax1x.com/2021/05/25/gzSIZd.gif" alt></p><p>对于 ROI-Align 而言，不在对 ROI 边界进行取整。假设 pool 到 <code>3X3</code> 的格子，那么计算每个格子中心四个点的坐标。对于每个点而言，对每个周围的四个点进行采样，使用双线性插值计算当前点的取值，而后 max pool 获取当前格子里面的值。无论采样点的多少与采样方式，结果都不会很差。如果使用的量化取整，结果就会很差。如下图，作者也只使用了这一张图介绍了 ROI-Align。</p><p><img data-src="https://z3.ax1x.com/2021/05/25/gzptwd.png" alt></p><p>这个过程佷繁琐不易理解，但其实并不难，可以来这篇博客看下动图。<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup></p><p><img data-src="https://z3.ax1x.com/2021/05/25/gziG9I.gif" alt></p><h1 id="Mask-损失"><a href="#Mask-损失" class="headerlink" title="Mask 损失"></a>Mask 损失</h1><p>Mask R-CNN 的分支由三部分组成，其中 $L<em>{\text{cls}}$ 和 $L</em>{\text{box}}$ 与 Faster R-CNN 没有本质区别，所以重点是 $ L_{\text{mask}}$，它是平均二分类交叉熵损失。</p><p>\begin{equation}<br>L = L<em>{\text{cls}} + L</em>{\text{box}} + L_{\text{mask}}<br>\end{equation}</p><p>假设一共有 $K$ 个类别，则 Mask 分割分支的输出维度是 $K m m$。所以对于 $m\times m$ 中的每个点，都会输出 $K$ 个二值 Mask（每个类别使用 <code>sigmoid</code> 输出）。这里与 FCN 的做法不同，FCN 在每个像素点上应用 softmax 函数，整体采用多任务交叉熵，这样会导致类间竞争（class competition），最终导致分割效果差。其实上文也能看到，分割效果的确很差。</p><p><img data-src="https://z3.ax1x.com/2021/05/25/gzgnb9.png" alt></p><blockquote><p>在 Faster RCNN 做 object detection 的时候，已经把某一块 RoI 识别为汽车，但这个 RoI 内可能存在其他物体的一部分，因此分割的 mask 中，除了要将汽车分割出来外，还要把另外那个物体也分割出来。这就导致这样的情况，在 object detection 的分支中，这块 RoI 整体被识别为汽车，但在 segmentation 的时候，这块 RoI 一部分被识别为汽车，一部分又要当作其他物体。如此一来，这两个分支回传到前面的梯度多少存在冲突，而前面的特征提取网络可是共享的，结果网络在学习的时候就可能出现左右为难的情况。</p></blockquote><p>那么来考虑二分类。To this we apply a per-pixel sigmoid, and define $L<em>{\text{mask}}$ as the average binary cross-entropy loss. For an RoI associated with ground-truth class $k$, $L</em>{\text{mask}}$ is only defined on the $k$-th mask (other mask outputs do not contribute to the loss). 也就是，只考虑一种类别，如果 ground truth 中标记了这个 bounding box 中是个人的话，那我们就只针对人的 mask 进行分割，而对这个 bounding box 中其他可能存在的物体一律忽视。如下图所示。这里画图的思想参考了这篇文章 <sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>。</p><p><img data-src="https://z3.ax1x.com/2021/05/25/gzRBjS.png" alt></p><p>在测试阶段，通过分类分支预测的类别来选择相应的 Mask 预测。这样，Mask 预测和分类预测就彻底解耦了。</p><h1 id="程序"><a href="#程序" class="headerlink" title="程序"></a>程序</h1><ol><li><a href="https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html" target="_blank" rel="noopener">torchvision</a> 上有现成的示例。</li><li>等我以后用到语义分割的时候再回来补冲这里的程序，那时候肯定是 open-mmlab 系列的东西了。</li></ol><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;"><a href="https://en.wikipedia.org/wiki/File:RoI_pooling_animated.gif" target="_blank" rel="noopener">ROI pooling 动图</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;"><a href="https://towardsdatascience.com/understanding-region-of-interest-part-2-roi-align-and-roi-warp-f795196fc193" target="_blank" rel="noopener">ROI Align 动图</a></span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;"><a href="https://zhuanlan.zhihu.com/p/65321082" target="_blank" rel="noopener">二分类损失代替多分类损失</a></span><a href="#fnref:3" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;不同于 FCN 的语义分割，Mask R-CNN 是用于实体分割的。借鉴 FCN 的思想，通过在 Faster R-CNN 的用于边界框识别分支上添加了一个并行的用于预测目标掩码的分支 Mask，在实现目标检测的同时，实现实例分割（object instance segmentation），即把每个目标像素分割出来。而 Faster R-CNN 和 FCN 在之前介绍过，所以本文的重点将会放在损失函数的设计和 ROI-Align 上。&lt;/p&gt;
&lt;p&gt;实体分割不同于语义分割的是，不仅要检测出所属类别，还要区分同一类别下的不同实例。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://z3.ax1x.com/2021/05/25/gxXEss.png&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>分割篇：开山之作 FCN</title>
    <link href="https://muyuuuu.github.io/2021/05/24/FCN/"/>
    <id>https://muyuuuu.github.io/2021/05/24/FCN/</id>
    <published>2021-05-24T15:04:53.000Z</published>
    <updated>2021-05-25T17:32:30.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>CV 系列的论文和程序得一点点开坑了。目前准备的计划任务是：FCN，OHEM，Mask RCNN，YOLO，Focal loss，Seesaw loss。别问，问就是网上一点点查阅得到的，然后写写代码。这个系列完结后，大概会结合对抗样本 and 目标检测做一些东西。自己还是差的太远。</p><a id="more"></a><h1 id="什么是语义分割"><a href="#什么是语义分割" class="headerlink" title="什么是语义分割"></a>什么是语义分割</h1><p>语义分割的直观解释可以见下图，计算照片中的每一个像素点的类别，进而得到哪些像素点属于同一类，把一些物体给分割出来：</p><p><img data-src="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/pr/DBOverview1_1_huff_0000964.jpg" alt></p><h1 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h1><p>CNN 能够对图片进行分类，可是怎么样才能识别图片中特定部分的物体，在这篇论文之前，还是一个未解难题。</p><ul><li>对于传统的分类网络，经过 CNN 不断卷积、池化的处理，最后进入全连接网络，预测当前图片的分类。但会丢失空间信息，无法预测每个像素的分类。</li><li>对于目标检测的网络，也是经过 CNN 不断卷积、池化的处理，在最后的特征图上预测类别和位置。但识别出来的是目标框，并非物体的轮廓边界。</li></ul><p>而 FCN 的创新之处在于，使用卷积操作替换了分类网络的全连接，使得输入输出保持在相同尺寸，这样就可以预测每个像素点的类别。加上使用了卷积，自然而然也就可以处理任意尺寸的图像。网络结构如下，用下面的卷积替换上面的全连接：</p><p><img data-src="https://z3.ax1x.com/2021/05/24/gvGwrQ.png" alt></p><h1 id="上采样"><a href="#上采样" class="headerlink" title="上采样"></a>上采样</h1><p>经过不断的卷积，图像的尺寸会减少而维度会增加。所以为了使得网络输出的图像尺寸和原图像一致，需要进行一些上采样，使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在与输入图等大小的特征图上对每个像素进行分类，逐像素地用 softmax 分类计算损失，相当于每个像素对应一个训练样本。这部分在论文的第三章有所描述。</p><p>而上采样采用的操作是<strong>转置卷积</strong>，如下图 <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> 所示，蓝色是输入，青色是输出，将图像的尺寸瞬间增加了一倍。而文中发现，这种形式的上采样是最有效的，且，可以通过叠加之前的输入（类此残差），获得更好的精度。此外文中特意表明了转置卷积也是卷积层，按照普通的卷积层进行训练即可。</p><p><img data-src="https://z3.ax1x.com/2021/05/24/gvNSo9.gif" alt></p><h1 id="融合操作"><a href="#融合操作" class="headerlink" title="融合操作"></a>融合操作</h1><p><img data-src="https://z3.ax1x.com/2021/05/24/gva3Vg.png" alt></p><p>如上图所示，论文给出了 FCN 的三种版本。</p><ul><li>对于 FCN-32s，直接在最后一层进行 32 倍的上采样，原始空间信息倍大量丢失</li><li>对于 FCN-16s，将 pool5 后的结果进行 2 倍上采样，与 pool4 的结果相加，得到结果 $F$，而后进行 16 倍上采样</li><li>对于 FCN-8s，将 $F$ 与 pool3 后的结果相加，而后进行 8 倍上采样</li></ul><p>论文中的结论是，FCN-8s 的效果要好一些，毕竟更多的利用了原始空间信息。网络结构图如下 <sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> ：</p><p><img data-src="https://z3.ax1x.com/2021/05/24/gvwICd.png" alt></p><h1 id="程序"><a href="#程序" class="headerlink" title="程序"></a>程序</h1><p>网上看到了份程序，逻辑写的还不错：</p><p><a href="https://github.com/pochih/FCN-pytorch/blob/master/python/fcn.py" target="_blank" rel="noopener">https://github.com/pochih/FCN-pytorch/blob/master/python/fcn.py</a></p><p>尺寸在我裁剪图片的时候进行了放缩，不要太在意。</p><p><img data-src="https://z3.ax1x.com/2021/05/24/gvBWfH.png" alt></p><h2 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h2><p>若要可视化展示结果，需要对网络输出的结果进行解码。如标注图片上的类别等。假设输入图像的尺寸是 [800, 800] 的，当前类别数量是 21，会得到 [bacthsize, num_classes, height, width] 的输出。假设当前 batchsize 是 1，那么就需要在 num_classes 张 [height, width] 大小的图片中选择出每个像素点的类别。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">out = fcn(data)[<span class="string">'out'</span>]</span><br><span class="line"><span class="comment"># 选择每个像素点的最大的类别</span></span><br><span class="line">om = torch.argmax(out.squeeze(), dim=<span class="number">0</span>).detach().cpu().numpy()</span><br><span class="line">decode_segmap(om)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decode_segmap</span><span class="params">(image, nc=<span class="number">21</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 类别颜色，画图用</span></span><br><span class="line">    label_colors = np.array([</span><br><span class="line">        (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>),  <span class="comment"># 0=background</span></span><br><span class="line">        <span class="comment"># 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle</span></span><br><span class="line">        (<span class="number">128</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">        (<span class="number">0</span>, <span class="number">128</span>, <span class="number">0</span>),</span><br><span class="line">        (<span class="number">128</span>, <span class="number">128</span>, <span class="number">0</span>),</span><br><span class="line">        (<span class="number">0</span>, <span class="number">0</span>, <span class="number">128</span>),</span><br><span class="line">        (<span class="number">128</span>, <span class="number">0</span>, <span class="number">128</span>),</span><br><span class="line">        <span class="comment"># 6=bus, 7=car, 8=cat, 9=chair, 10=cow</span></span><br><span class="line">        (<span class="number">0</span>, <span class="number">128</span>, <span class="number">128</span>),</span><br><span class="line">        (<span class="number">128</span>, <span class="number">128</span>, <span class="number">128</span>),</span><br><span class="line">        (<span class="number">64</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">        (<span class="number">192</span>, <span class="number">0</span>, <span class="number">0</span>),</span><br><span class="line">        (<span class="number">64</span>, <span class="number">128</span>, <span class="number">0</span>),</span><br><span class="line">        <span class="comment"># 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person</span></span><br><span class="line">        (<span class="number">192</span>, <span class="number">128</span>, <span class="number">0</span>),</span><br><span class="line">        (<span class="number">64</span>, <span class="number">0</span>, <span class="number">128</span>),</span><br><span class="line">        (<span class="number">192</span>, <span class="number">0</span>, <span class="number">128</span>),</span><br><span class="line">        (<span class="number">64</span>, <span class="number">128</span>, <span class="number">128</span>),</span><br><span class="line">        (<span class="number">192</span>, <span class="number">128</span>, <span class="number">128</span>),</span><br><span class="line">        <span class="comment"># 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor</span></span><br><span class="line">        (<span class="number">0</span>, <span class="number">64</span>, <span class="number">0</span>),</span><br><span class="line">        (<span class="number">128</span>, <span class="number">64</span>, <span class="number">0</span>),</span><br><span class="line">        (<span class="number">0</span>, <span class="number">192</span>, <span class="number">0</span>),</span><br><span class="line">        (<span class="number">128</span>, <span class="number">192</span>, <span class="number">0</span>),</span><br><span class="line">        (<span class="number">0</span>, <span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">    ])</span><br><span class="line">    r = np.zeros_like(image).astype(np.uint8)</span><br><span class="line">    g = np.zeros_like(image).astype(np.uint8)</span><br><span class="line">    b = np.zeros_like(image).astype(np.uint8)</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(<span class="number">0</span>, nc):</span><br><span class="line">        <span class="comment"># 目标类的索引</span></span><br><span class="line">        idx = image == l</span><br><span class="line">        r[idx] = label_colors[l, <span class="number">0</span>]</span><br><span class="line">        g[idx] = label_colors[l, <span class="number">1</span>]</span><br><span class="line">        b[idx] = label_colors[l, <span class="number">2</span>]</span><br><span class="line">    rgb = np.stack([r, g, b], axis=<span class="number">2</span>)</span><br><span class="line">    plt.imshow(rgb)</span><br><span class="line">    plt.savefig(<span class="string">'result.png'</span>)</span><br></pre></td></tr></table></figure><h1 id="延伸"><a href="#延伸" class="headerlink" title="延伸"></a>延伸</h1><p>此外，U-Net <sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup> 的网络结构也适合做分割，先记下来，也许某一天做语义分割的任务会用到。</p><p><img data-src="https://z3.ax1x.com/2021/05/24/gv6rd0.png" alt></p><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;"><a href="https://arxiv.org/abs/1411.4038" target="_blank" rel="noopener">Fully Convolutional Networks for Semantic Segmentation</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;"><a href="https://github.com/vdumoulin/conv_arithmetic" target="_blank" rel="noopener">卷积动画演示</a></span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;"><a href="http://flyrie.top/2018/06/22/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%EF%BC%88FCN%EF%BC%89/" target="_blank" rel="noopener">FCN-8s 结构图</a></span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">4.</span><span style="display: inline-block; vertical-align: top;"><a href="https://learnopencv.com/pytorch-for-beginners-semantic-segmentation-using-torchvision/" target="_blank" rel="noopener">分割后的图片解码 </a></span><a href="#fnref:4" rev="footnote"> ↩</a></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">5.</span><span style="display: inline-block; vertical-align: top;"><a href="https://github.com/milesial/Pytorch-UNet" target="_blank" rel="noopener">U-Net 网络实现</a></span><a href="#fnref:5" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;CV 系列的论文和程序得一点点开坑了。目前准备的计划任务是：FCN，OHEM，Mask RCNN，YOLO，Focal loss，Seesaw loss。别问，问就是网上一点点查阅得到的，然后写写代码。这个系列完结后，大概会结合对抗样本 and 目标检测做一些东西。自己还是差的太远。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>目标检测篇：自定义 MMDetection 的 Pipeline</title>
    <link href="https://muyuuuu.github.io/2021/05/20/MMdetection-pipeline/"/>
    <id>https://muyuuuu.github.io/2021/05/20/MMdetection-pipeline/</id>
    <published>2021-05-20T15:57:34.000Z</published>
    <updated>2021-05-25T17:34:58.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>经过几天连续的开坑和读源代码，对 mmdetection 的配置流程了解的差不多了。考虑一个实例应用，尝试着将 <code>FGSM</code> 攻击算法的制作的对抗样本植入目标检测中，企图增加网络的鲁棒性，也就是一个自定义输出处理 <code>Pipeline</code> 的实际流程。之后会尝试自定义损失函数，支持简单的对抗训练，如 MART 算法等 <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>。</p><a id="more"></a><h1 id="对抗攻击之植入-mmdetection"><a href="#对抗攻击之植入-mmdetection" class="headerlink" title="对抗攻击之植入 mmdetection"></a>对抗攻击之植入 mmdetection</h1><p>众所周知，攻击算法基于原始样本制作一种含有梯度的扰动信息，将扰动信息叠加至原始样本，就得到了对抗样本。因此，对抗样本应该添加在数据处理的 pipeline 中，而不是网络层。首先实现最简单的对抗训练：</p><p>\begin{equation}<br>\min<em>\theta \biggl( \max \Bigl( l \bigl(T</em>\theta(x’), y_i \bigl) \Bigr) \biggr)<br>\end{equation}</p><p>内部的对抗样本 $x’$ 企图最大化模型的分类误差，外部的训练企图最小化对抗样本带来的误差。查看训练数据的 pipeline，我们发现是在最后一步转为 tensor，而攻击算法是在tensor上进行操作的。所以，对抗攻击应该加在最后一步之后或之前。我们查看返回 tensor 的源代码。此部分代码在 <code>mmdet/datasets/pipelines</code> 目录下。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, results)</span>:</span></span><br><span class="line">    <span class="string">"""Call function to transform and format common fields in results.</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        results (dict): Result dict contains the data to convert.</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        dict: The result dict contains the data that is formatted with \</span></span><br><span class="line"><span class="string">            default bundle.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="string">'img'</span> <span class="keyword">in</span> results:</span><br><span class="line">        img = results[<span class="string">'img'</span>]</span><br><span class="line">        <span class="comment"># add default meta keys</span></span><br><span class="line">        results = self._add_default_meta_keys(results)</span><br><span class="line">        <span class="keyword">if</span> len(img.shape) &lt; <span class="number">3</span>:</span><br><span class="line">            img = np.expand_dims(img, <span class="number">-1</span>)</span><br><span class="line">        img = np.ascontiguousarray(img.transpose(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">        results[<span class="string">'img'</span>] = DC(to_tensor(img), stack=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> [<span class="string">'proposals'</span>, <span class="string">'gt_bboxes'</span>, <span class="string">'gt_bboxes_ignore'</span>, <span class="string">'gt_labels'</span>]:</span><br><span class="line">        <span class="keyword">if</span> key <span class="keyword">not</span> <span class="keyword">in</span> results:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        results[key] = DC(to_tensor(results[key]))</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'gt_masks'</span> <span class="keyword">in</span> results:</span><br><span class="line">        results[<span class="string">'gt_masks'</span>] = DC(results[<span class="string">'gt_masks'</span>], cpu_only=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'gt_semantic_seg'</span> <span class="keyword">in</span> results:</span><br><span class="line">        results[<span class="string">'gt_semantic_seg'</span>] = DC(</span><br><span class="line">            to_tensor(results[<span class="string">'gt_semantic_seg'</span>][<span class="literal">None</span>, ...]), stack=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><p>而对抗攻击只关注图像与标签，所以，只关注图像与标签，而这部分一目了然。所以，开始写自己的对抗样本：</p><ul><li>黑盒攻击，基于 resnet18 制作攻击样本，插入到 pipeline 中</li><li>我暂时的想法是只攻击目标区域，所以筛选出目标区域的位置与标签，按照梯度上升的方向制作对抗样本。</li></ul><h1 id="自定义-backbone"><a href="#自定义-backbone" class="headerlink" title="自定义 backbone"></a>自定义 backbone</h1><p><strong>注意这步不做也行</strong>。可以直接模改原有的 <code>backbone</code>，只是不推荐。而为了方便调试，我们使用自己定义的网络，网络只打印输入观察数据是否修改成功。因此，自定义的网络如下，并放在 <code>mmdet/models/backbones/mybackbone</code>下，</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> ..builder <span class="keyword">import</span> BACKBONES</span><br><span class="line"></span><br><span class="line"><span class="meta">@BACKBONES.register_module()</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">mynet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        print(x)</span><br></pre></td></tr></table></figure><p>而后为了导入模块，在 <code>mmdet/models/backbones/__init__.py</code> 中添加 <code>from .mybackbone import mynet</code>。为了适配 faster rcnn 的其它参数，我这里的 backbone 直接使用了 ResNet 里面的内容，只是打印了 x，这里是为了方便观察结果。这里需要注意，那些 <code>super</code> 初始化也要改，防止重名，因为不具备普适性，所以这里就不演示了。而后配置文件中指定以下就可以自由使用，我的配置文件是 <code>adv_faster_rcnn.py</code>：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = dict(</span><br><span class="line">    ...</span><br><span class="line">    backbone=dict(</span><br><span class="line">        type=<span class="string">'mynet'</span>,</span><br><span class="line">        arg1=xxx,</span><br><span class="line">        arg2=xxx),</span><br><span class="line">    ...</span><br><span class="line"><span class="comment"># 测试用，跑一轮就停</span></span><br><span class="line">runner = dict(type=<span class="string">'EpochBasedRunner'</span>, max_epochs=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>而后执行一下，成功的看到输入被打印了出来。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mmdet.apis <span class="keyword">import</span> init_detector, inference_detector</span><br><span class="line"><span class="comment"># 目标检测配置文件</span></span><br><span class="line">config_file = <span class="string">'mmdetection/configs/faster_rcnn/adv_faster_rcnn.py'</span></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">checkpoint_file = <span class="string">'mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置模型</span></span><br><span class="line">model = init_detector(config=config_file,</span><br><span class="line">                      checkpoint=checkpoint_file,</span><br><span class="line">                      device=<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line">img = <span class="string">'a.png'</span></span><br><span class="line"><span class="comment">#  推理实际调用语句</span></span><br><span class="line"><span class="comment"># results = model(return_loss=False, rescale=True, **data)</span></span><br><span class="line">result = inference_detector(model=model, imgs=img)</span><br></pre></td></tr></table></figure><h1 id="对抗样本代码思想"><a href="#对抗样本代码思想" class="headerlink" title="对抗样本代码思想"></a>对抗样本代码思想</h1><p>首先在 <code>pipeline</code> 文件夹下创建自己的 <code>my_pipeline</code>，而后定义自己的处理流程，比如我就看看处理的数据都有哪些：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mmdet.datasets <span class="keyword">import</span> PIPELINES</span><br><span class="line"></span><br><span class="line"><span class="meta">@PIPELINES.register_module()</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyTransform</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, results)</span>:</span></span><br><span class="line">        print(type(results))</span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> results:</span><br><span class="line">            print(key, type(results[key]))</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><p>最后在 <code>__init__.py</code> 中导入自己的东西，<code>from .my_pipeline import MyTransform</code>。综上发现，在 <code>DefaultFormatBundle</code> 和 <code>Collect</code> 处理后，数据类型不是我能驾驭的常见数据类型： <code>mmcv.parallel.data_container.DataContainer</code>。</p><p>所以选择在 <code>Normalize</code> 后加入对抗攻击，因为常见的攻击算法也都是在标准化之后，此外那里还是 <code>ndarray</code> 等常见类型，我能把握住这些基本的类似那个。<code>Normalize</code> 后的数据类型：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">img_prefix      &lt;<span class="class"><span class="keyword">class</span> '<span class="title">str</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">seg_prefix</span>      &lt;<span class="title">class</span> '<span class="title">NoneType</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">proposal_file</span>   &lt;<span class="title">class</span> '<span class="title">NoneType</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">bbox_fields</span>     &lt;<span class="title">class</span> '<span class="title">list</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">mask_fields</span>     &lt;<span class="title">class</span> '<span class="title">list</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">seg_fields</span>      &lt;<span class="title">class</span> '<span class="title">list</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">filename</span>        &lt;<span class="title">class</span> '<span class="title">str</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">ori_filename</span>    &lt;<span class="title">class</span> '<span class="title">str</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">img</span>             &lt;<span class="title">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">img_shape</span>       &lt;<span class="title">class</span> '<span class="title">tuple</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">ori_shape</span>       &lt;<span class="title">class</span> '<span class="title">tuple</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">img_fields</span>      &lt;<span class="title">class</span> '<span class="title">list</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">gt_bboxes</span>       &lt;<span class="title">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">gt_bboxes_ignore</span>        &lt;<span class="title">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">gt_labels</span>       &lt;<span class="title">class</span> '<span class="title">numpy</span>.<span class="title">ndarray</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">flip</span>            &lt;<span class="title">class</span> '<span class="title">bool</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">flip_direction</span>  &lt;<span class="title">class</span> '<span class="title">NoneType</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">img_norm_cfg</span>    &lt;<span class="title">class</span> '<span class="title">dict</span>'&gt;</span></span><br></pre></td></tr></table></figure><p>我利用的信息只有 <code>img</code>，<code>gt_labels</code> 和 <code>gt_bboxes</code>。其实我也不知道以上字段是啥，源码和文档的信息很少，所以我只能自己都打印了一下。所以此时的任务就是，按照 <code>gt_bboxes</code>，截取 <code>img</code>，根据 <code>gt_labels</code>，制作对抗样本。但对抗样本返回的是 tensor，所以最后要转回到 numpy，在覆盖原来的数据。而 PGD、CW 等攻击算法过程会很慢，所以选用攻击强度大且快捷的 <code>FGSM</code> 单步算法。</p><p>而为了防止对抗样本带来的过大负担，所以添加了两个额外参数 $p_1$ 和 $p_2$。</p><ul><li>如果概率小于 $p_1$，在目标区域叠加高斯噪音</li><li>如果概率在 $p_1$ 到 $p_2$ 之间，在目标区域制作对抗样本</li><li>如果概率大于 $p_2$，使用原图，不做任何处理</li></ul><p>综上，此时的配置文件应该为：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">adv_para = dict(mu=<span class="number">0</span>, std=<span class="number">0.1</span>, epsilon=<span class="number">0.1</span>, pro1=<span class="number">0.3</span>, pro2=<span class="number">0.6</span>, adv=<span class="string">'fgsm'</span>)</span><br><span class="line"></span><br><span class="line">train_pipeline = [</span><br><span class="line">    dict(type=<span class="string">'LoadImageFromFile'</span>),</span><br><span class="line">    dict(type=<span class="string">'LoadAnnotations'</span>, with_bbox=<span class="literal">True</span>),</span><br><span class="line">    dict(type=<span class="string">'Resize'</span>, img_scale=(<span class="number">1333</span>, <span class="number">800</span>), keep_ratio=<span class="literal">True</span>),</span><br><span class="line">    dict(type=<span class="string">'RandomFlip'</span>, flip_ratio=<span class="number">0.0001</span>),</span><br><span class="line">    dict(type=<span class="string">'Normalize'</span>, **img_norm_cfg_trian),</span><br><span class="line">    <span class="comment"># 自己的 pipeline</span></span><br><span class="line">    dict(type=<span class="string">'advTransform'</span>, **adv_para),</span><br><span class="line">    dict(type=<span class="string">'Pad'</span>, size_divisor=<span class="number">32</span>),</span><br><span class="line">    dict(type=<span class="string">'DefaultFormatBundle'</span>),</span><br><span class="line">    dict(type=<span class="string">'Collect'</span>, keys=[<span class="string">'img'</span>, <span class="string">'gt_bboxes'</span>, <span class="string">'gt_labels'</span>]),</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h1 id="开始制作"><a href="#开始制作" class="headerlink" title="开始制作"></a>开始制作</h1><p>为了使代码易于维护和扩展，我尽力使额外添加的程序符合设计模式，对扩展开放，对修改封闭，针对接口编程。</p><ul><li>在 <code>mmdet/datasets/pipelines/</code> 目录下增加 <code>adv_example</code> pipeline，生成对抗样本。</li><li>至于攻击算法，依据设计模式，应使用额外的类来实现。位于 <code>datasets/</code> 目录下，命名为 attack 文件夹。</li></ul><h2 id="对抗样本-pipeline"><a href="#对抗样本-pipeline" class="headerlink" title="对抗样本 pipeline"></a>对抗样本 pipeline</h2><p>这里有几个点需要注意下：</p><ul><li>通过获得的 <code>results</code>，图像的维度是：高、宽、通道</li><li><code>bboxes</code> 中的信息是 <code>x1,x2,y1,y2</code> </li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mmdet.datasets <span class="keyword">import</span> PIPELINES</span><br><span class="line"><span class="comment"># 导入攻击算法</span></span><br><span class="line"><span class="keyword">from</span> mmdet.datasets <span class="keyword">import</span> attack</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@PIPELINES.register_module()</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">advTransform</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">                 mu=<span class="number">0</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 std=<span class="number">0.1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 epsilon=<span class="number">0.1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 pro1=<span class="number">0.3</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 pro2=<span class="number">0.6</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 adv=<span class="string">'fgsm'</span>)</span>:</span></span><br><span class="line">        <span class="comment"># 高斯噪音的均值和方差</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(mu, int) <span class="keyword">or</span> isinstance(mu, float):</span><br><span class="line">            self.mu = mu</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.mu = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> isinstance(mu, int) <span class="keyword">or</span> isinstance(mu, float):</span><br><span class="line">            self.std = std</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.std = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对抗扰动值</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(mu, int) <span class="keyword">or</span> isinstance(mu, float):</span><br><span class="line">            self.epsilon = epsilon</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.epsilon = <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 概率 p1 和 p2</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(pro1, float):</span><br><span class="line">            self.pro1 = pro1</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.pro1 = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> isinstance(pro2, float):</span><br><span class="line">            self.pro2 = pro2</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.pro2 = <span class="number">0.6</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用的攻击算法</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(adv, str):</span><br><span class="line">            self.adv = adv</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.adv = <span class="string">'fgsm'</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 产生一个随机数</span></span><br><span class="line">        <span class="comment"># 如果位于区间 [0, pro1), 目标区域添加噪音</span></span><br><span class="line">        <span class="comment"># 如果位于区间 [pro1, pro2), 目标区域用 adv 算法攻击</span></span><br><span class="line">        <span class="comment"># 如果区间位于 [pro2, 1) 不做任何操作，返回原图</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">assert</span> <span class="number">0</span> &lt; pro1 &lt; pro2 &lt; <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.pro1 = pro1</span><br><span class="line">        self.pro2 = pro2</span><br><span class="line"></span><br><span class="line">        self.rand_ = random.random()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 复写这个方法</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, results)</span>:</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(len(results['gt_bboxes']))</span></span><br><span class="line">        <span class="comment"># print(len(results['gt_labels']))</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回原图</span></span><br><span class="line">        <span class="keyword">if</span> self.rand_ &gt; self.pro2:</span><br><span class="line">            <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 目标区域叠加高斯噪音</span></span><br><span class="line">        <span class="keyword">elif</span> self.rand_ &lt; self.pro1:</span><br><span class="line">            <span class="comment"># 可能有好几个盒子</span></span><br><span class="line">            bboxes = results[<span class="string">'gt_bboxes'</span>]</span><br><span class="line">            img = results[<span class="string">'img'</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> box <span class="keyword">in</span> bboxes:</span><br><span class="line">                box = box.tolist()</span><br><span class="line">                box = [int(i) <span class="keyword">for</span> i <span class="keyword">in</span> box]</span><br><span class="line">                x1, y1, x2, y2 = box[<span class="number">0</span>], box[<span class="number">1</span>], box[<span class="number">2</span>], box[<span class="number">3</span>]</span><br><span class="line">                noise = np.random.normal(</span><br><span class="line">                    self.mu, self.std, size=(y2 - y1, x2 - x1, <span class="number">3</span>))</span><br><span class="line">                img[y1:y2, x1:x2] += noise</span><br><span class="line"></span><br><span class="line">            results[<span class="string">'img'</span>] = img</span><br><span class="line">            <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对抗攻击</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># labels = results['ann_info']['labels']</span></span><br><span class="line">            <span class="comment"># bboxes = results['ann_info']['bboxes']</span></span><br><span class="line">            labels = results[<span class="string">'gt_labels'</span>]</span><br><span class="line">            bboxes = results[<span class="string">'gt_bboxes'</span>]</span><br><span class="line">            img = results[<span class="string">'img'</span>]</span><br><span class="line">            <span class="comment"># 针对接口编程，只需要给攻击算法提供 图像、位置、标签和扰动值</span></span><br><span class="line">            img = attack.fgsm.fgsm_attack(img, bboxes, labels, self.epsilon)</span><br><span class="line">            results[<span class="string">'img'</span>] = img</span><br><span class="line">            <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><h2 id="攻击算法"><a href="#攻击算法" class="headerlink" title="攻击算法"></a>攻击算法</h2><p>攻击算法位于 <code>datasets/attack/</code> 文件夹下。此外，为了导入包，需要添加 <code>__init__.py</code>，并按以下格式添加内容：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> .fgsm <span class="keyword">import</span> fgsm_attack</span><br><span class="line"></span><br><span class="line">__all__ = [<span class="string">'fgsm_attack'</span>]</span><br></pre></td></tr></table></figure><p>同样这里也有一些需要注意的地方：</p><ul><li>针对接口编程，只需要给攻击算法提供图像、目标区域、标签和扰动值，至于内部自己如何实现，不重要</li><li>攻击算法返回的就是图像，内部如何实现，不重要，减少两个模块的耦合</li></ul><p><code>fgsm.py</code> 的内容为：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fgsm_attack</span><span class="params">(img, bboxes, labels, epsilon)</span>:</span></span><br><span class="line">    <span class="comment"># data_grad 转 tensor</span></span><br><span class="line">    <span class="keyword">import</span> torch</span><br><span class="line">    <span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">    model = torch.hub.load(</span><br><span class="line">        <span class="string">'pytorch/vision:v0.9.0'</span>, <span class="string">'resnet18'</span>, pretrained=<span class="literal">True</span>)</span><br><span class="line">    model.eval()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 增加 batch 维度，然后 channel first</span></span><br><span class="line">    tmp_img = torch.from_numpy(img).clone().unsqueeze(dim=<span class="number">0</span>).transpose(</span><br><span class="line">        <span class="number">1</span>, <span class="number">3</span>).transpose(<span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># tenor 转 numpy</span></span><br><span class="line">    <span class="keyword">for</span> box, target <span class="keyword">in</span> zip(bboxes, labels):</span><br><span class="line">        <span class="comment"># numpy 2 list</span></span><br><span class="line">        box = box.tolist()</span><br><span class="line">        box = [int(i) <span class="keyword">for</span> i <span class="keyword">in</span> box]</span><br><span class="line">        <span class="comment"># print(box, target)</span></span><br><span class="line">        x1, y1, x2, y2 = box[<span class="number">0</span>], box[<span class="number">1</span>], box[<span class="number">2</span>], box[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># deep copy</span></span><br><span class="line">        input_ = tmp_img[:, :, y1:y2, x1:x2].clone()</span><br><span class="line">        input_.requires_grad = <span class="literal">True</span></span><br><span class="line">        label = torch.tensor([int(target)])</span><br><span class="line"></span><br><span class="line">        output = model(input_)</span><br><span class="line"></span><br><span class="line">        loss = F.nll_loss(output, label)</span><br><span class="line">        <span class="comment"># model.zero_grad()</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        sign_data = input_.grad.data.sign()</span><br><span class="line">        <span class="comment"># 脱离计算图</span></span><br><span class="line">        perturbed_image = input_.detach() + epsilon * sign_data</span><br><span class="line">        <span class="comment"># 指定区域生成对抗样本</span></span><br><span class="line">        tmp_img[:, :, y1:y2, x1:x2] += perturbed_image</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除 batch 维度</span></span><br><span class="line">    tmp_img = tmp_img.squeeze().detach().cpu().numpy().transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> tmp_img</span><br></pre></td></tr></table></figure><h1 id="踩坑记录"><a href="#踩坑记录" class="headerlink" title="踩坑记录"></a>踩坑记录</h1><ul><li>也许你看过一些对抗攻击的算法，知道最后的对抗样本应该 <code>torch.clamp</code> 到 $[0,1]$。可那是论文里用的玩具数据集才会做的事情，那些数据集知道均值和方差。现实世界的真实数据，又怎么会知道均值和方差，怎么去标准化到 $[0,1]$ 之间呢？</li><li>我遇到了一个佷头疼的 bug，是多线程导致的反向传播异常，大概错误信息是：terminate called after throwing an instance of ‘c10::Error what():  CUDA error: initialization error。网上翻阅了无数 bug issue，才找到一篇有用的，也不知道那些 github 仓库的作者咋想的，问题还没解决就 close 掉，冲业绩还是图仓库 bug 少？这里把每个 GPU 的线程数量设为 0 就可以了 <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> 。而至于写多线程下的梯度反向传播，我貌似还没这个本事。<strong>但是，我服务器上没发现有这个 bug，应该是版本问题。</strong></li></ul><h1 id="程序"><a href="#程序" class="headerlink" title="程序"></a>程序</h1><p>官方的程序如何使用，我的就怎么使用，毕竟是直接 <code>fork</code> 过来的，从安装一步步来就行。此外，为了方便使用，我把配置文件放到了 <code>configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py</code> 文件中，可以进去参观下。</p><p><a href="https://github.com/muyuuuu/mmdetection" target="_blank" rel="noopener">https://github.com/muyuuuu/mmdetection</a></p><p>此外，我在 colab 也创建了一份能用的，在不会用就真没救了。</p><p><a href="https://github.com/muyuuuu/open-mmlab-colab/blob/main/Detection/mmdet_adv.ipynb" target="_blank" rel="noopener">https://github.com/muyuuuu/open-mmlab-colab/blob/main/Detection/mmdet_adv.ipynb</a></p><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">https://openreview.net/forum?id=rklOg6EFwS</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">https://github.com/pytorch/pytorch/issues/1355#issuecomment-299094286</span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;经过几天连续的开坑和读源代码，对 mmdetection 的配置流程了解的差不多了。考虑一个实例应用，尝试着将 &lt;code&gt;FGSM&lt;/code&gt; 攻击算法的制作的对抗样本植入目标检测中，企图增加网络的鲁棒性，也就是一个自定义输出处理 &lt;code&gt;Pipeline&lt;/code&gt; 的实际流程。之后会尝试自定义损失函数，支持简单的对抗训练，如 MART 算法等 &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>目标检测篇：MMDetection 推理使用与详细踩坑记录</title>
    <link href="https://muyuuuu.github.io/2021/05/11/MMDetection-use/"/>
    <id>https://muyuuuu.github.io/2021/05/11/MMDetection-use/</id>
    <published>2021-05-11T22:13:23.000Z</published>
    <updated>2021-05-25T17:35:22.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最近喜欢上了听音乐，B 站关注了个 UP 主叫『<strong>咻咻满</strong>』，长得好看，戏腔唱『<strong>青花瓷</strong>』入坑了，也听了其它的『星辰大海』和『白月光和朱砂痣』，都挺好听。以后得关注点女 UP 了，看着多可爱，生活又不是只有代码。卧艹不对说回正题。</p><p>MMDetection 是一个基于 PyTorch 的目标检测开源工具箱 <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>，支持了众多主流的和最新的检测算法，例如 Faster R-CNN，Mask R-CNN，RetinaNet 等，官网也给出了详细的教程。既然如此，生命不息，开坑不止。前前后后被各种事情打断，大概花了一周搞懂了如何使用 <code>MMdetection</code> 去做检测的任务。本文收录：</p><ul><li>安装</li><li>修改配置文件</li><li>调用模型与训练好的参数，进行推理</li><li>自定义训练</li><li>数据处理流程</li></ul><p>注意，本文更多像是记录学习过程，这也是我第一次用这个工具，遇到问题一步一步的 debug 与记录，并不是直接的教程。且，本文程序大多能直接复制运行，需要对应到自己的路径。我希望读者看完本文后具有解决问题的能力，而不只是会解决问题。</p><a id="more"></a><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>MMDetection 检测框架包括 mmdetection 和 mmcv，两者是不可分割的。首先安装 mmcv，掏出官方文档 <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>，发现有两个版本可供安装，支持 <code>CUDA</code> 操作的 mmcv-full 和不支持 <code>CUDA</code> 的 mmcv，而图片处理显然需要 <code>GPU</code>。所以知道了要安装的是 mmcv-full，之后就是确定安装版本。</p><p>首先查看自己的 <code>CUDA</code> 和 <code>pytorch</code> 版本，然后查阅官方提供的表格，找到对应的安装命令。综上，我本地服务器的安装指令就是（我现在写代码都默认 Linux 系统了，本教程不知道适不适合 windows）</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu92/torch1<span class="number">.7</span><span class="number">.0</span>/index.html</span><br></pre></td></tr></table></figure><p>而后安装 mmdetection，继续掏出官方文档 <sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>，按着步骤一步一步来：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/open-mmlab/mmdetection.git</span><br><span class="line">cd mmdetection</span><br><span class="line">pip install -r requirements/build.txt</span><br><span class="line">pip install -v -e .</span><br></pre></td></tr></table></figure><p>也就是安装完成后，当前目录会保留一个 <code>mmdetection</code> 的文件夹，一些模型的配置文件都在里面，不要删除这个文件夹。在安装完成后，执行一段代码查看是否安装成功</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mmdet.apis <span class="keyword">import</span> init_detector, inference_detector</span><br></pre></td></tr></table></figure><h1 id="简单推理"><a href="#简单推理" class="headerlink" title="简单推理"></a>简单推理</h1><p>在网上查阅相关用法时，发现绝大多数教程<strong>已经过时</strong>，软件迭代重构、接口更新很正常。即使某一天本文被骂陈旧过时，我也不会感觉到任何意外。接口问题多查阅官方文档，其余问题可以多用谷歌搜索。但官方文档 <sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> 写的实在是烂，甚至连返回类型都没写，是 tensor，还是 list。不仅没写类型，输出是什么也没写，是得分，是窗口还是类别，一个字都不肯多说，<strong>以上结论仅限博客发布的日期</strong>。所以只能自己一个一个打印了，然后自己分析了下，结果的形式是多个列表，因为有多个目标。每个列表的形式是盒子 <code>xmin, ymin, xmax, ymax</code> 以及得分。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mmdet.apis <span class="keyword">import</span> init_detector, inference_detector</span><br><span class="line"></span><br><span class="line"><span class="comment"># 目标检测配置文件</span></span><br><span class="line">config_file = <span class="string">'mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'</span></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">checkpoint_file = <span class="string">'mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置模型</span></span><br><span class="line">model = init_detector(config=config_file,</span><br><span class="line">                      checkpoint=checkpoint_file,</span><br><span class="line">                      device=<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line">img = <span class="string">'woman-3377839_1920.jpg'</span></span><br><span class="line"><span class="comment">#  推理实际调用语句</span></span><br><span class="line"><span class="comment"># results = model(return_loss=False, rescale=True, **data)</span></span><br><span class="line">result = inference_detector(model=model, imgs=img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印结果</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">    print(i)</span><br></pre></td></tr></table></figure><p>在我打印 result 后，发现了一个震惊的消息，只有盒子、概率，没有类别，也就时说代码只能预测当前目标在哪，目标的概率，但不能预测目标是什么 <sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>，没有类别输出。来看一下官方的回答。我当时属实没看懂，数据集有类别信息？既然有了类别信息还推理干啥…</p><p><img data-src="https://z3.ax1x.com/2021/05/13/gBkChn.png" alt></p><p>没办法接着去翻 github，自己提了个问 <sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>。才知道 <code>result</code> 的长度就是类别长度，而 <code>print(model.CLASSES)</code> 可以打印类别。比如 <code>model.ClASSES</code> 的长度是 80，那么 <code>result</code> 的长度也就是 80，<code>result[0]</code> 就对应 <code>model.CLASSES</code> 的第一个类别，表示第一个类别的盒子、概率。这样一切就解释通了。</p><ul><li>如果一个图片里只有一个目标，那么 <code>result</code> 类别索引对应的元素中，只有一组数据。</li><li>如果一个图片里有多个目标，那么 <code>result</code> 类别索引对应的元素中，就有多组数据。</li></ul><p>因为我的服务器没有 GUI，而官方画图程序需要调用 matplotlib 和 tkiner，所以无法显示图片，只能读取结果信息，自己用 PIL 画一下了。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw</span><br><span class="line"><span class="comment"># 打开原图</span></span><br><span class="line">img = Image.open(<span class="string">'Hippopx.jpg'</span>).convert(<span class="string">'RGB'</span>)</span><br><span class="line"><span class="comment"># 画出目标框，因为一个类别可能对应多个目标</span></span><br><span class="line"><span class="keyword">for</span> rec <span class="keyword">in</span> result[<span class="number">0</span>]:</span><br><span class="line">    x, y, w, h = rec[<span class="number">0</span>], rec[<span class="number">1</span>], rec[<span class="number">2</span>], rec[<span class="number">3</span>]</span><br><span class="line">    draw = ImageDraw.Draw(img)</span><br><span class="line">    draw.rectangle((x, y, w, h), width=<span class="number">2</span>, outline=<span class="string">'#41fc59'</span>)</span><br><span class="line"><span class="comment"># 保存结果图片</span></span><br><span class="line">img.save(<span class="string">'result.png'</span>)</span><br></pre></td></tr></table></figure><p>一个类对应一个目标：<img data-src="https://z3.ax1x.com/2021/05/13/gBksu8.jpg" alt> 一个类有多个目标：<img data-src="https://z3.ax1x.com/2021/05/13/gBAUqU.jpg" alt></p><h1 id="自定义推理"><a href="#自定义推理" class="headerlink" title="自定义推理"></a>自定义推理</h1><h2 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h2><p>将数据的软链接挂到 <code>mmdetection</code> 文件夹下，目录结构如下。 <code>ln -s minidata /mmdetection/data/</code>，创建软链时需要注意，使用绝对路径。因为之后会沿着软链访问数据，相对路径可能找不到数据。此时的目录结构如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mmdetection</span><br><span class="line">├── mmdet</span><br><span class="line">├── tools</span><br><span class="line">├── configs</span><br><span class="line">├── data</span><br><span class="line">│   ├── minidata</span><br><span class="line">│   │   ├── annotations/</span><br><span class="line">│   │   ├── test_data/</span><br></pre></td></tr></table></figure><p><code>annotations</code> 是对图片信息的说明，<code>test_data</code> 就是要推理的图片。其实这里的结构也不太重要，重点是后面的配置文件要把路径给指对了。而后下载预训练的模型，对目标数据集进行推理。模型都可以在官方文档的 <code>Model Zoo</code> 中下载到。</p><h3 id="修改配置文件-不建议"><a href="#修改配置文件-不建议" class="headerlink" title="修改配置文件(不建议)"></a>修改配置文件(不建议)</h3><p>因为源代码中指定的配置文件是 <code>configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py</code>，而打开这个文件，我们会发现以下几行信息：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">_base_ = [</span><br><span class="line">    <span class="string">'../_base_/models/faster_rcnn_r50_fpn.py'</span>,</span><br><span class="line">    <span class="string">'../_base_/datasets/coco_detection.py'</span>,</span><br><span class="line">    <span class="string">'../_base_/schedules/schedule_1x.py'</span>, <span class="string">'../_base_/default_runtime.py'</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>也就是，配置文件是继承自 <code>_base_</code> 文件夹下面的模型、数据、学习率、运行时设置这四个文件。所以要按照自己想要的方式运行，就需要修改这四个配置文件。</p><p>比如以数据为例，因为目标数据集位于 <code>data/mini_data</code> 下，所以要修改配置文件，使配置文件找到正确的数据路径。打开 <code>configs/_base_/datasets/coco_detection.py</code>，修改 <code>data</code> 字典中的 <code>test</code>。<strong>类别数量修改同理，在models文件夹下。</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">test=dict(</span><br><span class="line">    type=dataset_type,</span><br><span class="line">    <span class="comment"># 找到自己的 json</span></span><br><span class="line">    ann_file=data_root + <span class="string">'annotations/openbrand_train.json'</span>,</span><br><span class="line">    <span class="comment"># 找到自己的图片路径</span></span><br><span class="line">    img_prefix=data_root + <span class="string">'test_data/'</span>,</span><br><span class="line">    pipeline=test_pipeline)</span><br></pre></td></tr></table></figure><ul><li>而后在 <code>mmdetection/mmdet/core/evaluation/classes_names</code> 中的 <code>coco_classes</code> 函数中修改类别名称信息。（这个我没找到如何在配置文件中修改，只能在源文件中修改了）</li><li>也在<code>mmdetection/mmdet/datasets/coco.py</code> 中的 <code>class CocoDataset(CustomDataset):</code> 类中的 <code>CLASSES</code> 字段修改为自己需要的类别信息。</li></ul><h2 id="开始推理"><a href="#开始推理" class="headerlink" title="开始推理"></a>开始推理</h2><p>而最后执行推理的代码如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python tools/test.py \</span><br><span class="line">    <span class="variable">$&#123;CONFIG_FILE&#125;</span> \</span><br><span class="line">    <span class="variable">$&#123;CHECKPOINT_FILE&#125;</span> \</span><br><span class="line">    [--out <span class="variable">$&#123;RESULT_FILE&#125;</span>] \</span><br><span class="line">    [--<span class="built_in">eval</span> <span class="variable">$&#123;EVAL_METRICS&#125;</span>] \</span><br></pre></td></tr></table></figure><ul><li><code>RESULT_FILE</code> 结果序列化输出到指定文件中，必须是 <code>.pkl</code> 文件</li><li><code>EVAL_METRICS</code> 结果要评估的项目，结果会打印到屏幕，对于 COCO 数据接而言，有 <code>proposal, bbox, segm</code> 等。但是需要注意的是，faster rcnn 没有 segm，mask rcnn 才有。</li></ul><p>比如：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># mmdetection 文件夹下执行</span></span><br><span class="line">python tools/test.py \</span><br><span class="line">    <span class="comment"># 配置文件</span></span><br><span class="line">    configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py \</span><br><span class="line">    <span class="comment"># 模型</span></span><br><span class="line">    checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth \</span><br><span class="line">    <span class="comment"># 输出</span></span><br><span class="line">    --out /mmnet/out.pkl \</span><br><span class="line">    --<span class="built_in">eval</span> bbox proposal \</span><br><span class="line">    --show-score-thr 0.5 <span class="comment"># 概率低于 0.5 的预测结果都要被删除</span></span><br></pre></td></tr></table></figure><p>打开 <code>test.py</code>，一步步追踪源码，发现推理时调用的东西和 <code>inference_detector</code> 接口调用的一样，所以推理阶段不输出类别，类别需要自己从 <code>model.CLASSES</code> 中获取。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    result = model(return_loss=<span class="literal">False</span>, rescale=<span class="literal">True</span>, **data)</span><br></pre></td></tr></table></figure><p>因为最后输出的结果保存到了 <code>out.pkl</code> 文件中，所以给一份精简代码，关于如何读取序列化数据。<del>其实跟 json 的读取挺像的。</del></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line">data = <span class="literal">None</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'out.pkl'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data = pickle.load(f)</span><br><span class="line">process(data)</span><br></pre></td></tr></table></figure><p>推理结束后可以删除数据的软链，以备下次使用。删除软件时需要注意，可能一不小心删除原始数据。正确的删除软链方式是 <code>rm minidata</code>，注意不要加斜杠。</p><p>理论上应该是按着上面描述的那样执行，但其实我这里报错了：<code>KeyError: &quot;CocoDataset: &#39;categories&#39;&quot;</code>。定位到报错代码，发现是因为使用 <code>pycocotools</code> 读取 json 文件时，没有读到分类这个属性。<strong>所以这里需要注意的是，推理要用的 json，自己要添加一下类别的信息。</strong></p><h2 id="通过配置文件推理"><a href="#通过配置文件推理" class="headerlink" title="通过配置文件推理"></a>通过配置文件推理</h2><p>当我本能的以为又要修改源代码时，我意识到一个问题。以任何学过『设计模式』而言的人来说，初衷绝对不是让用户去修改源代码，每次修改来修改去，程序到最后可能都没法用了。而是应该通过添加额外配置文件，来达到用户想要的目的。<strong>对修改封闭，对扩展开放。</strong>所以以上修改我又还原了，决定自己写脚本进行推理。</p><h3 id="自定义脚本推理"><a href="#自定义脚本推理" class="headerlink" title="自定义脚本推理"></a>自定义脚本推理</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> mmdet.apis <span class="keyword">import</span> init_detector, inference_detector</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> pycocotools.coco <span class="keyword">import</span> COCO</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提交要求</span></span><br><span class="line"><span class="comment"># [&#123;</span></span><br><span class="line"><span class="comment">#     "image_id": int,</span></span><br><span class="line"><span class="comment">#     "category_id": int,</span></span><br><span class="line"><span class="comment">#     "bbox": [x_min,y_min,width,height],</span></span><br><span class="line"><span class="comment">#     "score": float,</span></span><br><span class="line"><span class="comment"># &#125;]</span></span><br><span class="line"></span><br><span class="line">anno_path = <span class="string">'test.json'</span></span><br><span class="line">coco = COCO(anno_path)</span><br><span class="line">ids = list(coco.imgs.keys())</span><br><span class="line"></span><br><span class="line">filename_id = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取文件名与对应的 ID</span></span><br><span class="line"><span class="comment"># 如 &#123;'000000.jpg': 12&#125;</span></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> tqdm(range(len(ids))):</span><br><span class="line">    img_id = ids[idx]</span><br><span class="line">    img_ids = coco.getImgIds(imgIds=img_id)</span><br><span class="line">    image = coco.loadImgs(img_ids)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> image:</span><br><span class="line">        filename_id[i[<span class="string">'file_name'</span>]] = i[<span class="string">'id'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 目标检测配置文件</span></span><br><span class="line">config_file = <span class="string">'mmnet/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'</span></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">checkpoint_file = <span class="string">'mmnet/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x.pth'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置模型</span></span><br><span class="line">model = init_detector(config=config_file,</span><br><span class="line">                      checkpoint=checkpoint_file,</span><br><span class="line">                      device=<span class="string">'cuda:0'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 需要推理的图片的路径</span></span><br><span class="line">root = <span class="string">'val_data/'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 存储结果，并生成 json</span></span><br><span class="line">results = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始推理</span></span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> tqdm(os.listdir(root)):</span><br><span class="line">    result = inference_detector(model=model, imgs=root + file)</span><br><span class="line">    <span class="keyword">for</span> cate, items <span class="keyword">in</span> enumerate(result, <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 同一类别的有很多结果</span></span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">            item = item.tolist()</span><br><span class="line">            x, y, w, h, s = item[<span class="number">0</span>], item[<span class="number">1</span>], item[<span class="number">2</span>], item[<span class="number">3</span>], item[<span class="number">4</span>]</span><br><span class="line">            d = &#123;&#125;</span><br><span class="line">            d[<span class="string">'image_id'</span>] = filename_id[file]</span><br><span class="line">            d[<span class="string">'category_id'</span>] = cate</span><br><span class="line">            d[<span class="string">'bbox'</span>] = [x, y, w, h]</span><br><span class="line">            d[<span class="string">'score'</span>] = s</span><br><span class="line">            results.append(d)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'result.json'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    json.dump(results, f, indent=<span class="number">4</span>)</span><br></pre></td></tr></table></figure><h3 id="配置文件推理"><a href="#配置文件推理" class="headerlink" title="配置文件推理"></a>配置文件推理</h3><p>之前说过，配置文件继承自以下四个文件：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">_base_ = [</span><br><span class="line">    <span class="string">'../_base_/models/faster_rcnn_r50_fpn.py'</span>,</span><br><span class="line">    <span class="string">'../_base_/datasets/coco_detection.py'</span>,</span><br><span class="line">    <span class="string">'../_base_/schedules/schedule_1x.py'</span>, <span class="string">'../_base_/default_runtime.py'</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>所以我们自己定义一个配置文件，称为 <code>mynet.py</code>，位于 <code>mmdetection/configs/faster_rcnn/</code> 文件夹下，把以上四个文件的内容全部拷贝到 <code>mynet.py</code> 中，并修改自己需要改的地方即可。<code>mynet.py</code> 文件如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line">_base_ = [</span><br><span class="line">    <span class="string">'../_base_/models/faster_rcnn_r50_fpn.py'</span>,</span><br><span class="line">    <span class="string">'../_base_/datasets/coco_detection.py'</span>,</span><br><span class="line">    <span class="string">'../_base_/schedules/schedule_1x.py'</span>, <span class="string">'../_base_/default_runtime.py'</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># model settings</span></span><br><span class="line">model = dict(</span><br><span class="line">    type=<span class="string">'FasterRCNN'</span>,</span><br><span class="line">    pretrained=<span class="string">'torchvision://resnet50'</span>,</span><br><span class="line">    backbone=dict(</span><br><span class="line">        type=<span class="string">'ResNet'</span>,</span><br><span class="line">        depth=<span class="number">50</span>,</span><br><span class="line">        num_stages=<span class="number">4</span>,</span><br><span class="line">        out_indices=(<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>),</span><br><span class="line">        frozen_stages=<span class="number">1</span>,</span><br><span class="line">        norm_cfg=dict(type=<span class="string">'BN'</span>, requires_grad=<span class="literal">True</span>),</span><br><span class="line">        norm_eval=<span class="literal">True</span>,</span><br><span class="line">        style=<span class="string">'pytorch'</span>),</span><br><span class="line">    neck=dict(</span><br><span class="line">        type=<span class="string">'FPN'</span>,</span><br><span class="line">        in_channels=[<span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>],</span><br><span class="line">        out_channels=<span class="number">256</span>,</span><br><span class="line">        num_outs=<span class="number">5</span>),</span><br><span class="line">    rpn_head=dict(</span><br><span class="line">        type=<span class="string">'RPNHead'</span>,</span><br><span class="line">        in_channels=<span class="number">256</span>,</span><br><span class="line">        feat_channels=<span class="number">256</span>,</span><br><span class="line">        anchor_generator=dict(</span><br><span class="line">            type=<span class="string">'AnchorGenerator'</span>,</span><br><span class="line">            scales=[<span class="number">8</span>],</span><br><span class="line">            ratios=[<span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>],</span><br><span class="line">            strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>, <span class="number">64</span>]),</span><br><span class="line">        bbox_coder=dict(</span><br><span class="line">            type=<span class="string">'DeltaXYWHBBoxCoder'</span>,</span><br><span class="line">            target_means=[<span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>, <span class="number">.0</span>],</span><br><span class="line">            target_stds=[<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>]),</span><br><span class="line">        loss_cls=dict(</span><br><span class="line">            type=<span class="string">'CrossEntropyLoss'</span>, use_sigmoid=<span class="literal">True</span>, loss_weight=<span class="number">1.0</span>),</span><br><span class="line">        loss_bbox=dict(type=<span class="string">'L1Loss'</span>, loss_weight=<span class="number">1.0</span>)),</span><br><span class="line">    roi_head=dict(</span><br><span class="line">        type=<span class="string">'StandardRoIHead'</span>,</span><br><span class="line">        bbox_roi_extractor=dict(</span><br><span class="line">            type=<span class="string">'SingleRoIExtractor'</span>,</span><br><span class="line">            roi_layer=dict(type=<span class="string">'RoIAlign'</span>, output_size=<span class="number">7</span>, sampling_ratio=<span class="number">0</span>),</span><br><span class="line">            out_channels=<span class="number">256</span>,</span><br><span class="line">            featmap_strides=[<span class="number">4</span>, <span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>]),</span><br><span class="line">        bbox_head=dict(</span><br><span class="line">            type=<span class="string">'Shared2FCBBoxHead'</span>,</span><br><span class="line">            in_channels=<span class="number">256</span>,</span><br><span class="line">            fc_out_channels=<span class="number">1024</span>,</span><br><span class="line">            roi_feat_size=<span class="number">7</span>,</span><br><span class="line">            <span class="comment"># 修改类别</span></span><br><span class="line">            num_classes=<span class="number">515</span>,</span><br><span class="line">            bbox_coder=dict(</span><br><span class="line">                type=<span class="string">'DeltaXYWHBBoxCoder'</span>,</span><br><span class="line">                target_means=[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">                target_stds=[<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span>]),</span><br><span class="line">            reg_class_agnostic=<span class="literal">False</span>,</span><br><span class="line">            loss_cls=dict(</span><br><span class="line">                type=<span class="string">'CrossEntropyLoss'</span>, use_sigmoid=<span class="literal">False</span>, loss_weight=<span class="number">1.0</span>),</span><br><span class="line">            loss_bbox=dict(type=<span class="string">'L1Loss'</span>, loss_weight=<span class="number">1.0</span>))),</span><br><span class="line">    <span class="comment"># model training and testing settings</span></span><br><span class="line">    train_cfg=dict(</span><br><span class="line">        rpn=dict(</span><br><span class="line">            assigner=dict(</span><br><span class="line">                type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">                pos_iou_thr=<span class="number">0.7</span>,</span><br><span class="line">                neg_iou_thr=<span class="number">0.3</span>,</span><br><span class="line">                min_pos_iou=<span class="number">0.3</span>,</span><br><span class="line">                match_low_quality=<span class="literal">True</span>,</span><br><span class="line">                ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">            sampler=dict(</span><br><span class="line">                type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">                num=<span class="number">256</span>,</span><br><span class="line">                pos_fraction=<span class="number">0.5</span>,</span><br><span class="line">                neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">                add_gt_as_proposals=<span class="literal">False</span>),</span><br><span class="line">            allowed_border=<span class="number">-1</span>,</span><br><span class="line">            pos_weight=<span class="number">-1</span>,</span><br><span class="line">            debug=<span class="literal">False</span>),</span><br><span class="line">        rpn_proposal=dict(</span><br><span class="line">            nms_pre=<span class="number">2000</span>,</span><br><span class="line">            max_per_img=<span class="number">1000</span>,</span><br><span class="line">            nms=dict(type=<span class="string">'nms'</span>, iou_threshold=<span class="number">0.7</span>),</span><br><span class="line">            min_bbox_size=<span class="number">0</span>),</span><br><span class="line">        rcnn=dict(</span><br><span class="line">            assigner=dict(</span><br><span class="line">                type=<span class="string">'MaxIoUAssigner'</span>,</span><br><span class="line">                pos_iou_thr=<span class="number">0.5</span>,</span><br><span class="line">                neg_iou_thr=<span class="number">0.5</span>,</span><br><span class="line">                min_pos_iou=<span class="number">0.5</span>,</span><br><span class="line">                match_low_quality=<span class="literal">False</span>,</span><br><span class="line">                ignore_iof_thr=<span class="number">-1</span>),</span><br><span class="line">            sampler=dict(</span><br><span class="line">                type=<span class="string">'RandomSampler'</span>,</span><br><span class="line">                num=<span class="number">512</span>,</span><br><span class="line">                pos_fraction=<span class="number">0.25</span>,</span><br><span class="line">                neg_pos_ub=<span class="number">-1</span>,</span><br><span class="line">                add_gt_as_proposals=<span class="literal">True</span>),</span><br><span class="line">            pos_weight=<span class="number">-1</span>,</span><br><span class="line">            debug=<span class="literal">False</span>)),</span><br><span class="line">    test_cfg=dict(</span><br><span class="line">        rpn=dict(</span><br><span class="line">            nms_pre=<span class="number">1000</span>,</span><br><span class="line">            max_per_img=<span class="number">1000</span>,</span><br><span class="line">            nms=dict(type=<span class="string">'nms'</span>, iou_threshold=<span class="number">0.7</span>),</span><br><span class="line">            min_bbox_size=<span class="number">0</span>),</span><br><span class="line">        rcnn=dict(</span><br><span class="line">            score_thr=<span class="number">0.05</span>,</span><br><span class="line">            nms=dict(type=<span class="string">'nms'</span>, iou_threshold=<span class="number">0.3</span>),</span><br><span class="line">            max_per_img=<span class="number">100</span>)</span><br><span class="line">        <span class="comment"># soft-nms is also supported for rcnn testing</span></span><br><span class="line">        <span class="comment"># e.g., nms=dict(type='soft_nms', iou_threshold=0.5, min_score=0.05)</span></span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset settings</span></span><br><span class="line">dataset_type = <span class="string">'CocoDataset'</span></span><br><span class="line">data_root = <span class="string">'mmnet/mmdetection/data/ljw/'</span></span><br><span class="line">img_norm_cfg = dict(</span><br><span class="line">    mean=[<span class="number">123.675</span>, <span class="number">116.28</span>, <span class="number">103.53</span>], std=[<span class="number">58.395</span>, <span class="number">57.12</span>, <span class="number">57.375</span>], to_rgb=<span class="literal">True</span>)</span><br><span class="line">train_pipeline = [</span><br><span class="line">    dict(type=<span class="string">'LoadImageFromFile'</span>),</span><br><span class="line">    dict(type=<span class="string">'LoadAnnotations'</span>, with_bbox=<span class="literal">True</span>),</span><br><span class="line">    dict(type=<span class="string">'Resize'</span>, img_scale=(<span class="number">1333</span>, <span class="number">800</span>), keep_ratio=<span class="literal">True</span>),</span><br><span class="line">    dict(type=<span class="string">'RandomFlip'</span>, flip_ratio=<span class="number">0.5</span>),</span><br><span class="line">    dict(type=<span class="string">'Normalize'</span>, **img_norm_cfg),</span><br><span class="line">    dict(type=<span class="string">'Pad'</span>, size_divisor=<span class="number">32</span>),</span><br><span class="line">    dict(type=<span class="string">'DefaultFormatBundle'</span>),</span><br><span class="line">    dict(type=<span class="string">'Collect'</span>, keys=[<span class="string">'img'</span>, <span class="string">'gt_bboxes'</span>, <span class="string">'gt_labels'</span>]),</span><br><span class="line">]</span><br><span class="line">test_pipeline = [</span><br><span class="line">    dict(type=<span class="string">'LoadImageFromFile'</span>),</span><br><span class="line">    dict(</span><br><span class="line">        type=<span class="string">'MultiScaleFlipAug'</span>,</span><br><span class="line">        img_scale=(<span class="number">1333</span>, <span class="number">800</span>),</span><br><span class="line">        flip=<span class="literal">False</span>,</span><br><span class="line">        transforms=[</span><br><span class="line">            dict(type=<span class="string">'Resize'</span>, keep_ratio=<span class="literal">True</span>),</span><br><span class="line">            dict(type=<span class="string">'RandomFlip'</span>),</span><br><span class="line">            dict(type=<span class="string">'Normalize'</span>, **img_norm_cfg),</span><br><span class="line">            dict(type=<span class="string">'Pad'</span>, size_divisor=<span class="number">32</span>),</span><br><span class="line">            dict(type=<span class="string">'ImageToTensor'</span>, keys=[<span class="string">'img'</span>]),</span><br><span class="line">            dict(type=<span class="string">'Collect'</span>, keys=[<span class="string">'img'</span>]),</span><br><span class="line">        ])</span><br><span class="line">]</span><br><span class="line">data = dict(</span><br><span class="line">    samples_per_gpu=<span class="number">2</span>,</span><br><span class="line">    workers_per_gpu=<span class="number">2</span>,</span><br><span class="line">    train=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_train2017.json'</span>,</span><br><span class="line">        img_prefix=data_root + <span class="string">'train2017/'</span>,</span><br><span class="line">        pipeline=train_pipeline),</span><br><span class="line">    val=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'annotations/instances_val2017.json'</span>,</span><br><span class="line">        img_prefix=data_root + <span class="string">'val2017/'</span>,</span><br><span class="line">        pipeline=test_pipeline),</span><br><span class="line">    test=dict(</span><br><span class="line">        type=dataset_type,</span><br><span class="line">        ann_file=data_root + <span class="string">'test.json'</span>,</span><br><span class="line">        img_prefix=data_root + <span class="string">'val_data/'</span>,</span><br><span class="line">        pipeline=test_pipeline))</span><br><span class="line">evaluation = dict(interval=<span class="number">1</span>, metric=<span class="string">'bbox'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># optimizer</span></span><br><span class="line">optimizer = dict(type=<span class="string">'SGD'</span>, lr=<span class="number">0.02</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">0.0001</span>)</span><br><span class="line">optimizer_config = dict(grad_clip=<span class="literal">None</span>)</span><br><span class="line"><span class="comment"># learning policy</span></span><br><span class="line">lr_config = dict(</span><br><span class="line">    policy=<span class="string">'step'</span>,</span><br><span class="line">    warmup=<span class="string">'linear'</span>,</span><br><span class="line">    warmup_iters=<span class="number">500</span>,</span><br><span class="line">    warmup_ratio=<span class="number">0.001</span>,</span><br><span class="line">    step=[<span class="number">8</span>, <span class="number">11</span>])</span><br><span class="line">runner = dict(type=<span class="string">'EpochBasedRunner'</span>, max_epochs=<span class="number">12</span>)</span><br></pre></td></tr></table></figure><p>最终，<code>python tools/test.py configs/faster_rcnn/mynet.py ......</code> 就可以运行自己的配置文件，完成推理。尽量避免了破坏原有的代码结构。如果想加速执行，就需要多显卡，而 <code>mmdetection</code> 对这方面支持的很好：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bash tools/dist_test.sh \</span><br><span class="line">    configs/faster_rcnn/my_faster_rcnn.py \</span><br><span class="line">    checkpoints/faster_rcnn_r50_fpn_1x.pth \</span><br><span class="line">    <span class="comment"># 4 个 GPU</span></span><br><span class="line">    <span class="number">4</span> \</span><br><span class="line">    --format-only \</span><br><span class="line">    <span class="comment"># 输出推理得到的 json 文件</span></span><br><span class="line">    --options <span class="string">"jsonfile_prefix=results6"</span></span><br></pre></td></tr></table></figure><h1 id="推理程序"><a href="#推理程序" class="headerlink" title="推理程序"></a>推理程序</h1><p>然后，我把一些简单的程序传到 <code>colab</code> 了，可以<a href="https://github.com/muyuuuu/open-mmlab-colab" target="_blank" rel="noopener">打开</a>去实际执行一下，虽然也有一些分类的任务，但思想是一样的。</p><h1 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h1><h2 id="Finetune"><a href="#Finetune" class="headerlink" title="Finetune"></a>Finetune</h2><p>这个恐怕是最简单但也是最常用的一种方案，和前文一样，也是基于配置文件、命令行启动的方式进行训练。修改类别同前文。同样以 Faster RCNN 为例，先写好自己的配置文件，执行方式为：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python tools/train.py \</span><br><span class="line">    $&#123;CONFIG_FILE&#125; \</span><br><span class="line">    [optional arguments]</span><br></pre></td></tr></table></figure><p>optional arguments 是可选参数，这里需要加上模型的 log 输出文件目录和预加载模型的地址：</p><ul><li><code>--work-dir work_dirs/</code>，将日志、模型输出到 <code>work_dirs</code> 文件夹下</li><li><code>--load-from model.pth</code>，只加载模型参数，从第 0 个 epoch 开始训练，但是我试了一下，这个参数不太行</li><li><code>--resume-from model.pth</code>，加载模型参数与优化器状态，继承上次的 epoch，通常用于恢复意外中断的训练过程</li></ul><p>当然如果想在多个 GPU 上训练也是可以的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bash ./tools/dist_train.sh \</span><br><span class="line">    <span class="variable">$&#123;CONFIG_FILE&#125;</span> \</span><br><span class="line">    <span class="variable">$&#123;GPU_NUM&#125;</span> \</span><br><span class="line">    [optional arguments]</span><br></pre></td></tr></table></figure><h2 id="配置文件训练"><a href="#配置文件训练" class="headerlink" title="配置文件训练"></a>配置文件训练</h2><p>官方文档给出了两种修改配置的方案 <sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup>：</p><ul><li>一种是通过 <code>python tools/train.py</code> 时添加 <code>--cfg-options</code> 参数，例如 <code>--cfg-options model.backbone.norm_eval=False</code> 会将模型的 BN 层调为运行时 <sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup> 状态。但是这样参数会很多，且很容易出错，个人不建议这么修改。</li><li>第二种方案就是自定义配置文件，并继承 <code>_base_</code>，具体操作可以见上文。模型、数据、学习率等都可以轻松设置。官网也给出了 Mask RCNN 的具体配置文件与解释 <sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup>。因为官方支持可以只在配置文件中写入修改部分，不修改的部分可以不必声明。而在子文件中修改配置文件时，如果重新定义了自己的变量，一定记得传入，否则默认还是原来的配置。如下：</li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新的修改</span></span><br><span class="line">test_pipeline = [</span><br><span class="line">    dict(type=<span class="string">'LoadImageFromFile'</span>),</span><br><span class="line">    dict(</span><br><span class="line">        type=<span class="string">'MultiScaleFlipAug'</span>,</span><br><span class="line">        img_scale=(<span class="number">1333</span>, <span class="number">800</span>),</span><br><span class="line">        flip=<span class="literal">False</span>,</span><br><span class="line">        transforms=[</span><br><span class="line">            dict(type=<span class="string">'Resize'</span>, keep_ratio=<span class="literal">True</span>),</span><br><span class="line">            dict(type=<span class="string">'RandomFlip'</span>),</span><br><span class="line">            dict(type=<span class="string">'Normalize'</span>, **img_norm_cfg),</span><br><span class="line">            dict(type=<span class="string">'Pad'</span>, size_divisor=<span class="number">32</span>),</span><br><span class="line">            dict(type=<span class="string">'ImageToTensor'</span>, keys=[<span class="string">'img'</span>]),</span><br><span class="line">            dict(type=<span class="string">'Collect'</span>, keys=[<span class="string">'img'</span>]),</span><br><span class="line">        ])</span><br><span class="line">]</span><br><span class="line"><span class="comment"># 传入自己的修改，其它不用写，用默认的</span></span><br><span class="line">data = dict(</span><br><span class="line">    test=dict(pipeline=test_pipeline))</span><br></pre></td></tr></table></figure><h1 id="数据处理流程"><a href="#数据处理流程" class="headerlink" title="数据处理流程"></a>数据处理流程</h1><p>这个在程序中的字段是 <code>pipeline</code>，也就是数据处理的一个管道。来看默认配置文件中的内容：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">img_norm_cfg = dict(</span><br><span class="line">    mean=[<span class="number">123.675</span>, <span class="number">116.28</span>, <span class="number">103.53</span>], std=[<span class="number">58.395</span>, <span class="number">57.12</span>, <span class="number">57.375</span>], to_rgb=<span class="literal">True</span>)</span><br><span class="line">train_pipeline = [</span><br><span class="line">    <span class="comment"># 从文件加载图片</span></span><br><span class="line">    dict(type=<span class="string">'LoadImageFromFile'</span>),</span><br><span class="line">    <span class="comment"># 加载 boxes，boxes_ignore，label 等信息</span></span><br><span class="line">    dict(type=<span class="string">'LoadAnnotations'</span>, with_bbox=<span class="literal">True</span>),</span><br><span class="line">    <span class="comment"># 重新定义图像大小、bbox 等区域的大小也会变换</span></span><br><span class="line">    dict(type=<span class="string">'Resize'</span>, img_scale=(<span class="number">1333</span>, <span class="number">800</span>), keep_ratio=<span class="literal">True</span>),</span><br><span class="line">    <span class="comment"># 随机翻转，bbox 等内容也会变化</span></span><br><span class="line">    dict(type=<span class="string">'RandomFlip'</span>, flip_ratio=<span class="number">0.5</span>),</span><br><span class="line">    <span class="comment"># 数据标准化</span></span><br><span class="line">    dict(type=<span class="string">'Normalize'</span>, **img_norm_cfg),</span><br><span class="line">    <span class="comment"># https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/pipelines/transforms.py</span></span><br><span class="line">    <span class="comment"># https://mmcv.readthedocs.io/en/latest/api.html</span></span><br><span class="line">    <span class="comment"># 填充除数，追踪源代码到 mmcv，意思是，填充后的图像边，是 32 的倍数</span></span><br><span class="line">    dict(type=<span class="string">'Pad'</span>, size_divisor=<span class="number">32</span>),</span><br><span class="line">    <span class="comment"># https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/pipelines/formating.py</span></span><br><span class="line">    <span class="comment"># 开始批处理。对于图片，处理、转为向量、收集到 batchsize。bbox，label 同理</span></span><br><span class="line">    dict(type=<span class="string">'DefaultFormatBundle'</span>),</span><br><span class="line">    dict(type=<span class="string">'Collect'</span>, keys=[<span class="string">'img'</span>, <span class="string">'gt_bboxes'</span>, <span class="string">'gt_labels'</span>]),</span><br><span class="line">]</span><br><span class="line">test_pipeline = [</span><br><span class="line">    dict(type=<span class="string">'LoadImageFromFile'</span>),</span><br><span class="line">    dict(</span><br><span class="line">        type=<span class="string">'MultiScaleFlipAug'</span>,</span><br><span class="line">        img_scale=(<span class="number">1333</span>, <span class="number">800</span>),</span><br><span class="line">        <span class="comment"># 禁止翻转</span></span><br><span class="line">        flip=<span class="literal">False</span>,</span><br><span class="line">        transforms=[</span><br><span class="line">            dict(type=<span class="string">'Resize'</span>, keep_ratio=<span class="literal">True</span>),</span><br><span class="line">            dict(type=<span class="string">'RandomFlip'</span>),</span><br><span class="line">            dict(type=<span class="string">'Normalize'</span>, **img_norm_cfg),</span><br><span class="line">            dict(type=<span class="string">'Pad'</span>, size_divisor=<span class="number">32</span>),</span><br><span class="line">            dict(type=<span class="string">'ImageToTensor'</span>, keys=[<span class="string">'img'</span>]),</span><br><span class="line">            dict(type=<span class="string">'Collect'</span>, keys=[<span class="string">'img'</span>]),</span><br><span class="line">        ])</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>而如果想扩展自己的数据处理流程 <sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup> ，先自己定义一个数据处理的类，然后导入进来，加入到 <code>train_pipeline</code> 即可。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> mmdet.datasets <span class="keyword">import</span> PIPELINES</span><br><span class="line"></span><br><span class="line"><span class="meta">@PIPELINES.register_module()</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyTransform</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, results)</span>:</span></span><br><span class="line">        results[<span class="string">'dummy'</span>] = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> .my_pipeline <span class="keyword">import</span> MyTransform</span><br><span class="line"></span><br><span class="line">train_pipeline = [</span><br><span class="line">    dict(type=<span class="string">'LoadImageFromFile'</span>),</span><br><span class="line">    dict(type=<span class="string">'LoadAnnotations'</span>, with_bbox=<span class="literal">True</span>),</span><br><span class="line">    dict(type=<span class="string">'Resize'</span>, img_scale=(<span class="number">1333</span>, <span class="number">800</span>), keep_ratio=<span class="literal">True</span>),</span><br><span class="line">    dict(type=<span class="string">'RandomFlip'</span>, flip_ratio=<span class="number">0.5</span>),</span><br><span class="line">    dict(type=<span class="string">'Normalize'</span>, **img_norm_cfg),</span><br><span class="line">    dict(type=<span class="string">'Pad'</span>, size_divisor=<span class="number">32</span>),</span><br><span class="line">    <span class="comment"># 添加自己的</span></span><br><span class="line">    dict(type=<span class="string">'MyTransform'</span>),</span><br><span class="line">    dict(type=<span class="string">'DefaultFormatBundle'</span>),</span><br><span class="line">    dict(type=<span class="string">'Collect'</span>, keys=[<span class="string">'img'</span>, <span class="string">'gt_bboxes'</span>, <span class="string">'gt_labels'</span>]),</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>而至于自定义模型的 backbone，neck，head <sup id="fnref:11"><a href="#fn:11" rel="footnote">11</a></sup> 、学习率和优化方案 <sup id="fnref:12"><a href="#fn:12" rel="footnote">12</a></sup>、自定义损失函数 <sup id="fnref:13"><a href="#fn:13" rel="footnote">13</a></sup> 等，官网也给出了详细的解决方案。</p><h1 id="references"><a href="#references" class="headerlink" title="references"></a>references</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;"><a href="https://github.com/open-mmlab/mmdetection/blob/master/README_zh-CN.md" target="_blank" rel="noopener">MMDetection 介绍</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;"><a href="https://github.com/open-mmlab/mmcv#install-with-pip" target="_blank" rel="noopener">mmcv-full 安装文档</a></span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;"><a href="https://mmdetection.readthedocs.io/en/latest/get_started.html#installation" target="_blank" rel="noopener">mmdetection 安装文档</a></span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">4.</span><span style="display: inline-block; vertical-align: top;"><a href="https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.apis.init_detector" target="_blank" rel="noopener">mmdetection 官方文档</a></span><a href="#fnref:4" rev="footnote"> ↩</a></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">5.</span><span style="display: inline-block; vertical-align: top;"><a href="https://github.com/open-mmlab/mmdetection/issues/3755" target="_blank" rel="noopener">inference_detector 无法输出每个盒子的所属类别</a></span><a href="#fnref:5" rev="footnote"> ↩</a></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">6.</span><span style="display: inline-block; vertical-align: top;"><a href="https://github.com/open-mmlab/mmdetection/issues/3755#issuecomment-840228347" target="_blank" rel="noopener">inference_detector 获取类别</a></span><a href="#fnref:6" rev="footnote"> ↩</a></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">7.</span><span style="display: inline-block; vertical-align: top;"><a href="https://mmdetection.readthedocs.io/en/latest/tutorials/config.html" target="_blank" rel="noopener">MMdetection 配置文件修改</a></span><a href="#fnref:7" rev="footnote"> ↩</a></li><li id="fn:8"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">8.</span><span style="display: inline-block; vertical-align: top;"><a href="https://muyuuuu.github.io/2021/05/07/DNN-data-normal/">BN 层在运行时状态</a></span><a href="#fnref:8" rev="footnote"> ↩</a></li><li id="fn:9"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">9.</span><span style="display: inline-block; vertical-align: top;"><a href="https://mmdetection.readthedocs.io/en/latest/tutorials/config.html" target="_blank" rel="noopener">Mask RCNN 配置文件说明</a></span><a href="#fnref:9" rev="footnote"> ↩</a></li><li id="fn:10"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">10.</span><span style="display: inline-block; vertical-align: top;"><a href="https://mmdetection.readthedocs.io/en/latest/tutorials/data_pipeline.html" target="_blank" rel="noopener">扩展数据处理流程</a></span><a href="#fnref:10" rev="footnote"> ↩</a></li><li id="fn:11"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">11.</span><span style="display: inline-block; vertical-align: top;"><a href="https://mmdetection.readthedocs.io/en/latest/tutorials/customize_models.html" target="_blank" rel="noopener">自定义模型</a></span><a href="#fnref:11" rev="footnote"> ↩</a></li><li id="fn:12"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">12.</span><span style="display: inline-block; vertical-align: top;"><a href="https://mmdetection.readthedocs.io/en/latest/tutorials/customize_runtime.html" target="_blank" rel="noopener">自定义学习率和优化方案</a></span><a href="#fnref:12" rev="footnote"> ↩</a></li><li id="fn:13"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">13.</span><span style="display: inline-block; vertical-align: top;"><a href="https://mmdetection.readthedocs.io/en/latest/tutorials/customize_losses.html" target="_blank" rel="noopener">自定义损失函数</a></span><a href="#fnref:13" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近喜欢上了听音乐，B 站关注了个 UP 主叫『&lt;strong&gt;咻咻满&lt;/strong&gt;』，长得好看，戏腔唱『&lt;strong&gt;青花瓷&lt;/strong&gt;』入坑了，也听了其它的『星辰大海』和『白月光和朱砂痣』，都挺好听。以后得关注点女 UP 了，看着多可爱，生活又不是只有代码。卧艹不对说回正题。&lt;/p&gt;
&lt;p&gt;MMDetection 是一个基于 PyTorch 的目标检测开源工具箱 &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;，支持了众多主流的和最新的检测算法，例如 Faster R-CNN，Mask R-CNN，RetinaNet 等，官网也给出了详细的教程。既然如此，生命不息，开坑不止。前前后后被各种事情打断，大概花了一周搞懂了如何使用 &lt;code&gt;MMdetection&lt;/code&gt; 去做检测的任务。本文收录：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;安装&lt;/li&gt;
&lt;li&gt;修改配置文件&lt;/li&gt;
&lt;li&gt;调用模型与训练好的参数，进行推理&lt;/li&gt;
&lt;li&gt;自定义训练&lt;/li&gt;
&lt;li&gt;数据处理流程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意，本文更多像是记录学习过程，这也是我第一次用这个工具，遇到问题一步一步的 debug 与记录，并不是直接的教程。且，本文程序大多能直接复制运行，需要对应到自己的路径。我希望读者看完本文后具有解决问题的能力，而不只是会解决问题。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>神经网络中的数据问题</title>
    <link href="https://muyuuuu.github.io/2021/05/07/DNN-data-normal/"/>
    <id>https://muyuuuu.github.io/2021/05/07/DNN-data-normal/</id>
    <published>2021-05-07T17:44:12.000Z</published>
    <updated>2021-05-25T17:35:54.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>今日在写程序时，遇到了一个蜜汁 <code>bug</code>，加载别人训练好的 <code>ResNet18</code>，识别精度很低，只有 16%，但理论上而言应该有 92%，我也好奇那 80% 的准确率去哪里了。而程序和数据本身又无错误，所以来探究一下这是为什么。</p><a id="more"></a><p>首先，网络结构和预训练的模型来自这里 <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>，这里声明一下，他提供的网络、参数都是没任何问题的，准确率低是我自己的原因。</p><h1 id="错误程序"><a href="#错误程序" class="headerlink" title="错误程序"></a>错误程序</h1><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> resnet18 <span class="keyword">import</span> ResNet18</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">testdataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data_path, label_path)</span>:</span></span><br><span class="line">        <span class="comment"># 模型是预训练好的，取后面 10000 个做测试</span></span><br><span class="line">        self.x_data = np.load(data_path)</span><br><span class="line">        <span class="comment"># 数据到 [0, 1] 之间</span></span><br><span class="line">        self.x_data = self.x_data / <span class="number">255</span></span><br><span class="line">        self.x_data = self.x_data[<span class="number">50000</span>:]</span><br><span class="line">        self.y_data = np.load(label_path)</span><br><span class="line">        self.y_data = self.y_data[<span class="number">50000</span>:]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        x_ = self.x_data[index]</span><br><span class="line">        x_ = x_.transpose(<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>)</span><br><span class="line">        y_ = self.y_data[index]</span><br><span class="line">        <span class="keyword">return</span> torch.from_numpy(x_), torch.from_numpy(y_)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.x_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_error</span><span class="params">(model, X, y)</span>:</span></span><br><span class="line">    out = model(X)</span><br><span class="line">    prediction = torch.argmax(out, <span class="number">1</span>)</span><br><span class="line">    prediction = prediction.unsqueeze(<span class="number">1</span>)</span><br><span class="line">    correct = (prediction == y).sum().float()</span><br><span class="line">    <span class="keyword">return</span> correct</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_eval</span><span class="params">(model, device, test_loader)</span>:</span></span><br><span class="line">    model.eval()</span><br><span class="line">    model.to(device)</span><br><span class="line">    natural_err_total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">        data, target = data.to(device,</span><br><span class="line">                               dtype=torch.float), target.to(device,</span><br><span class="line">                                                             dtype=torch.float)</span><br><span class="line">        X, y = Variable(data, requires_grad=<span class="literal">True</span>), Variable(target)</span><br><span class="line">        err_natural = _error(model, X, y)</span><br><span class="line">        natural_err_total += err_natural</span><br><span class="line">    print(<span class="string">'acc: '</span>, natural_err_total / <span class="number">10000</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 加载 resnet</span></span><br><span class="line">    resnet = ResNet18()</span><br><span class="line">    resnet_path = <span class="string">"resnet18_ckpt.pth"</span></span><br><span class="line">    checkpoint = torch.load(resnet_path, map_location=<span class="string">'cpu'</span>)</span><br><span class="line">    print(<span class="string">'loaded model...'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这里只是为了对应模型参数</span></span><br><span class="line">    net_state = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> checkpoint[<span class="string">'net'</span>]:</span><br><span class="line">        net_state[key[<span class="number">7</span>:]] = checkpoint[<span class="string">'net'</span>][key]</span><br><span class="line">    resnet.load_state_dict(net_state)</span><br><span class="line">    print(<span class="string">'set model...'</span>)</span><br><span class="line"></span><br><span class="line">    data_path = <span class="string">"cifar10_data.npy"</span></span><br><span class="line">    label_path = <span class="string">"cifar10_label.npy"</span></span><br><span class="line">    test_data = testdataset(data_path=data_path, label_path=label_path)</span><br><span class="line">    test_loader = DataLoader(test_data, batch_size=<span class="number">128</span>)</span><br><span class="line">    print(<span class="string">'load data...'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 干净样本准确率</span></span><br><span class="line">    print(<span class="string">'natural'</span>, end=<span class="string">', '</span>)</span><br><span class="line">    _eval(model=resnet, device=<span class="string">'cpu'</span>, test_loader=test_loader)</span><br></pre></td></tr></table></figure><p>在这样操作下，准确率只有 <code>16.89%</code> ，我也很奇怪是哪里错了。</p><h1 id="正确程序"><a href="#正确程序" class="headerlink" title="正确程序"></a>正确程序</h1><p>从师兄那里找到了一份正确的程序，准确率是 <code>92.84%</code>。后文会进行说明，这份代码只是结果对，但逻辑不对。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> resnet18 <span class="keyword">import</span> ResNet18</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TensorDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dataPath, labelPath)</span>:</span></span><br><span class="line">        x = np.load(dataPath)</span><br><span class="line">        x = x[<span class="number">50000</span>:] / <span class="number">255.</span></span><br><span class="line">        x = x.astype(<span class="string">"float32"</span>)</span><br><span class="line">        data = x.transpose(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        label = np.load(labelPath)[<span class="number">50000</span>:]</span><br><span class="line">        label = np.reshape(label, (data.shape[<span class="number">0</span>], ))</span><br><span class="line">        data, label = torch.from_numpy(data), torch.from_numpy(label)</span><br><span class="line">        self.data_tensor = data</span><br><span class="line">        self.target_tensor = label</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.data_tensor[index], self.target_tensor[index]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.data_tensor.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net = ResNet18()</span><br><span class="line">resnet_path = <span class="string">"resnet18_ckpt.pth"</span></span><br><span class="line">d = torch.load(resnet_path, map_location=torch.device(<span class="string">'cpu'</span>))[<span class="string">'net'</span>]</span><br><span class="line">d = OrderedDict([(k[<span class="number">7</span>:], v) <span class="keyword">for</span> (k, v) <span class="keyword">in</span> d.items()])</span><br><span class="line">net.load_state_dict(d)</span><br><span class="line">dataPath = <span class="string">"cifar10_data.npy"</span></span><br><span class="line">labelPath = <span class="string">"cifar10_label.npy"</span></span><br><span class="line">dataset = TensorDataset(dataPath, labelPath)</span><br><span class="line">dataloader = torch.utils.data.DataLoader(dataset,</span><br><span class="line">                                         batch_size=<span class="number">64</span>,</span><br><span class="line">                                         shuffle=<span class="literal">True</span>,</span><br><span class="line">                                         num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line">correct = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> batch_idx, (inputs, targets) <span class="keyword">in</span> enumerate(dataloader):</span><br><span class="line">    outputs = net(inputs)</span><br><span class="line">    _, predicted = outputs.max(<span class="number">1</span>)</span><br><span class="line">    total += targets.size(<span class="number">0</span>)</span><br><span class="line">    correct += predicted.eq(targets).sum().item()</span><br><span class="line">acc = <span class="number">100.</span> * correct / total</span><br><span class="line">print(acc)</span><br></pre></td></tr></table></figure><h1 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h1><p>两份代码的数据加载、准确率计算都是正确的。经过二分法逐行注释，终于找到了问题所在，来依次分析一下。</p><p>第一个问题，因为网络的输入是 <code>channel first</code>，而 <code>numpy</code> 的数据中 <code>channel</code> 位于最后面，所以需要对数据进行转置处理。<strong>但是这里有坑</strong>。假设，图片之前的维度是 <code>height, width, channel</code>，大小是 <code>32 X 32 X 3</code>。</p><ul><li>假设此时转置的方法是 <code>np.transpose(2, 0, 1)</code>，得到矩阵的维度是 <code>channel, height, width</code>，大小是 <code>3 X 32 X 32</code>，这样输入网络是没有问题的。</li><li>假设此时转置的方法是 <code>np.transpose(2, 1, 0)</code>，得到矩阵的维度是 <code>channel, width, height</code>，大小是 <code>3 X 32 X 32</code>，这样输入网络不会报错，但准确率会很低，大概只有 <code>50%</code>，究其原因是数据增强所导致的。</li></ul><p>第二个问题，是 <code>model.eval()</code> 导致的，如果开启这个，准确率就会很低；如果不开启，准确率又正常，所以来深究一下这是为哈。<del>踩坑无数。</del>首先来回顾下 <code>pytorch</code> 的训练过程：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> x, y <span class="keyword">in</span> dataloader:</span><br><span class="line">    <span class="comment"># 模型输出</span></span><br><span class="line">    y_pre = model(x)</span><br><span class="line">    <span class="comment"># 计算损失</span></span><br><span class="line">    loss = criterion(y_pre, y)</span><br><span class="line">    <span class="comment"># 上次计算遗留的梯度清空，准备反向传播</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># 计算梯度，不反向传播</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># 更新参数</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><p>而 <code>model.eval()</code> 会将 <code>batchnormal</code> 和 <code>dropout</code> 固定住，用训练好的值。否则，一旦测试时数据的 <code>batchsize</code> 变小，就会导致图像失真，模型准确率降低。这<strong>可能</strong>是问题所在。且在使用 <code>pytorch</code> 训练模型时，一定要注意 <code>train</code> 和 <code>eval</code> 模式的切换。</p><p>沿着这个思路，先在一些网站先找到一些<strong>可能</strong>的解决方案 <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> <sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>。这里说可能是因为：任何问题都需要上下文才能知道准确的解决方案，即使描述的是同一个问题，也可能有多种解决方案。里面大概的解决方案如下：</p><ul><li><code>batchsize</code> 很小导致的，但我这里 <code>batchsize</code> 已经是 128 了，显然并不是这个原因</li><li>许多地方用同一个 <code>bn</code> 层，但我打开训练代码 <sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> ，里面 <code>bn</code> 层没有共用，所以也不是这个原因</li><li>在训练阶段，将模型设置为 <code>model.train()</code> 之前，一定要更新参数，包括 <code>zero_grad</code>，但我看了代码，不是这个问题</li><li><code>bn</code> 层的参数 <code>track_running_stats</code> 导致的。那我们来看看这个参数是啥意思，打开原文档 <sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup> ，发现描述的佷晦涩，我没看懂。所以在网上找了找 <sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup> ，意思是，如果这个参数为 <code>True</code>，<code>bn</code> 就会追踪历史数据，以滑动加权平均的方式来更新 $\mu$ 和 $\sigma$。而 <code>track_running_stats</code> 取值为 <code>False</code>，就不会追踪历史数据，只会根据当前的 <code>batch</code> 计算均值和方差。<ul><li>可能由于数据比较不稳且 <code>batchsize</code> 很小影响了精度，但我打开程序，也不是这个原因。何况 <code>model.eval()</code> 模式下，<code>track_running_stats</code> 取值为 <code>True</code>，使用训练好的模型参数，且 <code>bn</code> 的参数也不会更新。</li><li>多说一些，<code>bn</code> 的均值和方差是在 <code>forward</code> 方法中更新的 <sup id="fnref:7"><a href="#fn:7" rel="footnote">7</a></sup> ，而不是在 <code>optimizer.step</code> 中更新。所以处于训练模式，<code>bn</code> 的参数不需要反向传播仍然能更新。<strong>这里需要注意。</strong></li></ul></li></ul><p>以上，也就是打开搜索引擎，能看到了解决方案了。<del>我屏蔽了某DN，某园等，以及另外的一些抄袭社区等等，他们的解决方案我看不到。</del>捕获回过头来分析下我看到的解决方案，也能意识到是数据处理部分的问题了。反过来想，训练模式下精度很高，说明 <code>bn</code> 层在动，而 <code>bn</code> 影响的是数据。众所周知，颠覆结果的不是模型，是数据，所以猜测是数据的问题。</p><p>打开源程序，我们发现训练阶段对数据做了标准化处理 <sup id="fnref:8"><a href="#fn:8" rel="footnote">8</a></sup>；而我们处理测试数据时，只是单纯的除以 255，保证数据在 0 到 1 之间，<strong>但这是不对的</strong>。那么也大概找到了解决方案，加载测试数据的时候进行标准化，此时模型的精度终于正确了！！！原因居然是：数据没有标准化处理。而 <code>train</code> 模式下精度很高，可能是因为通过 <code>bn</code> 层调整了数据分布。所以正确代码如下：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">testdataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data_path, label_path)</span>:</span></span><br><span class="line">        <span class="comment"># 模型是预训练好的，取后面 10000 个做测试</span></span><br><span class="line">        self.x_data = np.load(data_path)</span><br><span class="line">        <span class="comment"># 数据到 [0, 1] 之间</span></span><br><span class="line">        self.x_data = self.x_data / <span class="number">255</span></span><br><span class="line">        self.x_data = self.x_data[<span class="number">50000</span>:]</span><br><span class="line">        self.y_data = np.load(label_path)</span><br><span class="line">        self.y_data = self.y_data[<span class="number">50000</span>:]</span><br><span class="line"></span><br><span class="line">        mean = np.array([<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>]).reshape(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        var = np.array([<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>]).reshape(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        self.x_data = (self.x_data - mean) / var</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, index)</span>:</span></span><br><span class="line">        x_ = self.x_data[index]</span><br><span class="line">        x_ = x_.transpose(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        y_ = self.y_data[index]</span><br><span class="line">        <span class="keyword">return</span> torch.from_numpy(x_), torch.from_numpy(y_)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.x_data)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    ...</span><br><span class="line">    net.eval()</span><br><span class="line">    ...</span><br><span class="line">    predict(net, testloader)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure><h1 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h1><p>既然标准化如此重要，就来回顾下标准化的用途。</p><ul><li>第一步，数据归一化，也就是映射到 0 到 1 之间，这是为了防止梯度爆炸以及特征尺度的缩放。<ul><li>因为误差反向传播求偏导的时候，会作用到原始数据 $x$，如果 $x$ 的取值是 255，梯度瞬间爆炸。</li><li>一个特征的变化范围可能是[1000,10000]，另一个特征的变化范围可能是[−0.1,0.2]，在进行距离有关的计算时，单位的不同会导致计算结果的不同，尺度大的特征会起决定性作用。所以要归一化，消除特征间单位和尺度差异的影响。刚才代码归一化的方式很简单，就是除以 255，当然还有很多其它的方式以及优缺点 <sup id="fnref:9"><a href="#fn:9" rel="footnote">9</a></sup> <sup id="fnref:10"><a href="#fn:10" rel="footnote">10</a></sup>。</li></ul></li></ul><p>在数据归一化后，可以标准化也可以不标准化，上述代码所用的 Z-Score 标准化的意思就是将数据映射到均值为 0，方差为 1 的分布空间中。</p><p>\begin{equation}<br>x = \frac{x-\mu}{\sigma}<br>\end{equation}</p><ul><li>此类标准化是通过特征的平均值和标准差，将特征缩放成一个标准的正态分布，缩放后均值为0，方差为1。特别适用于数据的最大值和最小值未知，或存在孤立点。</li><li>标准化是为了方便数据的下一步处理，而进行的数据缩放等变换，不同于归一化，并不是为了方便与其他数据一同处理或比较。归一化是为了消除纲量压缩到 <code>[0, 1]</code> 区间；标准化只是调整特征整体的分布，也就是平移到原点附近。且，归一化与最大，最小值有关；标准化与均值，标准差有关。</li><li>估算均值与方差需要总体的平均值与方差，但是这一值在真实的分析与挖掘中很难得到，大多数情况下是用样本的均值与标准差替代，所以一般要求数据符合正态分布。</li></ul><p>因此，也很容易定位到问题所在。训练的时候归一化处理的数据，而预测的时候没有，数据在两种不同的分布空间，所以导致预测精度降低。<del>本文记录了全部 debug 的过程，学到了好多东西（误</del></p><h1 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">https://github.com/laisimiao/classification-cifar10-pytorch</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">https://www.zhihu.com/question/354742972</span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;">https://github.com/laisimiao/classification-cifar10-pytorch/blob/master/models/resnet.py#L60-L64</span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">4.</span><span style="display: inline-block; vertical-align: top;">https://discuss.pytorch.org/t/performance-highly-degraded-when-eval-is-activated-in-the-test-phase/3323</span><a href="#fnref:4" rev="footnote"> ↩</a></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">5.</span><span style="display: inline-block; vertical-align: top;">https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html</span><a href="#fnref:5" rev="footnote"> ↩</a></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">6.</span><span style="display: inline-block; vertical-align: top;">https://www.zhihu.com/question/282672547</span><a href="#fnref:6" rev="footnote"> ↩</a></li><li id="fn:7"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">7.</span><span style="display: inline-block; vertical-align: top;">https://pytorch.org/docs/stable/_modules/torch/nn/modules/batchnorm.html#BatchNorm2d</span><a href="#fnref:7" rev="footnote"> ↩</a></li><li id="fn:8"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">8.</span><span style="display: inline-block; vertical-align: top;">https://github.com/laisimiao/classification-cifar10-pytorch/blob/master/main.py#L38-L41</span><a href="#fnref:8" rev="footnote"> ↩</a></li><li id="fn:9"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">9.</span><span style="display: inline-block; vertical-align: top;">https://ssjcoding.github.io/2019/03/27/normalization-and-standardization/</span><a href="#fnref:9" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今日在写程序时，遇到了一个蜜汁 &lt;code&gt;bug&lt;/code&gt;，加载别人训练好的 &lt;code&gt;ResNet18&lt;/code&gt;，识别精度很低，只有 16%，但理论上而言应该有 92%，我也好奇那 80% 的准确率去哪里了。而程序和数据本身又无错误，所以来探究一下这是为什么。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DeepLearning" scheme="https://muyuuuu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>对抗攻击篇：CW 攻击算法</title>
    <link href="https://muyuuuu.github.io/2021/05/04/CW-attack/"/>
    <id>https://muyuuuu.github.io/2021/05/04/CW-attack/</id>
    <published>2021-05-04T12:08:04.000Z</published>
    <updated>2021-05-25T17:36:24.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>五一闲的没事继续开坑，差不多也该做论文了。等看完一些经典的攻击算法后，做一些复现和对比实验，然后去看经典的防御算法。CW 算法是一种基于优化的攻击算法 <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>，而论文的创新点在于损失函数的定义与梯度的截断。</p><a id="more"></a><h1 id="L-BFGS"><a href="#L-BFGS" class="headerlink" title="L-BFGS"></a>L-BFGS</h1><p>从最开始的 L-BFGS <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> 出发，通过 $L_2$ 范数距离寻找和原始样本 $x$ 最接近的对抗样本 $x’$，而寻找对抗样本的过程就是解决以下优化问题：</p><p>\begin{equation}<br>\begin{aligned}<br>\min &amp; \; c\Vert x-x’ \Vert<em>2 + \text{loss}</em>{F,t}(x’) \<br>\text{s.t.} &amp; \; x’ \in [0,1]<br>\end{aligned}<br>\end{equation}</p><p>其中 $c$ 是一个常数，表示损失函数权重为 1 的情况下，对抗样本与原始样本距离的权重应该是多少；$t$ 表示错误分类的标签，$x$ 是已知的可以视为常量，那么唯一的变量就是 $x’$，可以通过一维线搜索的问题求解到 $c$ 的取值。</p><p>论文中给出了 $t$ 的选择方法。假设当前为 10 分类任务，正确类别是 0，那么 $t$ 可以取 $1,2,\cdots,9$，那么取哪一个合适呢？换句话说，手写字体识别中，1 和 7 在字迹潦草的情况下容易被认错，那么正确类别是 1 时，对抗样本向 7 靠近，更容易攻击成功。</p><ul><li>平均选择，均匀的在错误类别中随机选择</li><li>最佳选择，在所有错误类别上进行攻击，选择最容易攻击的</li><li>最差选择，在所有错误类别上进行攻击，选择最难以攻击的</li></ul><h1 id="CW"><a href="#CW" class="headerlink" title="CW"></a>CW</h1><p>从最终输出概率的角度而言，获取最容易攻击的类别和最难以攻击的类别并不难。理解上述公式后，转换到 CW 算法论文中的攻击算法，用公式描述：</p><p>\begin{equation}<br>\begin{aligned}<br>\min &amp; \; \ D(x, x+\delta) \<br>\text{s.t.} &amp; \; \ C(x+\delta) = t \<br>{ } &amp; \; \ x + \delta \in [0,1]<br>\end{aligned}<br>\end{equation}</p><p>$t$ 依然是被错误分类的标签，$C$ 表示分类结果，$D$是距离度量函数，而本文选择的距离是 $L<em>0, L_2, L</em>\inf$ 三种范数距离。论文中指出：没有任何一种距离能衡量人类感知的差异，现有距离的度量方式都有或多或少的缺陷，所以本文选取了三种范数距离，但每一种距离也达到了目前最好的攻击效果。未来的工作中，可以好好研究下如何构造合适的距离度量函数。</p><h1 id="解非线性优化"><a href="#解非线性优化" class="headerlink" title="解非线性优化"></a>解非线性优化</h1><p>回到主题，将攻击公式化后，尝试借助优化的方法去求解问题。但由于 $C(x+\delta)=t$ 具有高度的非线性，所以选择一种更适合优化的表达方式。定义一个目标函数 $f$，当且仅当 $f(x+\delta) \leq 0$ 时，$C(x+\delta)=t$。论文中给出了 7 种 $f$ 的选择，但我懒，准备少写几个，不影响</p><p>\begin{equation}<br>\begin{aligned}<br>f<em>1(x’) &amp;= -\text{loss}</em>{F,t}(x’) + 1 \<br>f<em>2(x’) &amp;= \Big( \max</em>{i\neq t} \big(Z(x’)_i\big) - Z(x’)_t \Big)^+ \<br>f_3(x’) &amp;= \big( 0.5-F(x’)_t \big)<br>\end{aligned}<br>\end{equation}</p><p>其中，$e^+$ 运算表示 $\max(e,0)$；$-\text{loss}$ 表示交叉熵损失；$F(x’)_i$ 表示神经网络使用 $x’$ 作为输入，产生类别是 $i$ 的概率；$Z(x’)$ 表示 softmax 前的输出，即 $F(x)=\text{softmax}(Z(x))$。其中，效果最好的是第二个。那我们就用第二个公式解释下这些都是什么。</p><p>在论文中，$i$ 表示 $x’$ 对应的正确类别；$t$ 表示 $x’$ 对应的错误类别。而 $C(x+\delta)=t$ 表示希望对抗样本被错误分类，此时按照假设，$f(x+\delta) \leq 0$。我们带入$f<em>2$，$\max</em>{i\neq t} \big(Z(x’)_i\big)$ 表示除了类别 $t$ 以外，网络以最大概率认为这是第 $i$ 个类，但第 $i$ 类的概率仍然低于第 $t$ 类的概率，以此认为攻击成功。$f_3$ 同理，表示分类错误的概率大于 0.5。因此，优化目标修改为：</p><p>\begin{equation}<br>\begin{aligned}<br>\min &amp; \; \ D(x, x+\delta) \<br>\text{s.t.} &amp; \; \ f(x+\delta) \leq 0 \<br>{ } &amp; \; \ x + \delta \in [0,1]<br>\end{aligned}<br>\end{equation}</p><p>为了便于优化，按着 L-BFGS 的形式就行修改，将约束条件转为目标函数。第一项表示对抗样本要接近原始样本，第二项表示分类越错越好。</p><p>\begin{equation}<br>\begin{aligned}<br>\min &amp; \; \ \Vert \delta \Vert_p + c f(x+\delta)\<br>\text{s.t.} &amp; \; \ x + \delta \in [0,1]<br>\end{aligned}<br>\end{equation}</p><p>其中，$c$ 的选择是一个坑，如果 $c\to 0$，那么梯度下降时，损失大部分来自图像误差；如果 $c$ 很大，那么分类损失将占主导，两者的损失应该相似。论文中，作者使用实验的方式确定了 $c$ 的最佳取值。</p><h1 id="梯度截断"><a href="#梯度截断" class="headerlink" title="梯度截断"></a>梯度截断</h1><p>因为对抗样本增加、减去梯度后很容易超出 $[0,1]$ 的范围，所以目前有一些截断的方法：</p><ul><li>梯度投影下降，对溢出部分直接截断，把截断后的对抗样本带入下一轮，但容易将截断带来的误差给传入下一轮迭代，这样会让误差越来越大。</li><li>梯度截断下降，不直接截断样本，而是将样本的截断代入要最小化的目标函数中，用 $f(\min(\max(x+\delta,0),1))$ 来代替 $f(x+\delta)$，但会带来梯度消失的问题。如当 $x$ 很大时取值为 1，且偏导数取值为 0。但反向传播时，无法更新 $x$。</li></ul><p>因此，本文引入变量 $w$，对抗样本可以表示为：</p><p>\begin{equation}<br>x+\delta=\frac{1}{2}\big( \tanh(w) + 1 \big)<br>\end{equation}</p><p>因为 $\tanh$ 的取值范围是 $[-1,1]$，所以 $x+\delta$ 的取值范围是 $[0,1]$，这样就满足了约束，也是一种光滑的截断，也算是本文比较大的创新点吧。</p><h1 id="开始攻击"><a href="#开始攻击" class="headerlink" title="开始攻击"></a>开始攻击</h1><p>我看论文中，$L<em>0$ 和 $L</em>\inf$ 都有一些缺陷，所以重点写 $L_2$ 攻击了。此时的方程为：</p><p>\begin{equation}<br>\begin{aligned}<br>\min &amp; \; \ \Big| \frac{1}{2}\big(\tanh(w) + 1\big) - x \Big|<em>2 + c f\big(\frac{1}{2}(\tanh(w) + 1)\big) \<br>f(x) &amp; = \max\Big( \max\big(Z(x)</em>{i:i\neq t}\big) - Z(x)_t, -k\Big)<br>\end{aligned}<br>\end{equation}</p><p>参数 $k$ 用于控制错误分类的置信度，论文中 $k=0$，即保证被正确分类的概率低于被错误分类的概率。他人实现的程序 <sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>，但是程序的实现和论文的内容有一些出入。论文中，$Z(x)<em>t$ 表示错误分类。在实现用，用真实标签的概率 $y</em>\text{true}$ 减去被错误识别的概率 $y_\text{false}$ 中最大的一个。</p><ul><li>若这一项大于0，会有损失，表示要降低对真实标签的可信度；</li><li>若这一相小于0，取值为0，表示无法识别正确分类。此时没有损失，满足之前的当且仅当 $f(x+\delta) \leq 0$ 时，$C(x+\delta)=t$，也就是，分类错误后，就不用优化这一项了；换句话说，在不满足 $C(x+\delta)=t$ 约束下，是没有目标函数的损失值的。这里的确需要好好理解。</li></ul><h1 id="程序-4"><a href="#程序-4" class="headerlink" title="程序 4"></a>程序 <sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup></h1><ul><li><code>fgsm_attack.py</code>，使用 <code>fgsm</code> 算法制作对抗样本</li><li><code>resnet</code>，使用 <code>ResNet50</code> 制作对抗样本</li><li><code>vgg</code>，黑盒攻击，使用 <code>VGG16</code> 作为目标模型</li><li><code>eval.py</code>，验证目标模型在对抗样本攻击下的准确率</li></ul><div class="table-container"><table><thead><tr><th>攻击模型</th><th>目标模型</th><th>原始准确率</th><th>L2攻击</th></tr></thead><tbody><tr><td>ResNet50</td><td>VGG16</td><td>94.27</td><td>53.63</td></tr></tbody></table></div><p>预训练模型<a href="https://github.com/laisimiao/classification-cifar10-pytorch" target="_blank" rel="noopener">下载</a>。</p><h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><ul><li><code>python cw_attack.py</code>，制作对抗样本</li><li><code>python eval.py</code>，验证目标模型在对抗样本攻击下的准确率</li></ul><h1 id="references"><a href="#references" class="headerlink" title="references"></a>references</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">https://arxiv.org/abs/1608.04644</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">https://arxiv.org/pdf/1312.6199.pdf</span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;">https://github.com/Harry24k/CW-pytorch/blob/master/CW.ipynb</span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">4.</span><span style="display: inline-block; vertical-align: top;">https://github.com/muyuuuu/Adversarial-Attack/tree/main/CW_L2</span><a href="#fnref:4" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;五一闲的没事继续开坑，差不多也该做论文了。等看完一些经典的攻击算法后，做一些复现和对比实验，然后去看经典的防御算法。CW 算法是一种基于优化的攻击算法 &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;，而论文的创新点在于损失函数的定义与梯度的截断。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="DeepLearning" scheme="https://muyuuuu.github.io/tags/DeepLearning/"/>
    
  </entry>
  
  <entry>
    <title>目标检测篇：目标检测快速训练与推理框架</title>
    <link href="https://muyuuuu.github.io/2021/05/03/fast-train-eval-platform-fasterrcnn-torch/"/>
    <id>https://muyuuuu.github.io/2021/05/03/fast-train-eval-platform-fasterrcnn-torch/</id>
    <published>2021-05-03T14:24:52.000Z</published>
    <updated>2021-05-25T17:39:38.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>最早在天池玩耍的时候接触到了目标检测。当时真的啥都不知道，头铁，一点点的开坑造轮子。后来再看前几名开源的程序，发现有很多库可以使用，切图，目标检测等，比如数据增强、目标检测都有现成的工具箱。所以想着，就先用调库的形式写一个简单的 <code>baseline</code>，下一个任务直接用现成的代码，省点事，所以写了一个这样的简单的平台。</p><a id="more"></a><p>注意：</p><ul><li>本文调库，且只针对 <code>COCO</code> 数据集。</li><li>平台很简单很简单，我不想写的太复杂。原因是：复杂的代码容易让使用者头晕，其次，如果真的要改形如损失函数等细节，调库肯定满足不了，这时候就要自己写。但平台应该足够抽象和简单，只是用来观察初步效果，不应该包含这些复杂的东西。<strong>对修改封闭，对扩展开放。</strong></li><li>因为这次接的任务涉及到了对抗样本，所以后期肯定要改损失函数，到时候在写针对细节的程序。</li></ul><h1 id="程序"><a href="#程序" class="headerlink" title="程序"></a>程序</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch             1.7.1+cu92</span><br><span class="line">torchvision       0.8.2+cu92</span><br><span class="line">pycocotools       2.0.2</span><br></pre></td></tr></table></figure><p><a href="https://github.com/muyuuuu/Faster-RCNN-COCO" target="_blank" rel="noopener">https://github.com/muyuuuu/Faster-RCNN-COCO</a></p><ul><li><code>preprocess</code> 文件夹，这俩代码都是单独执行的<ul><li><code>mean-std.py</code>，计算样本三通道的均值与方差，用于数据标准化</li><li><code>reconstruct-anno.py</code>，重构 <code>json</code>，支持多个 <code>batchsize</code></li></ul></li><li><code>model</code> 文件夹<ul><li><code>data_helper.py</code>，加载数据</li><li><code>engine.py</code>，训练与推理的具体过程</li><li><code>eval.py</code>，推理程序，<code>python eval.py</code> 执行</li><li><code>model.py</code>，模型</li><li><code>train.py</code>，训练程序，<code>python train.py</code> 执行</li><li><code>utils.py</code>，保存、加载模型和写入日志</li></ul></li></ul><h1 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h1><p>首先，掏出 <code>torchvision</code>，找到其实现的 <code>fasterrcnn_resnet50_fpn</code> 模型。查看其源程序：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fasterrcnn_resnet50_fpn</span><span class="params">(pretrained=False, progress=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                            num_classes=<span class="number">91</span>, pretrained_backbone=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                            trainable_backbone_layers=None, **kwargs)</span>:</span></span><br><span class="line">    trainable_backbone_layers = _validate_trainable_layers(</span><br><span class="line">        pretrained <span class="keyword">or</span> pretrained_backbone, trainable_backbone_layers, <span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        <span class="comment"># no need to download the backbone if pretrained is set</span></span><br><span class="line">        pretrained_backbone = <span class="literal">False</span></span><br><span class="line">    backbone = resnet_fpn_backbone(<span class="string">'resnet50'</span>, pretrained_backbone, </span><br><span class="line">    trainable_layers=trainable_backbone_layers)</span><br><span class="line">    model = FasterRCNN(backbone, num_classes, **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        state_dict = load_state_dict_from_url(</span><br><span class="line">            model_urls[<span class="string">'fasterrcnn_resnet50_fpn_coco'</span>],</span><br><span class="line">            progress=progress)</span><br><span class="line">        model.load_state_dict(state_dict)</span><br><span class="line">        overwrite_eps(model, <span class="number">0.0</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure><ul><li><code>pretrained</code> 取值为 <code>False</code> 的情况下，<code>pretrained_backbone</code> 取值会为 <code>True</code>，会返回在 <code>ImageNet</code> 上预训练的 backbone；<code>pretrained</code> 取值为 <code>True</code> 的情况下，<code>pretrained_backbone</code> 取值会为 <code>False</code>，将会返回一个在 <code>COCO train2017</code> 上预训练的模型；而无论如何，<code>backbone</code> 是使用了 <code>FPN</code> 机制的。</li><li><code>num_classes</code> 设置成自己需要检测的类的数量，<strong>注意多一个背景类</strong>；</li><li>观察 <code>**kwargs</code> 参数，传给了 <code>FasterRCNN</code>，所以追踪这个类，发现它能设置很多参数 <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> ，比如 <code>anchor</code> 的大小和比例。这个时候对原始数据 <code>EDA</code> 一下，设置合适的参数就可以了；</li></ul><p>此时创建模型的程序为：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision.models.detection <span class="keyword">as</span> td</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span><span class="params">(num_class)</span>:</span></span><br><span class="line">    anchor_sizes = ((<span class="number">64</span>, ), (<span class="number">128</span>, ), (<span class="number">256</span>, ), (<span class="number">512</span>, ), (<span class="number">1024</span>, ))</span><br><span class="line">    aspect_ratios = ((<span class="number">0.5</span>, <span class="number">1.0</span>, <span class="number">2.0</span>), ) * len(anchor_sizes)</span><br><span class="line">    rpn_anchor_generator = td.anchor_utils.AnchorGenerator(</span><br><span class="line">        anchor_sizes, aspect_ratios)</span><br><span class="line">    <span class="comment"># https://github.com/pytorch/vision/blob/master/torchvision/models/detection/faster_rcnn.py</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># faster rcnn，网络会再次对 图像数据进行重定义尺寸</span></span><br><span class="line">    <span class="comment"># https://github.com/pytorch/vision/blob/c2ab0c59f42babf9ad01aa616cd8a901daac86dd/torchvision/models/detection/transform.py#L64</span></span><br><span class="line">    detector = td.fasterrcnn_resnet50_fpn(</span><br><span class="line">        rpn_anchor_generator=rpn_anchor_generator, pretrained=<span class="literal">True</span>)</span><br><span class="line">    num_classes = num_class</span><br><span class="line">    <span class="comment"># ROI head 是 backbone 后，预测盒子和类别的位置</span></span><br><span class="line">    <span class="comment"># box_predictor 是 FastRCNNPredictor 类，cls_score 是类别分类器</span></span><br><span class="line">    <span class="comment"># in_features 是模型的输入特征</span></span><br><span class="line">    <span class="comment"># https://github.com/pytorch/vision/blob/5339e63148304ce32fd1cbd1e8bb74ea79458691/torchvision/models/detection/faster_rcnn.py#L263-L276</span></span><br><span class="line">    in_features = detector.roi_heads.box_predictor.cls_score.in_features</span><br><span class="line">    <span class="comment"># 设置要预测的新的分类数</span></span><br><span class="line">    detector.roi_heads.box_predictor = td.faster_rcnn.FastRCNNPredictor(</span><br><span class="line">        in_features, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> detector</span><br></pre></td></tr></table></figure><h1 id="数据制作"><a href="#数据制作" class="headerlink" title="数据制作"></a>数据制作</h1><p>之前头铁自己写库解析 <code>anno_json</code> 去制作数据集，后来发现有它人最好的第三方工具，直接 <code>pip install pycocotools</code> 上车。然后去写自己的 <code>dataloader</code> 类就好了。注意，在构造函数中，只初始化一些工具，不要加载数据，否则会内存溢出；将数据加载推迟到 <code>__getitem__</code> 方法中，反正者里面只拿一小部分的数据。此时的核心代码为：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pycocotools.coco <span class="keyword">import</span> COCO</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">train_data_set</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, image_dir, anno_path)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.image_dir = image_dir</span><br><span class="line">        <span class="comment"># COCO api class that loads COCO annotation file and prepare data structures</span></span><br><span class="line">        self.coco = COCO(anno_path)</span><br><span class="line">        <span class="comment"># 获取 image 的 id，字典转为 list</span></span><br><span class="line">        self.ids = list(self.coco.imgs.keys())</span><br><span class="line">        self.transform = transforms.Compose([</span><br><span class="line">            <span class="keyword">lambda</span> x: Image.open(x).convert(<span class="string">'RGB'</span>),</span><br><span class="line">            transforms.Resize((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">            transforms.ToTensor(),</span><br><span class="line">            <span class="comment"># transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))</span></span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据集很大时，要在 getitem 中获取</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        <span class="comment"># 某个图片的 id</span></span><br><span class="line">        img_id = self.ids[idx]</span><br><span class="line">        <span class="comment"># 图片路径</span></span><br><span class="line">        path = self.image_dir + self.coco.loadImgs(img_id)[<span class="number">0</span>][<span class="string">'file_name'</span>]</span><br><span class="line">        <span class="comment"># 获取图片的 annotations 的 id</span></span><br><span class="line">        ann_ids = self.coco.getAnnIds(imgIds=img_id)</span><br><span class="line">        <span class="comment"># 根据 annotations 的 id 获取 annotions</span></span><br><span class="line">        target = self.coco.loadAnns(ann_ids)</span><br><span class="line">        <span class="keyword">return</span> self.transform(path), target</span><br></pre></td></tr></table></figure><p>但是，还没结束，这里还要改一些 <code>key</code>，因为提供的 <code>json</code> 文件中，目标区域的名字是 <code>bbox</code>，但 <code>FasterRCNN</code> 要求的 <code>key</code> 是 <code>boxes</code>。所以，这部分修改也在数据加载里面完成。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> target:</span><br><span class="line">    v = &#123;&#125;</span><br><span class="line">    v[<span class="string">'boxes'</span>] = d.pop(<span class="string">'bbox'</span>)</span><br><span class="line">    d[<span class="string">'boxes'</span>] = v[<span class="string">'boxes'</span>]</span><br><span class="line">    x = []</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> v[<span class="string">'boxes'</span>]:</span><br><span class="line">        x.append(y)</span><br><span class="line">    x[<span class="number">2</span>], x[<span class="number">3</span>] = x[<span class="number">0</span>] + x[<span class="number">2</span>], x[<span class="number">1</span>] + x[<span class="number">3</span>]</span><br><span class="line">    d[<span class="string">'boxes'</span>] = torch.tensor(x, dtype=torch.float32)</span><br><span class="line">    v = &#123;&#125;</span><br><span class="line">    v[<span class="string">'labels'</span>] = d.pop(<span class="string">'category_id'</span>)</span><br><span class="line">    d[<span class="string">'labels'</span>] = torch.tensor(v[<span class="string">'labels'</span>] - <span class="number">1</span>, dtype=torch.int64)</span><br></pre></td></tr></table></figure><ul><li><code>pycocotools</code> 做出来的 <code>boxes</code> 是一个列表，列表的每个元素是张量；但我们需要的是张量，张量的尺寸是 <code>[1, 4]</code>，所以有了上面的修改；此次任务不涉及 <code>mask</code>，所以没有考虑 <code>segementation</code> 的修改；</li><li>如果遇到 AssertionError: target boxes must of float type 此类错误，直接打开源代码：</li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">floating_point_types = (torch.float, torch.double, torch.half)</span><br><span class="line"><span class="keyword">assert</span> t[<span class="string">"boxes"</span>].dtype <span class="keyword">in</span> floating_point_types, <span class="string">'target boxes must of float type'</span></span><br><span class="line"><span class="keyword">assert</span> t[<span class="string">"labels"</span>].dtype == torch.int64, <span class="string">'target labels must of int64 type'</span></span><br></pre></td></tr></table></figure><p>一目了然，这并不是说 boxes 是浮点数，而是说，张量中的元素应该是 <code>torch.float32, torch.float64, torch.float16</code> 类型的，创建张量的时候要加上这个参数；</p><ul><li>如果遇到 ValueError: All bounding boxes should have positive height and width. 错误，并不是说盒子里面出现的负数，而是说，FasterRCNN 希望看到 <code>[xmin, ymin, xmax, ymax]</code> 这样的数据，而你传入的是 <code>[xmin, ymin, width, height]</code> 这样的数据。但在后面 <code>torchvision</code> 中修复了这个问题 <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>。</li><li>如果遇到 sampled_pos_inds_subset = torch.where(labels &gt; 0)[0] CUDA error: device-side assert triggered 这样的错误，也不要慌。有两种解决方案，选一个就好。<ul><li>这里出错的原因很简单，数据提供的类是从 1 开始编号的，假设是 <code>label = [1，2，3]</code>；在预测时，正确的标签是 3，但程序中 <code>label[3]</code> 会出错，所以，将标签改为 <code>[0,1,2]</code> 就可以了。</li><li>传入训练模型时，增加背景类。这里看自己，如果需要背景类，就第二种方案；如果不需要背景类，就第一种方案。</li></ul></li><li>而如果要追求多个 <code>batchsize</code>，只能重构 <code>json</code>，此部分程序在 <code>github</code> 中给出。</li></ul><h1 id="训练与推理"><a href="#训练与推理" class="headerlink" title="训练与推理"></a>训练与推理</h1><p>首先来看官方提供训练的例子（注意这个例子在某些版本上不一定能跑通）：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=<span class="literal">True</span>)</span><br><span class="line">images, boxes = torch.rand(<span class="number">4</span>, <span class="number">3</span>, <span class="number">600</span>, <span class="number">1200</span>), torch.rand(<span class="number">4</span>, <span class="number">11</span>, <span class="number">4</span>)</span><br><span class="line">labels = torch.randint(<span class="number">1</span>, <span class="number">91</span>, (<span class="number">4</span>, <span class="number">11</span>))</span><br><span class="line">images = list(image <span class="keyword">for</span> image <span class="keyword">in</span> images)</span><br><span class="line">targets = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(images)):</span><br><span class="line">    d = &#123;&#125;</span><br><span class="line">    d[<span class="string">'boxes'</span>] = boxes[i]</span><br><span class="line">    d[<span class="string">'labels'</span>] = labels[i]</span><br><span class="line">    targets.append(d)</span><br><span class="line">output = model(images, targets)</span><br><span class="line"><span class="comment"># For inference</span></span><br><span class="line">model.eval()</span><br><span class="line">x = [torch.rand(<span class="number">3</span>, <span class="number">300</span>, <span class="number">400</span>), torch.rand(<span class="number">3</span>, <span class="number">500</span>, <span class="number">400</span>)]</span><br><span class="line">predictions = model(x)</span><br></pre></td></tr></table></figure><p>所以，训练的时候，把 image 和 target 转成列表并输入就可以了。注意，列表中的每个元素的类型必须和模型参数的类型一致，别忘了 <code>to(device)</code>。我把最终训练和推理的程序放到 <code>engine</code> 程序中了：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_fn</span><span class="params">(train_dataloader, detector, optimizer, device, epoch, scheduler)</span>:</span></span><br><span class="line">    detector.train()</span><br><span class="line">    loss_value = <span class="number">0</span></span><br><span class="line">    cnt = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> images, target <span class="keyword">in</span> tqdm(train_dataloader):</span><br><span class="line">        cnt += <span class="number">1</span></span><br><span class="line">        images = list(image.to(device) <span class="keyword">for</span> image <span class="keyword">in</span> images)</span><br><span class="line">        <span class="comment"># it's key:value for t in targets.items</span></span><br><span class="line">        <span class="comment"># This is the format the fasterrcnn expects for targets</span></span><br><span class="line">        targets = []</span><br><span class="line">        <span class="keyword">for</span> l, b <span class="keyword">in</span> zip(target[<span class="string">'labels'</span>], target[<span class="string">'boxes'</span>]):</span><br><span class="line">            d = &#123;&#125;</span><br><span class="line">            d[<span class="string">'labels'</span>] = l.view(<span class="number">-1</span>).to(device)</span><br><span class="line">            d[<span class="string">'boxes'</span>] = b.view(<span class="number">-1</span>, <span class="number">4</span>).to(device)</span><br><span class="line">            targets.append(d)</span><br><span class="line">        loss_dict = detector(images, targets)</span><br><span class="line">        losses = sum(loss <span class="keyword">for</span> loss <span class="keyword">in</span> loss_dict.values())</span><br><span class="line">        loss_value = losses.item()</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        losses.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        scheduler.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 训练数据过大，训练一部分就保存模型</span></span><br><span class="line">        <span class="keyword">if</span> cnt % <span class="number">1000</span> == <span class="number">999</span>:</span><br><span class="line">            cnt = <span class="number">0</span></span><br><span class="line">            utils.save_checkpoint_state(<span class="string">"model_tmp.pth"</span>, epoch, detector,</span><br><span class="line">                                        optimizer, scheduler)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss_value</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(val_dataloader, detector, device)</span>:</span></span><br><span class="line">    results = []</span><br><span class="line">    <span class="keyword">for</span> images, image_names <span class="keyword">in</span> tqdm(val_dataloader):</span><br><span class="line">        images = list(image.to(device) <span class="keyword">for</span> image <span class="keyword">in</span> images)</span><br><span class="line">        model_time = time.time()</span><br><span class="line">        outputs = detector(images)</span><br><span class="line">        model_time = time.time() - model_time</span><br><span class="line">        <span class="keyword">for</span> i, image <span class="keyword">in</span> enumerate(images):</span><br><span class="line">            boxes = (outputs[i][<span class="string">"boxes"</span>].data.cpu().numpy().tolist())</span><br><span class="line">            scores = outputs[i][<span class="string">"scores"</span>].data.cpu().numpy()</span><br><span class="line">            labels = outputs[i][<span class="string">"labels"</span>].data.cpu().numpy()</span><br><span class="line">            image_id = image_names[i]</span><br><span class="line">            <span class="keyword">for</span> b, s, l <span class="keyword">in</span> zip(boxes, scores, labels):</span><br><span class="line">                <span class="keyword">if</span> s &gt; <span class="number">0.5</span>:</span><br><span class="line">                    result = &#123;</span><br><span class="line">                        <span class="string">"image_id"</span>: image_id,</span><br><span class="line">                        <span class="string">"boxes"</span>: b,</span><br><span class="line">                        <span class="string">"scores"</span>: s.astype(float),</span><br><span class="line">                        <span class="string">"labels"</span>: l.astype(float),</span><br><span class="line">                    &#125;</span><br><span class="line">                    results.append(result)</span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><h1 id="预测无输出"><a href="#预测无输出" class="headerlink" title="预测无输出"></a>预测无输出</h1><p>在推理时，网络对所有图片的输出都是：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[&#123;<span class="string">'boxes'</span>: tensor([], size=(<span class="number">0</span>, <span class="number">4</span>)),</span><br><span class="line">  <span class="string">'labels'</span>: tensor([], dtype=torch.int64),</span><br><span class="line">  <span class="string">'scores'</span>: tensor([])&#125;]</span><br></pre></td></tr></table></figure><p>这个 <code>bug</code> 当时我也佷头疼，翻遍了全网，总结下可能导致此类错误的原因吧：</p><ul><li>类别数目没有加一，也就是没有考虑背景类。这个解决方案在上面已经给出。传入训练模型时，增加一个背景类</li><li><code>pretrained=False</code>。当时是我考虑少了，以为 <code>pretrained=False</code>的情况下，毕竟模型的 backbone 是经过预训练的，以为能应付简单的目标检测，后来发现是我草率了；<code>pretrained=True</code>，不仅 backbone，整个模型都是预训练的，这样才能检测到目标。</li></ul><h1 id="references"><a href="#references" class="headerlink" title="references"></a>references</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;">https://github.com/pytorch/vision/blob/730c5e1eab130e2900c8e839ea08fa11f024516f/torchvision/models/detection/faster_rcnn.py#L23</span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;">https://github.com/pytorch/vision/issues/2740</span><a href="#fnref:2" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最早在天池玩耍的时候接触到了目标检测。当时真的啥都不知道，头铁，一点点的开坑造轮子。后来再看前几名开源的程序，发现有很多库可以使用，切图，目标检测等，比如数据增强、目标检测都有现成的工具箱。所以想着，就先用调库的形式写一个简单的 &lt;code&gt;baseline&lt;/code&gt;，下一个任务直接用现成的代码，省点事，所以写了一个这样的简单的平台。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>目标检测篇：FPN</title>
    <link href="https://muyuuuu.github.io/2021/05/01/FPN/"/>
    <id>https://muyuuuu.github.io/2021/05/01/FPN/</id>
    <published>2021-05-01T12:27:48.000Z</published>
    <updated>2021-05-25T17:40:08.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>在目标检测领域，很难保证所要检测目标的大小都是类似的，MNIST，cifar10，imageNet 等玩具数据集除外。实际场景中，往往目标大小不一致、长宽比例不一致、图片的大小也不一致。长宽比例不一致可以通过之前提到的 Faster R-CNN <sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> 来解决。FPN 的全称是 Feature Pyramid Networks <sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> ，本算法重点关注目标多尺度的问题。因为传统两阶段检测（区域提议、区域识别）算法基于特征图进行预测，通常来自网络骨干的最后一层，回导致小物体信息的丢失。</p><a id="more"></a><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p><img data-src="https://z3.ax1x.com/2021/05/01/gVYavt.png" alt></p><p>来看一下传统的多尺度检测方法：</p><ul><li>图 a 中，一看就是常规的方法，将一张图片的多个尺度的特征进行预测。对某一输入图片我们通过压缩或放大从而形成不同尺寸的图片作为模型输入，使用同一模型对这些不同尺寸的图片分别处理后，最终再将这些分别得到的特征（feature maps）组合起来。此种方法缺点在于需要对同一图片在更改维度后输入处理多次，计算缓慢。</li><li>图 b 中，用单一尺寸的图片做为输入，然后经 CNN 模型处理后，拿最终一层的feature maps 作为最终的特征集。优点是计算简单，如大多数 R-CNN 系列目标检测方法所用，如 Faster R-CNN 等。因此最终这些模型对小维度的目标检测性能不是很好。我曾遇到过在 $8000\times 8000$ 的图像中检测 $10\times 10$ 目标的任务，使用普通的 backbone 去卷积时，一不小心由于 <code>stride</code> 过大，直接错过了目标，导致小目标检测的性能急剧下降。</li><li>图 c 中，用单一尺寸的图片做为输入，此方法除选取最后一层的特征外，选用稍靠下的反映图片 low level 信息的 feature maps。然后将这些不同层次的特征简单合并起来，用于最终的特征组合输出。但依然会忽略一些具有更低级别信息，对更小维度的目标检测效果就不大好。</li><li>图 d 中，用单一尺寸的图片作为输入，选取所有层的特征联合起来做为最终的特征输出。另外还对各层所反映的不同级别的特征信息进行了自上向下的整合，能更好检测目标。而此方法正是我们本文中要讲的 FPN CNN 特征提取方法。</li></ul><p>注意：</p><ul><li>对于卷积神经网络而言，不同深度对应着不同层次的语义特征，浅层网络分辨率高，学的更多是浅层特征，如细节、边缘等；深层网络分辨率低，学的更多是深层语义特征，如物体轮廓、类别等。</li></ul><h1 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a>FPN</h1><p>FPN 是传统 CNN 网络对图片信息进行表达的一种增强整合。目的是为了改进 CNN 网络的特征提取方式，从而可以使最终输出的特征更好地涵盖输入图片各个维度的信息。它包括两个基本过程：自下至上的通路，即计算不同尺寸的特征；自上至下的通路，即自上至下的特征补充。</p><h2 id="自下而上"><a href="#自下而上" class="headerlink" title="自下而上"></a>自下而上</h2><p>也就是网络的前向计算部分，而每层的输出都是上一层输出尺寸的 1/2，就完成了传统金字塔方法和 CNN 网络的名词的对应。</p><h2 id="自上而下"><a href="#自上而下" class="headerlink" title="自上而下"></a>自上而下</h2><p>将深层的有更强语义信息的 feature 经过上采样变成具有高分辨率特征图像的过程。然后再与下一层得到的 feature 经过侧边连接相加，进行增强。最底层的输出会有细节信息和高层特征，检测大目标的同时，也不会忽略小目标。</p><p>增强后的数据经过一个 <code>3×3</code> 卷积的处理，原文的意思是这个卷积能减少上采样导致混叠的不利影响，就可以作为网络的输出了。这个图看不懂的话，可以看下面的代码。代码看不懂的话，<del>我也没办法了</del>。</p><p>这里需要注意的是，<strong>每一层，也就是这三个 predict，输出的通道数是相同的。</strong></p><p><img data-src="https://z3.ax1x.com/2021/05/01/gVNOHK.png" alt></p><h1 id="与-RPN-结合"><a href="#与-RPN-结合" class="headerlink" title="与 RPN 结合"></a>与 RPN 结合</h1><p>FPN 将提取到的特征送到 RPN 中用于目标检测，RPN 再去用于用于预测边界框和前景、背景。因为 FPN 有多个层次的输出，所以在每一层的输出后面接入一个 <code>3×3</code> 卷积的处理，在共用两个并联的 <code>1x1</code> 的卷积层用于预测前景背景和目标框的位置。所以一般而言，称特征提取器为 backbone，FPN 为 neck，RPN 预测部分为 head。图片来源 <sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>：</p><p><img data-src="https://miro.medium.com/1*Hi3mCsgTEjPLtWnRyXx47w.jpeg" alt></p><h1 id="与-Faster-RCNN-结合"><a href="#与-Faster-RCNN-结合" class="headerlink" title="与 Faster RCNN 结合"></a>与 Faster RCNN 结合</h1><p>这里，就参考这篇文章 <sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> 吧，我就不照抄了。大体意思就是。在 backbone 中接入 FPN，生成不同尺寸的特征图。使用 RPN 生成不同的 ROI。根据 ROI 尺寸的不同，在不同尺寸的特征图中选择特征块，如下图所示 <sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>： </p><p><img data-src="https://miro.medium.com/max/2000/1*Wvn0WG4XZ0w9Ed2fFYPrXw.jpeg" alt></p><h1 id="程序"><a href="#程序" class="headerlink" title="程序"></a>程序</h1><p>讲真，挺容易理解的。</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个卷积残差块</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bottleneck</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_planes, planes, stride=<span class="number">1</span>)</span>:</span></span><br><span class="line">        super(Bottleneck, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=in_planes,</span><br><span class="line">                               out_channels=planes,</span><br><span class="line">                               kernel_size=<span class="number">1</span>,</span><br><span class="line">                               bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(planes)</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=planes,</span><br><span class="line">                               out_channels=planes,</span><br><span class="line">                               kernel_size=<span class="number">3</span>,</span><br><span class="line">                               stride=stride,</span><br><span class="line">                               padding=<span class="number">1</span>,</span><br><span class="line">                               bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(planes)</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(in_channels=planes,</span><br><span class="line">                               out_channels=self.expansion * planes,</span><br><span class="line">                               kernel_size=<span class="number">1</span>,</span><br><span class="line">                               bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(num_features=self.expansion * planes)</span><br><span class="line"></span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 步长不为 1 或者 输入特征不等于输出特征</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> in_planes != self.expansion * planes:</span><br><span class="line">            <span class="comment"># 残差块</span></span><br><span class="line">            self.shortcut = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=in_planes,</span><br><span class="line">                          out_channels=self.expansion * planes,</span><br><span class="line">                          kernel_size=<span class="number">1</span>,</span><br><span class="line">                          stride=stride,</span><br><span class="line">                          bias=<span class="literal">False</span>), nn.BatchNorm2d(self.expansion * planes))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        out = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        out = F.relu(self.bn2(self.conv2(out)))</span><br><span class="line">        out = self.bn3(self.conv3(out))</span><br><span class="line">        out += self.shortcut(x)</span><br><span class="line">        out = F.relu(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FPN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, block, num_blocks)</span>:</span></span><br><span class="line">        super(FPN, self).__init__()</span><br><span class="line">        self.in_planes = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">3</span>,</span><br><span class="line">                               out_channels=<span class="number">64</span>,</span><br><span class="line">                               kernel_size=<span class="number">7</span>,</span><br><span class="line">                               stride=<span class="number">2</span>,</span><br><span class="line">                               padding=<span class="number">3</span>,</span><br><span class="line">                               bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Bottom-up layers, backbone of the network</span></span><br><span class="line">        <span class="comment"># planes 是输出特征</span></span><br><span class="line">        <span class="comment"># channel 变化：3 -&gt; 64 -&gt; 64 -&gt; 256</span></span><br><span class="line">        self.layer1 = self._make_layer(block=block,</span><br><span class="line">                                       planes=<span class="number">64</span>,</span><br><span class="line">                                       num_blocks=num_blocks[<span class="number">0</span>],</span><br><span class="line">                                       stride=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># channel 变化：64*4 -&gt; 128 -&gt; 128 -&gt; 512</span></span><br><span class="line">        self.layer2 = self._make_layer(block=block,</span><br><span class="line">                                       planes=<span class="number">128</span>,</span><br><span class="line">                                       num_blocks=num_blocks[<span class="number">1</span>],</span><br><span class="line">                                       stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># out_channel: 1024</span></span><br><span class="line">        self.layer3 = self._make_layer(block=block,</span><br><span class="line">                                       planes=<span class="number">256</span>,</span><br><span class="line">                                       num_blocks=num_blocks[<span class="number">2</span>],</span><br><span class="line">                                       stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># out_channel 2048</span></span><br><span class="line">        self.layer4 = self._make_layer(block=block,</span><br><span class="line">                                       planes=<span class="number">512</span>,</span><br><span class="line">                                       num_blocks=num_blocks[<span class="number">3</span>],</span><br><span class="line">                                       stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Top layer</span></span><br><span class="line">        <span class="comment"># layer4 后面接一个1x1, 256 conv，得到金字塔最顶端的feature</span></span><br><span class="line">        self.toplayer = nn.Conv2d(in_channels=<span class="number">2048</span>,</span><br><span class="line">                                  out_channels=<span class="number">256</span>,</span><br><span class="line">                                  kernel_size=<span class="number">1</span>,</span><br><span class="line">                                  stride=<span class="number">1</span>,</span><br><span class="line">                                  padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Smooth layers</span></span><br><span class="line">        <span class="comment"># 这个是上面引文中提到的抗 『混叠』 的3x3卷积</span></span><br><span class="line">        <span class="comment"># 由于金字塔上的所有feature共享classifier和regressor</span></span><br><span class="line">        <span class="comment"># 要求它们的channel dimension必须一致</span></span><br><span class="line">        <span class="comment"># 这个用于多路预测</span></span><br><span class="line">        self.smooth1 = nn.Conv2d(in_channels=<span class="number">256</span>,</span><br><span class="line">                                 out_channels=<span class="number">256</span>,</span><br><span class="line">                                 kernel_size=<span class="number">3</span>,</span><br><span class="line">                                 stride=<span class="number">1</span>,</span><br><span class="line">                                 padding=<span class="number">1</span>)</span><br><span class="line">        self.smooth2 = nn.Conv2d(in_channels=<span class="number">256</span>,</span><br><span class="line">                                 out_channels=<span class="number">256</span>,</span><br><span class="line">                                 kernel_size=<span class="number">3</span>,</span><br><span class="line">                                 stride=<span class="number">1</span>,</span><br><span class="line">                                 padding=<span class="number">1</span>)</span><br><span class="line">        self.smooth3 = nn.Conv2d(in_channels=<span class="number">256</span>,</span><br><span class="line">                                 out_channels=<span class="number">256</span>,</span><br><span class="line">                                 kernel_size=<span class="number">3</span>,</span><br><span class="line">                                 stride=<span class="number">1</span>,</span><br><span class="line">                                 padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Lateral layers</span></span><br><span class="line">        <span class="comment"># 为了匹配channel dimension引入的1x1卷积</span></span><br><span class="line">        <span class="comment"># 注意这些backbone之外的extra conv，输出都是256 channel</span></span><br><span class="line">        self.latlayer1 = nn.Conv2d(in_channels=<span class="number">1024</span>,</span><br><span class="line">                                   out_channels=<span class="number">256</span>,</span><br><span class="line">                                   kernel_size=<span class="number">1</span>,</span><br><span class="line">                                   stride=<span class="number">1</span>,</span><br><span class="line">                                   padding=<span class="number">0</span>)</span><br><span class="line">        self.latlayer2 = nn.Conv2d(in_channels=<span class="number">512</span>,</span><br><span class="line">                                   out_channels=<span class="number">256</span>,</span><br><span class="line">                                   kernel_size=<span class="number">1</span>,</span><br><span class="line">                                   stride=<span class="number">1</span>,</span><br><span class="line">                                   padding=<span class="number">0</span>)</span><br><span class="line">        self.latlayer3 = nn.Conv2d(in_channels=<span class="number">256</span>,</span><br><span class="line">                                   out_channels=<span class="number">256</span>,</span><br><span class="line">                                   kernel_size=<span class="number">1</span>,</span><br><span class="line">                                   stride=<span class="number">1</span>,</span><br><span class="line">                                   padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_layer</span><span class="params">(self, block, planes, num_blocks, stride)</span>:</span></span><br><span class="line">        strides = [stride] + [<span class="number">1</span>] * (num_blocks - <span class="number">1</span>)</span><br><span class="line">        layers = []</span><br><span class="line">        <span class="keyword">for</span> stride <span class="keyword">in</span> strides:</span><br><span class="line">            layers.append(block(self.in_planes, planes, stride))</span><br><span class="line">            self.in_planes = planes * block.expansion</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="comment">## FPN的lateral connection部分: upsample以后，element-wise相加</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_upsample_add</span><span class="params">(self, x, y)</span>:</span></span><br><span class="line">        _, _, H, W = y.size()</span><br><span class="line">        <span class="comment"># 上采样到指定尺寸</span></span><br><span class="line">        <span class="keyword">return</span> F.upsample(x, size=(H, W), mode=<span class="string">'bilinear'</span>) + y</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># Bottom-up</span></span><br><span class="line">        c1 = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        c1 = F.max_pool2d(c1, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        c2 = self.layer1(c1)</span><br><span class="line">        c3 = self.layer2(c2)</span><br><span class="line">        c4 = self.layer3(c3)</span><br><span class="line">        c5 = self.layer4(c4)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Top-down</span></span><br><span class="line">        <span class="comment"># P5: 金字塔最顶上的feature 2048 -&gt; 256</span></span><br><span class="line">        p5 = self.toplayer(c5)</span><br><span class="line">        <span class="comment"># P4: 上一层 p5 + 侧边来的 c4</span></span><br><span class="line">        <span class="comment"># 其余同理</span></span><br><span class="line">        p4 = self._upsample_add(p5, self.latlayer1(c4))</span><br><span class="line">        p3 = self._upsample_add(p4, self.latlayer2(c3))</span><br><span class="line">        p2 = self._upsample_add(p3, self.latlayer3(c2))</span><br><span class="line"></span><br><span class="line">        p4 = self.smooth1(p4)</span><br><span class="line">        p3 = self.smooth2(p3)</span><br><span class="line">        p2 = self.smooth3(p2)</span><br><span class="line">        <span class="keyword">return</span> p2, p3, p4, p5</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">FPN101</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 2 通过步长，控制上一层的图片尺寸是下一层图片尺寸的几倍，这里都是 2</span></span><br><span class="line">    <span class="keyword">return</span> FPN(Bottleneck, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></span><br><span class="line">    net = FPN101()</span><br><span class="line">    fms = net(torch.randn((<span class="number">1</span>, <span class="number">3</span>, <span class="number">600</span>, <span class="number">900</span>), requires_grad=<span class="literal">True</span>))</span><br><span class="line">    <span class="keyword">for</span> fm <span class="keyword">in</span> fms:</span><br><span class="line">        print(fm.size())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ref: https://github.com/kuangliu/pytorch-fpn/blob/master/fpn.py</span></span><br></pre></td></tr></table></figure><h1 id="references"><a href="#references" class="headerlink" title="references"></a>references</h1><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style:none; padding-left: 0;"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">1.</span><span style="display: inline-block; vertical-align: top;"><a href="https://muyuuuu.github.io/2021/04/28/faster-rcnn/">Faster R-CNN</a></span><a href="#fnref:1" rev="footnote"> ↩</a></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">2.</span><span style="display: inline-block; vertical-align: top;"><a href="https://arxiv.org/pdf/1612.03144.pdf" target="_blank" rel="noopener">FPN 论文</a></span><a href="#fnref:2" rev="footnote"> ↩</a></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">3.</span><span style="display: inline-block; vertical-align: top;"><a href="https://xmfbit.github.io/2018/04/02/paper-fpn/" target="_blank" rel="noopener">FPN 用于 Faster R0CNN</a></span><a href="#fnref:3" rev="footnote"> ↩</a></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px;">4.</span><span style="display: inline-block; vertical-align: top;"><a href="https://jonathan-hui.medium.com/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c" target="_blank" rel="noopener">FPN与RPN结合</a></span><a href="#fnref:4" rev="footnote"> ↩</a></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在目标检测领域，很难保证所要检测目标的大小都是类似的，MNIST，cifar10，imageNet 等玩具数据集除外。实际场景中，往往目标大小不一致、长宽比例不一致、图片的大小也不一致。长宽比例不一致可以通过之前提到的 Faster R-CNN &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 来解决。FPN 的全称是 Feature Pyramid Networks &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; ，本算法重点关注目标多尺度的问题。因为传统两阶段检测（区域提议、区域识别）算法基于特征图进行预测，通常来自网络骨干的最后一层，回导致小物体信息的丢失。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="CV" scheme="https://muyuuuu.github.io/tags/CV/"/>
    
  </entry>
  
</feed>
